#!/usr/bin/env python
# -*- coding: utf-8 -*-

# Templates:
#
# Nouns:
# -----
#
# aquila:
#
# {{la-noun|aquila|aquilae|f|first}}
# {{la-decl-1st|aquil}}
#
# abāctor:
#
# {{la-noun|abāctor|abāctōris|m|third}}
# {{la-decl-3rd|abactor}}
#
# abaculus:
#
# {{la-noun|abaculus|abaculī|m|second}}
# {{la-decl-2nd|abacul}}
#
# abdōmen:
#
# {{la-noun|abdōmen|abdōminis|n|third}}
# {{la-decl-3rd-N|abdōmen}}
#
# abomāsum:
#
# {{la-noun|abomāsum|abomāsī|n|second}}
# {{la-decl-2nd-N|abomās}}
#
# accipiter:
#
# {{la-noun|accipiter|accipitris|m|third}}
# {{la-decl-3rd|accipiter}}
#
# ȳ:
#
# {{la-noun|ȳ|indecl=yes}}
#
# dē:
#
# {{head|la|noun|head=dē|{{l|en|indeclinable}}}}
#
# absinthium:
#
# {{la-noun|absinthium|absinthiī|gen2=absinthī|n|second}}
# {{la-decl-2nd-N-ium|absinth}}
#
# lēns:
#
# {{la-noun|lēns|lentis|f|third}}
# {{la-decl-3rd|lēns}}
#
# diēs:
#
# {{la-noun|diēs|diēī|m|g2=f|fifth}}
# {{la-decl-5th-i|d}}
#
# ōs:
#
# {{la-noun|ōs|ōris|n|third}}
# {{la-decl-3rd-N-I|ōs|ōr}}
#
# os:
#
# {{la-noun|os|ossis|n|third}}
# {{la-decl-3rd-N-I|os|oss|gen_pl=ossium}}
#
# cōnsēnsus:
#
# {{la-noun|cōnsēnsus|cōnsēnsūs|m|fourth}}
# {{la-decl-4th|cōnsēns}}
#
# comma:
#
# {{la-noun|comma|commatis|n|third}}
# {{la-decl-3rd-N|comma}}
#
# colon:
#
# {{la-noun|colon|colī|n|second}}
# {{la-decl-2nd-N-Greek|col}}
#
# gas:
#
# {{la-noun|gas|gasis|n|third}}
# {{la-decl-3rd|gas|gas}}
#
# phoenīx:
#
# {{la-noun|phoenīx|phoenīcis|f|third}}
# {{la-decl-3rd-I|phoenīx}}
# {{la-noun|phoenīx|phoenīcis|m|third}}
# {{la-decl-3rd|phoenīx}}
#
# Proper nouns:
# -------------
#
# Belgium:
#
# {{la-proper noun|Belgium|Belgiī|n|second}}
# {{la-decl-2nd-N|num=sg|Belgi}}
#
# Isrāēl:
#
# {{la-proper noun|Isrāēl||m|indecl=1}}<br/>
# {{la-proper noun|Isrāēl|Isrāēlis|m|third}}
# {{la-decl-3rd|num=sg|Isrāēl|Isrāēl}}
#
# Abaddōn:
#
# {{head|la|proper noun|head=Abaddōn|g=m|indeclinable}}
#
# Andorra:
#
# {{la-proper noun|Andorra|Andorrae|f|first}}
# {{la-decl-1st|loc=1|num=sg|Andorr}}
#
# Niger:
#
# {{la-proper noun|Niger|Nigrī|m|second}}
# {{la-decl-2nd-er|Niger|Nigr}}
# {{la-proper noun|Niger|Nigris|m|third}}
# {{la-decl-3rd|num=sg|Niger|acc_sg=Nigrim}}
#
# Achilles:
#
# {{la-proper noun|Achilles|Achillis|m|third}}
# {{la-decl-3rd|num=sg|Achilles|Achill}}
#
# Pronouns:
# ---------
#
# is:
#
# {{head|la|pronoun}}
# {{la-decl-irreg|is}}
#
# Verbs:
# ------
#
# līberō:
#
# {{la-verb|līberō|līberāre|līberāvī|līberātum|conj=1}}
# {{la-conj-1st|līber|līberāv|līberāt|sync_perf=poet|p3inf=1}}
#
# ferō:
#
# {{la-verb|ferō|ferre|tulī|perf2=tetulī|lātum|conj=3|pattern=irreg}}
# {{la-conj-irreg|fero}}
#
# eō:
#
# {{la-verb|eō|īre|iī|itum|conj=irreg}}
# {{la-conj-irreg|eo|p3inf=1}}
#
# for:
#
# {{la-verb|for|fārī|fātus sum|conj=1|pattern=depon}}
# {{la-conj-1st|type=depon|f|fāt|p3inf=1}}
#
# abdīcō:
#
# {{la-verb|abdīcō|abdīcere|abdīxī|abdictum|conj=irreg}}
# {{la-conj-irreg|dico|ab}}
#
# abdō:
#
# {{la-verb|abdō|abdere|abdidī|abditum|conj=3}}
# {{la-conj-3rd|abd|abdid|abdit}}
#
# alō:
#
# {{la-verb|alō|alere|aluī|altum|sup2=alitum|conj=3}}
# {{la-conj-3rd|al|alu|alt}}
# {{la-conj-3rd|al|alu|alit}}
#
# lingō:
#
# {{la-verb|lingō|lingere|linxī|linctum|conj=3}}
# {{la-conj-3rd|ling|linx|linct}}
#
# vērō:
#
# {{la-verb|vērō|vērāre|conj=1|pattern=nopass-noperf}}
# {{la-conj-1st|type=nopass-noperf|vēr}}
#
# lābor:
#
# {{la-verb|lābor|lābī|lāpsus sum|conj=3|pattern=depon}}
# {{la-conj-3rd|type=depon|lāb|lāps}}
#
# videō:
#
# {{la-verb|videō|vidēre|vīdī|vīsum|conj=2}}
# {{la-conj-2nd|vid|vīd|vīs|p3inf=1}} 
#
# Prefixes:
# ---------
#
# ā-:
#
# {{head|la|prefix|head=ā-}}
#
# Prepositions:
# -------------
#
# in:
#
# {{la-prep|accusative|ablative}}
#
# Adjectives:
# -----------
#
# phoenīx:
#
# {{la-adj-3rd-1E|phoenīx|phoenīcis}}
# {{la-decl-3rd-1E|type=par|phoenīx|phoenīc}}
#
# incōmptus:
#
# {{la-adj-1&2|incōmptus|incōmpta|incōmptum}}
# {{la-decl-1&2|incōmpt}}
#
# Adverbs:
# --------
#
# lentē:
#
# {{la-adv|lentē}}
#
# ferē:
#
# {{la-adv|ferē|-}}
#
# Interjections:
# --------------
#
# ēn:
#
# {{la-interj|ēn}}
#
# tax:
#
# {{head|la|interjection}}
#
# Letters:
# --------
#
# o:
#
# {{head|la|letter}}
#
# Abbreviations:
# --------------
#
# JUL:
#
# {{head|la|abbreviation}}
#
# Adjective forms:
# ----------------
#
# {{la-adj-form|abdominālēs}}
# # {{inflection of|abdominālis||nom|m|p|lang=la}}
# # {{inflection of|abdominālis||nom|f|p|lang=la}}
# # {{inflection of|abdominālis||acc|m|p|lang=la}}
# # {{inflection of|abdominālis||acc|f|p|lang=la}}
# # {{inflection of|abdominālis||voc|m|p|lang=la}}
# # {{inflection of|abdominālis||voc|f|p|lang=la}}
#
# Verb forms:
# -----------
#
# {{la-verb-form|abdūce}}
#
# # {{inflection of|abdūcō||2|s|pres|actv|impr|lang=la}}
#
# Noun forms:
# -----------
#
# {{la-noun-form|diē}}
#
# # {{inflection of|diēs||abl|s|lang=la|nodot=1}} (&quot;[[day]]&quot;).
#
# Participle forms:
# -----------------
#
# abrāse:
#
# {{la-part-form|abrāse}}
#
# # {{inflection of|abrāsus||voc|m|s|lang=la}}
#
# Pronoun forms:
# --------------
#
# mī:
#
# {{la-pronoun-form|mī}}
# {{head|la|pronoun form|head=mī}}
#


# Clean up use of macrons in Latin lemmas.

import pywikibot, re, sys, codecs, argparse

import blib
from blib import getparam, rmparam, msg, errandmsg, site, tname

import lalib
from lalib import remove_macrons


cases = [ "nom", "gen", "dat", "acc", "abl", "voc", "loc" ]

la_noun_decl_overrides = [ "%s_%s" % (case, num)
    for num in ["sg", "pl"] for case in cases]

la_adj_decl_overrides = [ "%s_%s_%s" % (case, num, g)
    for g in ["m", "f", "n"]
    for num in ["sg", "pl"]
    for case in cases
]

def get_references(page, start, end, include_page=False):
  global args
  if args.dry_run:
    msg("Getting references to %s" % page)
    return []
  else:
    return blib.references(remove_macrons(page), start, end, include_page=include_page)

def frob_param(t, param, stem_or_exact, is_exact, pagemsg, notes, split_slashes=False, no_warn=False):
  origt = unicode(t)
  origval = getparam(t, param)
  if split_slashes:
    vals = origval.split("/")
  else:
    vals = [origval]
  newvals = []
  for val in vals:
    no_macrons_val = remove_macrons(val)
    assert len(no_macrons_val) == len(val)
    if type(stem_or_exact) is not list:
      stem_or_exact = [stem_or_exact]
    for st in stem_or_exact:
      no_macrons_st = remove_macrons(st)
      assert len(no_macrons_st) == len(st)
      if is_exact:
        if no_macrons_val == no_macrons_st:
          newvals.append(st)
          break
      else:
        if no_macrons_val.startswith(no_macrons_st):
          newvals.append(st + val[len(st):])
          break
    else:
      if val or not no_warn:
        # no break
        if is_exact:
          pagemsg("WARNING: Unable to match value %s in param %s against replacement(s) %s" % (
            val, param, ",".join(stem_or_exact)))
        else:
          pagemsg("WARNING: Unable to match value %s in param %s against replacement stem(s) %s" % (
            val, param, ",".join(stem_or_exact)))
      newvals.append(val)
  newval = "/".join(newvals)
  if newval != origval:
    t.add(param, newval)
    pagemsg("Replaced %s with %s" % (origt, unicode(t)))
    notes.append("updated macrons in %s" % tname(t))

def frob_stem(t, param, stem, pagemsg, notes, split_slashes=False, no_warn=False):
  frob_param(t, param, stem, False, pagemsg, notes, split_slashes=split_slashes,
      no_warn=no_warn)

def frob_exact(t, param, newval, pagemsg, notes, split_slashes=False, no_warn=False):
  frob_param(t, param, newval, True, pagemsg, notes, split_slashes=split_slashes,
      no_warn=no_warn)

def frob_chain_stem(t, param, stem, pagemsg, notes, split_slashes=False, no_warn=False):
  if type(param) is list:
    first, rest = param
  else:
    first = param
    rest = param
  if first:
    frob_stem(t, first, stem, pagemsg, notes, split_slashes=split_slashes,
        no_warn=no_warn)
  num = 2
  while getparam(t, "%s%s" % (rest, num)):
    frob_stem(t, "%s%s" % (rest, num), stem, pagemsg, notes, split_slashes=split_slashes,
        no_warn=no_warn)
    num += 1

def frob_chain_exact(t, param, newval, pagemsg, notes, split_slashes=False, no_warn=False):
  if type(param) is list:
    first, rest = param
  else:
    first = param
    rest = param
  if first:
    frob_exact(t, first, newval, pagemsg, notes, split_slashes=split_slashes,
        no_warn=no_warn)
  num = 2
  while getparam(t, "%s%s" % (rest, num)):
    frob_exact(t, "%s%s" % (rest, num), newval, pagemsg, notes, split_slashes=split_slashes,
        no_warn=no_warn)
    num += 1

def find_heads_and_defns(page, pagemsg):
  text = unicode(page.text)

  retval = lalib.find_latin_section(text, pagemsg)
  if retval is None:
    return None

  sections, j, secbody, sectail, has_non_latin = retval

  subsections = re.split("(^==+[^=\n]+==+\n)", secbody, 0, re.M)

  parsed_subsections = [None] * len(subsections)
  pronun_templates = []
  headwords = []

  most_recent_headword = None

  def new_headword(header, level, subsection, head_template, is_lemma):
    return {
      'head_template': head_template,
      'header': header,
      'is_lemma': is_lemma,
      'infl_templates': [],
      'infl_of_templates': [],
      'subsection': subsection,
      'level': level,
    }

  def transfer_most_recent_headword():
    headwords.append(most_recent_headword)

  for k in xrange(len(subsections)):
    if k < 2 or (k % 2) == 1:
      parsed_subsections[k] = blib.parse_text(subsections[k])
      continue
    m = re.search("^(==+)([^=\n]+)", subsections[k - 1])
    level = len(m.group(1))
    header = m.group(2)
    headword_templates_in_section = []

    if most_recent_headword and most_recent_headword['level'] >= level:
      transfer_most_recent_headword()
      most_recent_headword = None

    parsed = blib.parse_text(subsections[k])
    parsed_subsections[k] = parsed
    for t in parsed.filter_templates():
      tn = tname(t)
      if tn == "la-IPA":
        pronun_templates.append((t, k))
      elif tn in lalib.la_headword_templates:
        if headword_templates_in_section:
          pagemsg("WARNING: Found additional headword template in same section: %s" % unicode(t))
          transfer_most_recent_headword()
        elif most_recent_headword:
          pagemsg("WARNING: Found headword template nested under previous one: %s" % unicode(t))
          transfer_most_recent_headword()
        most_recent_headword = new_headword(header, level, k, t,
          tn in lalib.la_lemma_headword_templates)
        headword_templates_in_section.append(t)
      elif tn in lalib.la_infl_templates:
        if not most_recent_headword:
          pagemsg("WARNING: Found inflection template not under headword template: %s" % unicode(t))
        else:
          most_recent_headword['infl_templates'].append(t)
      elif tn in lalib.la_infl_of_templates:
        if not most_recent_headword:
          pagemsg("WARNING: Found inflection-of template not under headword template: %s" % unicode(t))
        else:
          most_recent_headword['infl_of_templates'].append(t)

  if most_recent_headword:
    transfer_most_recent_headword()

  return (
    sections, j, secbody, sectail, has_non_latin, subsections,
    parsed_subsections, pronun_templates, headwords
  )


def process_page(index, page, pos, lemma, stem, save, verbose):
  pagetitle = unicode(page.title())
  def pagemsg(txt):
    msg("Page %s %s: %s" % (index, pagetitle, txt))

  def errandpagemsg(txt):
    errandmsg("Page %s %s: %s" % (index, pagetitle, txt))

  def expand_text(tempcall):
    return blib.expand_text(tempcall, pagetitle, pagemsg, verbose)

  pagemsg("Processing")

  text = unicode(page.text)
  parsed = blib.parse(page)
  notes = []
  for t in parsed.filter_templates():
    origt = unicode(t)
    tn = tname(t)

    if tn == "la-IPA":
      if not getparam(t, "1"):
        if remove_macrons(lemma) != lemma:
          eccl = getparam(t, "eccl")
          rmparam(t, "eccl")
          t.add("1", lemma)
          if eccl:
            t.add("eccl", eccl)
          notes.append("add pronunciation to {{la-IPA}}")
      else:
        frob_stem(t, "1", stem, pagemsg, notes)
    elif tn == "la-noun-form" and pos == "noun":
      frob_stem(t, "1", stem, pagemsg, notes)
    elif tn == "la-adj-form" and pos == "adj":
      frob_stem(t, "1", stem, pagemsg, notes)
    elif tn == "la-num-form" and pos == "numadj":
      frob_stem(t, "1", stem, pagemsg, notes)
    elif tn in ["la-perfect participle", "la-future participle",
        "la-gerundive",
        "la-verb-form", "la-part-form", "la-decl-1&2",
        "la-decl-3rd-part"] and pos == "verb":
      frob_stem(t, "1", stem, pagemsg, notes)
    elif tn == "la-present participle" and pos == "verb":
      # la-present participle has a different format
      stems = stem
      if type(stems) is not list:
        stems = [stem]
      stems = [re.sub(u"[āē]ns$", "", st) for st in stems]
      for st in stems:
        frob_exact(t, "1", st, pagemsg, notes)
    elif tn == "inflection of":
      lang = getparam(t, "lang")
      if lang:
        lemma_param = "1"
        alt_param = "2"
      else:
        lang = getparam(t, "1")
        lemma_param = "2"
        alt_param = "3"
      if lang == "la":
        tlemma = getparam(t, lemma_param)
        talt = getparam(t, alt_param)
        if not talt:
          frob_exact(t, lemma_param, lemma, pagemsg, notes)
        elif remove_macrons(tlemma) == remove_macrons(talt):
          t.add(lemma_param, talt)
          t.add(alt_param, "")
          notes.append("moved alt param in {{inflection of|la}} to lemma")
          frob_exact(t, lemma_param, lemma, pagemsg, notes)
        else:
          pagemsg("WARNING: In %s, alt param != lemma param even aside from macrons" % origt)
          frob_exact(t, alt_param, lemma, pagemsg, notes)

  return unicode(parsed), notes

def process_lemma(index, page, pos, explicit_infl, lemma, explicit_stem, save, verbose):
  pagetitle = unicode(page.title())
  def pagemsg(txt):
    msg("Page %s %s: %s" % (index, pagetitle, txt))

  def errandpagemsg(txt):
    errandmsg("Page %s %s: %s" % (index, pagetitle, txt))

  def expand_text(tempcall):
    return blib.expand_text(tempcall, pagetitle, pagemsg, verbose)

  pagemsg("Processing")

  retval = find_heads_and_defns(page, pagemsg)
  if retval is None:
    return None, None

  (
    sections, j, secbody, sectail, has_non_latin, subsections,
    parsed_subsections, pronun_templates, headwords
  ) = retval

  notes = []
  for headword in headwords:
    ht = headword['head_template']
    tn = tname(ht)

    if pos == "noun" and tn == "la-noun":
      if explicit_infl == 1:
        if lemma.endswith("a"):
          inferred_stem = lemma[:-1]
        else:
          errandpagemsg("WARNING: Bad 1st-declension noun lemma %s" % lemma)
          return None, None
      elif explicit_infl == 2:
        if lemma.endswith("r"):
          inferred_stem = lemma
        elif lemma.endswith("ius") or lemma.endswith("ium"):
          inferred_stem = lemma[:-3] # second genitive will have -ī
        elif lemma.endswith("us") or lemma.endswith("um"):
          inferred_stem = lemma[:-2]
        else:
          errandpagemsg("WARNING: Bad 2nd-declension noun lemma %s" % lemma)
          return None, None
      elif explicit_infl == 3:
        inferred_stem = lalib.infer_3rd_decl_stem(lemma)
      elif explicit_infl == 4:
        if lemma.endswith("us"):
          inferred_stem = lemma[:-2]
        else:
          errandpagemsg("WARNING: Bad 4th-declension noun lemma %s" % lemma)
          return None, None
      elif explicit_infl == 5:
        if lemma.endswith(u"ēs"):
          inferred_stem = lemma[:-2]
        else:
          errandpagemsg("WARNING: Bad 5th-declension noun lemma %s" % lemma)
          return None, None
      else:
        errandpagemsg("WARNING: Unrecognized infl %s" % explicit_infl)
        return None, None

      stem = explicit_stem or inferred_stem

      infl_to_ordinal = {
        1: 'first',
        2: 'second',
        3: 'third',
        4: 'fourth',
        5: 'fifth'
      }

      if (remove_macrons(lemma) == remove_macrons(getparam(ht, "1")) and
          getparam(ht, "4") == infl_to_ordinal[explicit_infl]):
        frob_exact(ht, "1", lemma, pagemsg, notes)
        frob_chain_stem(ht, ["2", "gen"], stem, pagemsg, notes)
        for inflt in headword['infl_templates']:
          infltn = tname(inflt)
          if infltn not in lalib.la_noun_decl_templates:
            pagemsg("WARNING: Saw bad declension template for infl=%s noun %s: %s" % (
              explicit_infl, lemma, unicode(inflt)))
            continue
          m = re.search('^la-decl-(.*)$', infltn)
          decltype = lalib.la_noun_decl_suffix_to_decltype[m.group(1)]
          if type(decltype) is tuple:
            decl = decltype[0]
            if len(decltype) >= 2:
              declsubtypes = decltype[1].split("-")
            else:
              declsubtypes = []
          else:
            decl = decltype
            declsubtypes = []
          if decl is None:
            pagemsg("WARNING: Don't know how to handle decl: %s" % unicode(inflt))
            continue
          if decl != str(explicit_infl):
            pagemsg("WARNING: Wrong decl %s != expected %s for decl template: %s" % (
              decl, explicit_infl, unicode(inflt)))
            continue
          if explicit_infl == 1:
            if not lemma.endswith("a"):
              errandpagemsg("WARNING: Bad 1st-declension noun lemma %s" % lemma)
              return None, None
            arg1 = lemma[:-1]
            arg2 = ""
          elif explicit_infl == 2:
            if lemma.endswith("us"):
              if "ius" in declsubtypes:
                if not lemma.endswith("ius"):
                  pagemsg("WARNING: Declension template requires lemma in -ius but lemma %s doesn't end that way: %s" % (
                    lemma, unicode(inflt)))
                  continue
                arg1 = lemma[:-3]
                arg2 = ""
              else:
                arg1 = lemma[:-2]
                arg2 = ""
            elif lemma.endswith("um"):
              if "ium" in declsubtypes:
                if not lemma.endswith("ium"):
                  pagemsg("WARNING: Declension template requires lemma in -ium but lemma %s doesn't end that way: %s" % (
                    lemma, unicode(inflt)))
                  continue
                arg1 = lemma[:-3]
                arg2 = ""
              else:
                arg1 = lemma[:-2]
                arg2 = ""
            elif lemma.endswith("r"):
              arg1 = lemma
              if explicit_stem and explicit_stem != lemma:
                arg2 = explicit_stem
              else:
                arg2 = ["", lemma]
            else:
              errandpagemsg("WARNING: Bad 2nd-declension noun lemma %s" % lemma)
              return None, None
          elif explicit_infl == 3:
            arg1 = lemma
            if explicit_stem and explicit_stem != inferred_stem:
              arg2 = explicit_stem
            else:
              arg2 = ["", inferred_stem]
          elif explicit_infl == 4:
            if not lemma.endswith("us"):
              errandpagemsg("WARNING: Bad 4th-declension noun lemma %s" % lemma)
              return None, None
            arg1 = lemma[:-2]
            arg2 = ""
          elif explicit_infl == 5:
            if not lemma.endswith(u"ēs"):
              errandpagemsg("WARNING: Bad 5th-declension noun lemma %s" % lemma)
              return None, None
            if "i" in declsubtypes:
              if not lemma.endswith(u"iēs"):
                pagemsg(u"WARNING: Declension template requires lemma in -iēs but lemma %s doesn't end that way: %s" % (
                  lemma, unicode(inflt)))
                continue
              arg1 = lemma[:-3]
              arg2 = ""
            else:
              arg1 = lemma[:-2]
              arg2 = ""
          else:
            errandpagemsg("WARNING: Unrecognized infl %s" % explicit_infl)
            return None, None

          if remove_macrons(arg1) != remove_macrons(getparam(inflt, "1")):
            pagemsg("WARNING: lemma stem %s doesn't match template stem: %s" % (
              arg1, unicode(inflt)))
            continue
          param2 = getparam(inflt, "2")
          if type(arg2) is not list:
            arg2 = [arg2]
          actual_matching_arg2 = None
          for matching_arg2 in arg2:
            if remove_macrons(matching_arg2) == remove_macrons(param2):
              actual_matching_arg2 = matching_arg2
              break
          else:
            # no break
            pagemsg("WARNING: lemma secondary stem(s) %s not matching template second param: %s" % (
              ",".join(arg2), unicode(inflt)))
            continue

          frob_exact(inflt, "1", arg1, pagemsg, notes)
          frob_exact(inflt, "2", actual_matching_arg2, pagemsg, notes)

          for override in la_noun_decl_overrides:
            frob_stem(inflt, override, stem, pagemsg, notes, split_slashes=True,
                no_warn=True)

    elif pos == "adj" and tn in lalib.la_adj_headword_templates:
      if explicit_infl == 1:
        if lemma.endswith("r"):
          inferred_stem = lemma
        elif lemma.endswith("us"):
          inferred_stem = lemma[:-2]
        else:
          errandpagemsg("WARNING: Bad 1st/2nd-declension adjective lemma %s" % lemma)
          return None, None
      elif explicit_infl == 3:
        inferred_stem = lalib.infer_3rd_decl_stem(lemma)
      stem = explicit_stem or inferred_stem

      if (explicit_infl == 1 and tn in ["la-adj-1&2", "la-adj-superlative"] or
          explicit_infl == 3 and tn in ["la-adj-3rd-1E", "la-adj-3rd-2E", "la-adj-3rd-3E", "la-adj-comparative"]):
        frob_chain_exact(ht, ["1", "head"], lemma, pagemsg, notes)
        if tn in ["la-adj-1&2", "la-adj-3rd-1E", "la-adj-3rd-2E", "la-adj-3rd-3E"]:
          frob_chain_stem(ht, "comp", stem, pagemsg, notes, no_warn=True)
          frob_chain_stem(ht, "sup", stem, pagemsg, notes, no_warn=True)
        if tn in ["la-adj-1&2", "la-adj-3rd-3E"]:
          frob_chain_stem(ht, ["2", "f"], stem, pagemsg, notes)
          frob_chain_stem(ht, ["3", "n"], stem, pagemsg, notes)
        elif tn == "la-adj-3rd-1E":
          frob_chain_stem(ht, ["2", "gen"], stem, pagemsg, notes)
        elif tn == "la-adj-3rd-2E":
          frob_chain_stem(ht, ["2", "n"], stem, pagemsg, notes)
        elif tn == "la-adj-comparative":
          if lemma.endswith("ior"):
            base = lemma[:-3]
            frob_stem(ht, "comp", base, pagemsg, notes, no_warn=True)
        elif tn == "la-adj-superlative":
          if lemma.endswith("issimus"):
            base = lemma[:-7]
          if lemma.endswith("rimus"):
            base = lemma[:-5]
          else:
            base = None
          if base:
            frob_stem(ht, "sup", base, pagemsg, notes)

        for inflt in headword['infl_templates']:
          infltn = tname(inflt)
          if infltn not in lalib.la_adj_decl_templates:
            pagemsg("WARNING: Saw bad declension template for infl=%s adj %s: %s" % (
              explicit_infl, lemma, unicode(inflt)))
            continue

          if explicit_infl == 1:
            if infltn != "la-decl-1&2":
              pagemsg("WARNING: Saw mismatching adjective declension template for first/second-declension adjective %s: %s" % (
                lemma, unicode(inflt)))
              continue
            if lemma.endswith("er") and lemma != stem:
              if getparam(inflt, "1").endswith("(e)r"):
                arg1 = lemma[:-2] + "(e)r"
                arg2 = ""
              else:
                arg1 = lemma
                arg2 = stem
            else:
              arg1 = stem
              arg2 = ""
          elif explicit_infl == 3:
            if infltn in ["la-decl-3rd-1E", "la-decl-3rd-3E", "la-decl-3rd-part"]:
              arg1 = lemma
              if stem != inferred_stem:
                arg2 = stem
              else:
                arg2 = ["", inferred_stem]
            elif infltn == "la-decl-3rd-2E":
              if not lemma.endswith("is"):
                pagemsg("WARNING: Bad lemma %s for 3rd declension, two-ending adjective: %s" % (
                  lemma, unicode(inflt)))
                continue
              arg1 = lemma[:-2]
              arg2 = ""
            elif infltn == "la-decl-3rd-comp":
              if not lemma.endswith("or"):
                pagemsg("WARNING: Bad lemma %s for 3rd declension comparative adjective: %s" % (
                  lemma, unicode(inflt)))
                continue
              arg1 = lemma[:-3]
              if getparam(inflt, "2"):
                arg2 = lemma[-3]
              else:
                arg2 = ""
          else:
            errandpagemsg("WARNING: Unrecognized infl %s" % explicit_infl)
            return None, None

          if remove_macrons(arg1) != remove_macrons(getparam(inflt, "1")):
            pagemsg("WARNING: lemma stem %s doesn't match template stem: %s" % (
              arg1, unicode(inflt)))
            continue
          param2 = getparam(inflt, "2")
          if type(arg2) is not list:
            arg2 = [arg2]
          actual_matching_arg2 = None
          for matching_arg2 in arg2:
            if remove_macrons(matching_arg2) == remove_macrons(param2):
              actual_matching_arg2 = matching_arg2
              break
          else:
            # no break
            pagemsg("WARNING: lemma secondary stem(s) %s not matching template second param: %s" % (
              ",".join(arg2), unicode(inflt)))
            continue
          frob_exact(inflt, "1", arg1, pagemsg, notes)
          frob_exact(inflt, "2", actual_matching_arg2, pagemsg, notes)

          for override in la_adj_decl_overrides:
            frob_stem(inflt, override, stem, pagemsg, notes, split_slashes=True,
                no_warn=True)

      else:
        pagemsg("WARNING: Mismatch between requested adjective inflection %s and actual adjective headword template %s" % (
          explicit_infl, unicode(ht)))

    elif pos == "verb" and tn == "la-verb":
      deponent = False
      if explicit_infl == 1 and not explicit_stem:
        infl = 1
        if lemma.endswith("or"):
          deponent = True
          vinf = lemma[:-2] + u"ārī"
          vperf = ""
          vsup = lemma[:-2] + u"ātum"
        elif lemma.endswith(u"ō"):
          vinf = lemma[:-1] + u"āre"
          vperf = lemma[:-1] + u"āvī"
          vsup = lemma[:-1] + u"ātum"
        else:
          errandpagemsg("WARNING: Bad lemma %s for 1st-conjugation verb" % lemma)
          return None, None
      elif explicit_infl == 4 and not explicit_stem:
        infl = 4
        if lemma.endswith("ior"):
          deponent = True
          vinf = lemma[:-3] + u"īrī"
          vperf = ""
          vsup = lemma[:-3] + u"ītum"
        elif lemma.endswith(u"iō"):
          vinf = lemma[:-2] + u"īre"
          vperf = lemma[:-2] + u"īvī"
          vsup = lemma[:-2] + u"ītum"
        else:
          errandpagemsg("WARNING: Bad lemma %s for 4th-conjugation verb" % lemma)
          return None, None
      elif not explicit_infl and explicit_stem:
        if lemma.endswith("or"):
          deponent = True
          if len(explicit_stem) != 2:
            errandpagemsg("WARNING: For verb lemma %s, wrong length of explicit stem %s" % (lemma, explicit_stem))
            return None, None
          vinf, vsup = explicit_stem
          vperf = ""
          if vinf.endswith(u"ī") and lemma[:-2] == vinf[:-1]:
            infl = 3
          elif vinf.endswith(u"ī") and lemma.endswith("ior") and lemma[:-3] == vinf[:-1]:
            infl = "io"
          elif vinf.endswith(u"ārī"):
            infl = 1
          elif vinf.endswith(u"ērī"):
            infl = 2
          elif vinf.endswith(u"īrī"):
            infl = 4
          else:
            errandpagemsg("WARNING: Unrecognized verb infinitive %s for lemma %s" % (vinf, lemma))
            return None, None
        elif lemma.endswith(u"ō"):
          if len(explicit_stem) != 3:
            errandpagemsg("WARNING: For verb lemma %s, wrong length of explicit stem %s" % (lemma, explicit_stem))
            return None, None
          vinf, vperf, vsup = explicit_stem
          if vinf.endswith(u"āre"):
            infl = 1
          elif vinf.endswith(u"ēre"):
            infl = 2
          elif vinf.endswith(u"īre"):
            infl = 4
          elif vinf.endswith("ere") and lemma.endswith(u"iō"):
            infl = "io"
          elif vinf.endswith("ere"):
            infl = 3
          elif (vinf.endswith("rre") or vinf.endswith("lle") or vinf.endswith("sse") or vinf.endswith("dare")):
            infl = "irreg"
          else:
            errandpagemsg("WARNING: Unrecognized verb infinitive %s for lemma %s" % (vinf, lemma))
            return None, None
      else:
        errandpagemsg("WARNING: For verb lemma %s, bad infl %s combined with explicit stem %s" % (lemma, explicit_infl, explicit_stem))
        return None, None

      if getparam(ht, "conj") != str(infl):
        continue

      def compare_principal_part(first, rest, value):
        values = [] if not value else value.split("/")
        no_macron_values = [remove_macrons(x) for x in values]
        actual_values = blib.fetch_param_chain(ht, first, rest)
        no_macron_actual_values = [remove_macrons(x) for x in actual_values]
        if no_macron_values != no_macron_actual_values:
          pagemsg("WARNING: Principal part mismatch for param=%s, saw %s, expected %s" % (
            rest, "/".join(actual_values), "/".join(values)))
          return False
        return True

      if not compare_principal_part("1", "head", lemma):
        continue
      if not compare_principal_part("2", "inf", vinf):
        continue
      if deponent:
        sups = vsup.split("/")
        perfs = []
        for sup in sups:
          if not sup.endswith("um"):
            errandpagemsg("WARNING: For verb lemma %s, bad deponent supine %s" % (lemma, sup))
            return None, None
          perfs.append(sup[:-2] + "us sum")
        if not compare_principal_part("3", "perf", "/".join(perfs)):
          continue
      else:
        if not compare_principal_part("3", "perf", vperf):
          continue
        if not compare_principal_part("4", "sup", vsup):
          continue

      frob_chain_exact(ht, ["1", "head"], lemma.split("/"), pagemsg, notes)
      frob_chain_exact(ht, ["2", "inf"], vinf.split("/"), pagemsg, notes)
      if deponent:
        frob_chain_exact(ht, ["3", "perf"], perfs, pagemsg, notes)
      else:
        frob_chain_exact(ht, ["3", "perf"], vperf.split("/"), pagemsg, notes)
        frob_chain_exact(ht, ["4", "sup"], vsup.split("/"), pagemsg, notes)

      for inflt in headword['infl_templates']:
        infltn = tname(inflt)
        if infltn not in lalib.la_verb_conj_templates:
          pagemsg("WARNING: Saw bad conjugation template for infl=%s verb %s: %s" % (
            infl, lemma, unicode(inflt)))
          continue

        def truncate_ending(val, expected_ending, parttype):
          if not val:
            return ""
          vals = val.split("/")
          stems = []
          for v in vals:
            if not v.endswith(expected_ending):
              errandpagemsg("WARNING: %s should end in -%s: %s" % (parttype, expected_ending, v))
              return None
            stems.append(v[:-len(expected_ending)])
          return "/".join(stems)

        if infl == "irreg":
          if infltn != "la-conj-irreg":
            pagemsg("WARNING: Saw mismatching conjugation template for infl=%s verb %s: %s" % (
              infl, lemma, unicode(inflt)))
            continue
          prefix = getparam(inflt, "2")
          if prefix:
            lemmaprefix = lemma[0:len(prefix)]
            if remove_macrons(lemmaprefix) != remove_macrons(prefix):
              pagemsg("WARNING: Saw prefix mismatch, actual %s != expected %s for lemma %s: %s" % (
                prefix, lemmaprefix, lemma, unicode(inflt)))
              continue
            frob_exact(inflt, "2", lemmaprefix, pagemsg, notes)
        else:
          if infl == 1:
            if infltn != "la-conj-1st":
              pagemsg("WARNING: Saw mismatching conjugation template for first-conjugation verb %s: %s" % (
                lemma, unicode(inflt)))
              continue
            if deponent:
              if not lemma.endswith("or"):
                errpagemsg("First-conjugation deponent lemma should end in -or: %s" % lemma)
                return None, None
              arg1 = lemma[:-2]
              if vsup == arg1 + u"ātum":
                arg2 = ["", arg1 + u"āt"]
              else:
                arg2 = truncate_ending(vsup, "um", "First-conjugation deponent supine")
                if arg2 is None:
                  return None, None
              arg3 = ""
            else:
              if not lemma.endswith(u"ō"):
                errpagemsg(u"First-conjugation lemma should end in -ō: %s" % lemma)
                return None, None
              arg1 = lemma[:-1]
              if vperf == arg1 + u"āvī":
                arg2 = ["", arg1 + u"āv"]
              else:
                arg2 = truncate_ending(vperf, u"ī", "First-conjugation perfect")
                if arg2 is None:
                  return None, None
              if vsup == arg1 + u"ātum":
                arg3 = ["", arg1 + u"āt"]
              else:
                arg3 = truncate_ending(vsup, "um", "First-conjugation supine")
                if arg3 is None:
                  return None, None
          else:
            if (infl == 2 and infltn != "la-conj-2nd" or
                infl == 3 and infltn != "la-conj-3rd" or
                infl == "io" and infltn != "la-conj-3rd-IO" or
                infl == 4 and infltn != "la-conj-4th"):
              pagemsg("WARNING: Saw mismatching conjugation template for infl=%s verb %s: %s" % (
                infl, lemma, unicode(inflt)))
              continue
            if deponent:
              if infl == 2:
                expected_ending = "eor"
              elif infl == 3:
                expected_ending = "or"
              else:
                expected_ending = "ior"
              if not lemma.endswith(expected_ending):
                errpagemsg("Infl=%s deponent lemma should end in -%s: %s" % (
                  infl, expected_ending, lemma))
                return None, None
              arg1 = lemma[:-len(expected_ending)]
              arg2 = truncate_ending(vsup, "um", "Infl=%s deponent supine" % infl)
              if arg2 is None:
                return None, None
              arg3 = ""
            else:
              if infl == 2:
                expected_ending = u"eō"
              elif infl == 3:
                expected_ending = u"ō"
              else:
                expected_ending = u"iō"
              if not lemma.endswith(expected_ending):
                errpagemsg("Infl=%s lemma should end in -%s: %s" % (
                  infl, expected_ending, lemma))
                return None, None
              arg1 = lemma[:-len(expected_ending)]
              arg2 = truncate_ending(vperf, u"ī", "Infl=%s perfect" % infl)
              if arg2 is None:
                return None, None
              arg3 = truncate_ending(vsup, "um", "Infl=%s supine" % infl)
              if arg3 is None:
                return None, None
          frob_exact(inflt, "1", arg1, pagemsg, notes)
          frob_exact(inflt, "2", arg2, pagemsg, notes)
          frob_exact(inflt, "3", arg3, pagemsg, notes)
          # FIXME, handle overrides

  secbody = "".join(unicode(x) for x in parsed_subsections)
  sections[j] = secbody + sectail
  return "".join(sections), notes

  #for t in parsed.filter_templates():
  #  origt = unicode(t)
  #
  #  if tn == "la-IPA":
  #    if not getparam(t, "1"):
  #      if remove_macrons(lemma) != lemma:
  #        eccl = getparam(t, "eccl")
  #        rmparam(t, "eccl")
  #        t.add("1", lemma)
  #        if eccl:
  #          t.add("eccl", eccl)
  #        notes.append("add pronunciation to {{la-IPA}}")
  #    else:
  #      frob_stem(t, "1", stem, pagemsg, notes)
  #  elif tn == "la-noun" and pos == "noun":
  #  elif tn in la_noun_decl_templates and pos == "noun":
  #    frob_stem(t, "1", stem, pagemsg, notes)
  #    frob_stem(t, "2", stem, pagemsg, notes)
  #    for override in la_noun_decl_overrides:
  #      frob_stem(t, override, stem, pagemsg, notes, split_slashes=True)
  #  elif tn == "la-adj-form" and pos == "adj":
  #    frob_stem(t, "1", stem, pagemsg, notes)
  #  elif tn == "la-num-form" and pos == "numadj":
  #    frob_stem(t, "1", stem, pagemsg, notes)
  #  elif tn in ["la-perfect participle", "la-future participle",
  #      "la-gerundive",
  #      "la-verb-form", "la-part-form", "la-decl-1&2",
  #      "la-decl-3rd-part"] and pos == "verb":
  #    frob_stem(t, "1", stem, pagemsg, notes)
  #  elif tn == "la-present participle" and pos == "verb":
  #    # la-present participle has a different format
  #    stems = stem
  #    if type(stems) is not list:
  #      stems = [stem]
  #    stems = [re.sub(u"[āē]ns$", "", st) for st in stems]
  #    for st in stems:
  #      frob_exact(t, "1", st, pagemsg, notes)
  #  elif tn == "inflection of":
  #    lang = getparam(t, "lang")
  #    if lang:
  #      lemma_param = "1"
  #      alt_param = "2"
  #    else:
  #      lang = getparam(t, "1")
  #      lemma_param = "2"
  #      alt_param = "3"
  #    if lang == "la":
  #      tlemma = getparam(t, lemma_param)
  #      talt = getparam(t, alt_param)
  #      if not talt:
  #        frob_exact(t, lemma_param, lemma, pagemsg, notes)
  #      elif remove_macrons(tlemma) == remove_macrons(talt):
  #        t.add(lemma_param, talt)
  #        t.add(alt_param, "")
  #        notes.append("moved alt param in {{inflection of|la}} to lemma")
  #        frob_exact(t, lemma_param, lemma, pagemsg, notes)
  #      else:
  #        pagemsg("WARNING: In %s, alt param != lemma param even aside from macrons" % origt)
  #        frob_exact(t, alt_param, lemma, pagemsg, notes)
  #
  #return unicode(parsed), notes


parser = blib.create_argparser("Clean up usage of macrons in Latin non-lemma forms")
parser.add_argument("--direcfile", help="File containing directives of lemmas to process.")
parser.add_argument("--dry-run", help="Just show what would be checked, don't actually check references.", action="store_true")
args = parser.parse_args()
start, end = blib.parse_start_end(args.start, args.end)

direcfile = args.direcfile.decode("utf-8")

lemmas = []

for line in codecs.open(direcfile, "r", "utf-8"):
  line = line.rstrip('\n')
  if line.startswith("*"):
    line = line[1:]
    msg("Need to investigate: %s" % line)
  if line.startswith("#"):
    continue
  line = re.sub(r" *\[.*\]$", "", line)
  parts = line.split(" ")
  if len(parts) == 2 and parts[0] in ["adv", "num", "phr", "prov"]:
    pass
  elif (len(parts) == 2 or len(parts) == 3) and parts[0] in [
      "n1", "n2", "n3", "n4", "n5", "pn1", "pn2", "pn3", "pn4", "pn5",
      "num1", "a1", "a3"
  ]:
    # noun or adjective
    if len(parts) == 3:
      pos, lemma, explicit_stem = parts
    else:
      pos, lemma = parts
      explicit_stem = None
    m = re.search("^(n|pn|a|num)([1-5])$", pos)
    code_to_pos = {"n": "noun", "pn": "propernoun", "a": "adj", "num": "numadj"}
    pos = code_to_pos[m.group(1)]
    infl = int(m.group(2))
  
    lemmas.append((pos, infl, lemma, explicit_stem))

    #def do_process_page(page, index, parsed):
    #  return process_page(index, page, pos, lemma, stem, args.save, args.verbose)
    #for index, page in get_references(lemma, start, end):
    #  stems = stem
    #  if type(stems) is not list:
    #    stems = [stems]
    #  for st in stems:
    #    no_macrons_stem = remove_macrons(st)
    #    assert len(no_macrons_stem) == len(st)
    #    if unicode(page.title()).startswith(no_macrons_stem):
    #      blib.do_edit(page, index, do_process_page, save=args.save, verbose=args.verbose)
    #      break
    #  else:
    #    # no break
    #    msg("Skipped %s for lemma %s because doesn't match stem(s) %s" % (
    #      unicode(page.title()), lemma, ", ".join(stems)))
  elif len(parts) == 2 and parts[0] in ["v1", "v4"]:
    # regular verb
    pos, lemma = parts
    m = re.search("^v([14])$", pos)
    infl = int(m.group(1))
    lemmas.append(("verb", infl, lemma, None))
  else:
    pos = "verb"
    stems_lemmas = []
    if len(parts) == 3:
      # deponent verb
      lemma, inf, supine = parts
      if lemma.startswith("*"):
        no_main = True
        lemma = lemma[1:]
      else:
        no_main = False
      if inf.startswith("*"):
        # FIXME
        inf = inf[1:]
      if supine.startswith("*"):
        # FIXME
        supine = supine[1:]
      if inf == "--":
        inf = ""
      if supine == "--":
        supine = ""
      lemmas.append(("verb", None, lemma, [inf, supine]))

      ## do the past passive and future active participles
      #if not supine.startswith("*") and not supine.startswith("--"):
      #  assert supine.endswith("um")
      #  stems_lemmas.append((supine[:-2], supine[:-2] + "us", True))
      #  stems_lemmas.append((supine[:-2] + u"ūr", supine[:-2] + u"ūrus", True))
      #if not no_main:
      #  # do the remaining two participles
      #  assert lemma.endswith(u"or") or lemma.endswith("itur")
      #  if inf.endswith(u"ārī"):
      #    short_part_stem = inf[:-3] + "a"
      #    long_part_stem = inf[:-2]
      #  elif inf.endswith(u"īrī"):
      #    short_part_stem = inf[:-3] + "ie"
      #    long_part_stem = inf[:-3] + u"iē"
      #  elif inf.endswith(u"ērī"):
      #    short_part_stem = inf[:-3] + "e"
      #    long_part_stem = inf[:-2]
      #  elif inf.endswith(u"ī") and lemma.endswith(u"iō"):
      #    short_part_stem = inf[:-1] + "ie"
      #    long_part_stem = inf[:-1] + u"iē"
      #  elif inf.endswith(u"ī") and lemma.endswith(u"it"):
      #    # impersonal -ī; don't know whether i-stem or not
      #    short_part_stem = [inf[:-1] + "e", inf[:-1] + "ie"]
      #    long_part_stem = [inf[:-1] + u"ē", inf[:-1] + u"iē"]
      #  else:
      #    assert inf.endswith(u"ī")
      #    short_part_stem = inf[:-1] + "e"
      #    long_part_stem = inf[:-1] + u"ē"
      #  if type(short_part_stem) is not list:
      #    short_part_stem = [short_part_stem]
      #  if type(long_part_stem) is not list:
      #    long_part_stem = [long_part_stem]
      #  for shstem, lostem in zip(short_part_stem, long_part_stem):
      #    stems_lemmas.append((shstem + "nt", lostem + "ns", True))
      #    stems_lemmas.append((shstem + "nd", shstem + "ndus", True))
      #
      #  # do the present stem
      #  if lemma.endswith(u"or"):
      #    m = re.search(u"^(.*?)([ei]?)or$", lemma)
      #    assert m
      #    if inf.endswith(u"ārī"):
      #      stem = m.group(1) + m.group(2)
      #    else:
      #      stem = m.group(1)
      #  else:
      #    m = re.search(u"^(.*?)([āēīi])tur$", lemma)
      #    assert m
      #    stem = m.group(1)
      #  stems_lemmas.append((stem, lemma, False))

    else:
      assert len(parts) == 4
      lemma, inf, perf, supine = parts
      if lemma.startswith("*"):
        no_main = True
        lemma = lemma[1:]
      else:
        no_main = False
      if inf.startswith("*"):
        # FIXME
        inf = inf[1:]
      if perf.startswith("*"):
        # FIXME
        perf = perf[1:]
      if supine.startswith("*"):
        # FIXME
        supine = supine[1:]
      if inf == "--":
        inf = ""
      if perf == "--":
        perf = ""
      if supine == "--":
        supine = ""
      lemmas.append(("verb", None, lemma, [inf, perf, supine]))
      ## do the past passive and future active participles
      #if not supine.startswith("*") and not supine.startswith("--"):
      #  assert supine.endswith("um")
      #  stems_lemmas.append((supine[:-2], supine[:-2] + "us", True))
      #  stems_lemmas.append((supine[:-2] + u"ūr", supine[:-2] + u"ūrus", True))
      ## do the perfect stem
      #if not perf.startswith("*") and not perf.startswith("--"):
      #  assert perf.endswith(u"ī") or perf.endswith("it")
      #  if perf.endswith(u"ī"):
      #    stems_lemmas.append((perf[:-1], lemma, False))
      #  else:
      #    # impersonal
      #    stems_lemmas.append((perf[:-2], lemma, False))
      #if not no_main:
      #  # do the remaining two participles
      #  assert lemma.endswith(u"ō") or lemma.endswith("t")
      #  if inf.endswith(u"āre"):
      #    short_part_stem = inf[:-3] + "a"
      #    long_part_stem = inf[:-2]
      #  elif inf.endswith(u"īre") or inf.endswith("ere") and lemma.endswith(u"iō"):
      #    short_part_stem = inf[:-3] + "ie"
      #    long_part_stem = inf[:-3] + u"iē"
      #  elif inf.endswith(u"ere") and lemma.endswith(u"it"):
      #    # impersonal -ere; don't know whether i-stem or not
      #    short_part_stem = [inf[:-3] + "e", inf[:-3] + "ie"]
      #    long_part_stem = [inf[:-3] + u"ē", inf[:-3] + u"iē"]
      #  else:
      #    assert inf.endswith("ere") or inf.endswith(u"ēre")
      #    short_part_stem = inf[:-3] + "e"
      #    long_part_stem = inf[:-3] + u"ē"
      #  if type(short_part_stem) is not list:
      #    short_part_stem = [short_part_stem]
      #  if type(long_part_stem) is not list:
      #    long_part_stem = [long_part_stem]
      #  for shstem, lostem in zip(short_part_stem, long_part_stem):
      #    stems_lemmas.append((shstem + "nt", lostem + "ns", True))
      #    stems_lemmas.append((shstem + "nd", shstem + "ndus", True))

      #  # do the present stem
      #  if lemma.endswith(u"ō"):
      #    m = re.search(u"^(.*?)([ei]?)ō$", lemma)
      #    assert m
      #    if inf.endswith(u"āre"):
      #      stem = m.group(1) + m.group(2)
      #    else:
      #      stem = m.group(1)
      #  else:
      #    m = re.search(u"^(.*?)([aei])t$", lemma)
      #    assert m
      #    stem = m.group(1)
      #  stems_lemmas.append((stem, lemma, False))

    #for stem, lemma, include_page in stems_lemmas:
    #  def do_process_page(page, index, parsed):
    #    return process_page(index, page, pos, lemma, stem, args.save, args.verbose)
    #  for index, page in get_references(lemma, start, end,
    #      include_page=include_page):
    #    no_macrons_stem = remove_macrons(stem)
    #    assert len(no_macrons_stem) == len(stem)
    #    if unicode(page.title()).startswith(no_macrons_stem):
    #      blib.do_edit(page, index, do_process_page, save=args.save, verbose=args.verbose)
    #    else:
    #      msg("Skipped %s for lemma %s because doesn't match stem %s" % (
    #        unicode(page.title()), lemma, stem))

for index, (pos, infl, lemma, explicit_stem) in blib.iter_items(lemmas, start, end,
    get_name=lambda lemmas: remove_macrons(lemmas[2])):
  def do_process_lemma(page, index, parsed):
    return process_lemma(index, page, pos, infl, lemma, explicit_stem, args.save, args.verbose)
  blib.do_edit(pywikibot.Page(site, remove_macrons(lemma)), index, do_process_lemma, save=args.save, verbose=args.verbose)
