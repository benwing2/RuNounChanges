#!/usr/bin/env python
# -*- coding: utf-8 -*-

# Templates:
#
# Nouns:
# -----
#
# aquila:
#
# {{la-noun|aquila<1>}}
# {{la-ndecl|aquila<1>}}
#
# abāctor:
#
# {{la-noun|abāctor<3>}}
# {{la-ndecl|abāctor<3>}}
#
# abaculus:
#
# {{la-noun|abaculus<2>}}
# {{la-ndecl|abaculus<2>}}
#
# abdōmen:
#
# {{la-noun|abdōmen<3>}}
# {{la-ndecl|abdōmen<3>}}
#
# abomāsum:
#
# {{la-noun|abomāsum<2>}}
# {{la-ndecl|abomāsum<2>}}
#
# accipiter:
#
# {{la-noun|accipiter<3>|g=m}}
# {{la-ndecl|accipiter<3>}}
#
# ȳ:
#
# {{la-noun|ȳ|g=f|indecl=y}}
#
# dē:
#
# {{la-noun|dē|g=f|indecl=y}}
#
# absinthium:
#
# {{la-noun|absinthium<2>}}
# {{la-ndecl|absinthium<2>}}
#
# lēns:
#
# {{la-noun|lēns<3>|g=f}}
# {{la-ndecl|lēns<3>}}
#
# diēs:
#
# {{la-noun|diēs<5>|g=m|g2=f}}
# {{la-ndecl|diēs<5>}}
#
# ōs:
#
# {{la-noun|ōs/ōr<3.N.I>}}
# {{la-ndecl|ōs/ōr<3.N.I>}}
#
# os:
#
# {{la-noun|os/oss<3.N.I>|gen_pl=ossium}}
# {{la-ndecl|os/oss<3.N.I>|gen_pl=ossium}}
#
# cōnsēnsus:
#
# {{la-noun|cōnsēnsus<4>}}
# {{la-ndecl|cōnsēnsus<4>}}
#
# comma:
#
# {{la-noun|comma<3>}}
# {{la-ndecl|comma<3>}}
#
# colon:
#
# {{la-noun|colon<2>}}
# {{la-ndecl|colon<2>}}
#
# gas:
#
# {{la-noun|gas/gas<3.N>}}
# {{la-ndecl|gas/gas<3.N>}}
#
# phoenīx:
#
# {{la-noun|phoenīx<3.I>|g=f}}
# {{la-ndecl|phoenīx<3.I>}}
# {{la-noun|phoenīx<3>|g=m}}
# {{la-ndecl|phoenīx<3>}}
#
# Proper nouns:
# -------------
#
# Belgium:
#
# {{la-proper noun|Belgium<2>}}
# {{la-ndecl|Belgium<2>}}
#
# Isrāēl:
#
# {{la-proper noun|((Isrāēl<0>,Isrāēl<3>))|g=m}}
# {{la-ndecl|((Isrāēl<0>,Isrāēl<3>))}}
#
# Abaddōn:
#
# {{la-proper noun|Abaddōn|g=m|indecl=1}}
#
# Andorra:
#
# {{la-proper noun|Andorra<1.loc>}}
# {{la-ndecl|Andorra<1.loc>}}
#
# Niger:
#
# {{la-proper noun|Niger/Nigr<2>}}
# {{la-ndecl|Niger/Nigr<2>}}
# {{la-proper noun|Niger/Nigr<3>|acc_sg=Nigrim|g=m}}
# {{la-ndecl|Niger/Nigr<3>|acc_sg=Nigrim}}
#
# Achilles:
#
# {{la-proper noun|Achilles/Achill<3>|g=m}}
# {{la-ndecl|Achilles/Achill<3>}}
#
# Pronouns:
# ---------
#
# is:
#
# {{head|la|pronoun}}
# {{la-adecl|is<irreg+>}}
#
# Verbs:
# ------
#
# līberō:
#
# {{la-verb|1+.p3inf.poet-sync-perf|līberō}}
# {{la-conj|1+.p3inf.poet-sync-perf|līberō}}
#
# ferō:
#
# {{la-verb|irreg|ferō}}
# {{la-conj|irreg|fero}}
#
# eō:
#
# {{la-verb|irreg.p3inf|eō}}
# {{la-conj|irreg.p3inf|eō}}
#
# for:
#
# {{la-verb|1+.p3inf|for}}
# {{la-conj|1+.p3inf|for}}
#
# abdīcō:
#
# {{la-verb|irreg|abdīcō}}
# {{la-conj|irreg|abdīcō}}
#
# abdō:
#
# {{la-verb|3|abdō|abdid|abdit}}
# {{la-conj|3|abdō|abdid|abdit}}
#
# alō:
#
# {{la-verb|3|alō|alu|alt/alit}}
# {{la-conj|3|alō|alu|alt/alit}}
#
# lingō:
#
# {{la-verb|3|lingō|linx|linct}}
# {{la-conj|3|lingō|linx|linct}}
#
# vērō:
#
# {{la-verb|1.nopass|vērō}}
# {{la-conj|1.nopass|vērō}}
#
# lābor:
#
# {{la-verb|3|lābor|lāps}}
# {{la-conj|3|lābor|lāps}}
#
# videō:
#
# {{la-verb|2.p3inf|videō|vīd|vīs}}
# {{la-conj|2.p3inf|videō|vīd|vīs}}
#
# Participles:
# ------------
#
# accūsāns:
#
# {{la-part|accūsāns}}
# {{la-adecl|accūsāns<3-P+>}}
#
# sapiēns:
#
# {{la-part|sapiēns}}
# {{la-adecl|sapiēns<3-P+>}}
#
# abditus:
#
# {{la-part|abditus}}
# {{la-adecl|abditus}}
#
# futūrus:
#
# {{la-part|futūrus}}
# {{la-adecl|futūrus}}
#
# gerendus:
#
# {{la-part|gerendus}}
# {{la-adecl|gerendus}}
#
# Prefixes:
# ---------
#
# ā-:
#
# {{head|la|prefix|head=ā-}}
#
# Prepositions:
# -------------
#
# in:
#
# {{la-prep|accusative|ablative}}
#
# Adjectives:
# -----------
#
# phoenīx:
#
# {{la-adj|phoenīx<+.-I>}}
# {{la-adecl|phoenīx<+.-I>}}
#
# incōmptus:
#
# {{la-adj|incomptus|comp=incomptior}}
# {{la-adecl|incomptus}}
#
# Adverbs:
# --------
#
# lentē:
#
# {{la-adv|lentē}}
#
# ferē:
#
# {{la-adv|ferē|-}}
#
# Interjections:
# --------------
#
# ēn:
#
# {{la-interj|ēn}}
#
# tax:
#
# {{head|la|interjection}}
#
# Letters:
# --------
#
# o:
#
# {{head|la|letter}}
#
# Abbreviations:
# --------------
#
# JUL:
#
# {{head|la|abbreviation}}
#
# Adjective forms:
# ----------------
#
# {{la-adj-form|abdominālēs}}
# # {{inflection of|abdominālis||nom|m|p|lang=la}}
# # {{inflection of|abdominālis||nom|f|p|lang=la}}
# # {{inflection of|abdominālis||acc|m|p|lang=la}}
# # {{inflection of|abdominālis||acc|f|p|lang=la}}
# # {{inflection of|abdominālis||voc|m|p|lang=la}}
# # {{inflection of|abdominālis||voc|f|p|lang=la}}
#
# Verb forms:
# -----------
#
# {{la-verb-form|abdūce}}
#
# # {{inflection of|abdūcō||2|s|pres|actv|impr|lang=la}}
#
# Noun forms:
# -----------
#
# {{la-noun-form|diē}}
#
# # {{inflection of|diēs||abl|s|lang=la|nodot=1}} (&quot;[[day]]&quot;).
#
# Participle forms:
# -----------------
#
# abrāse:
#
# {{la-part-form|abrāse}}
#
# # {{inflection of|abrāsus||voc|m|s|lang=la}}
#
# Pronoun forms:
# --------------
#
# mī:
#
# {{la-pronoun-form|mī}}
# {{head|la|pronoun form|head=mī}}
#


# FIXME:
#
# 1. DONE: Pronunciation templates.
# 2. DONE: Make sure lang and pos in {{head}} agree.
# 3. DONE: Verb overrides.
# 4. * before supine and perfect (maybe not needed).
# 5. DONE: For participles, check the etymology section to make sure the lemma
#    is correct.
# 6. DONE: Numbers, phrases, etc.
# 7. DONE: Handle multipart tag sets.
# 8. Handle irregular verb conjugations, which may have prefixes.
# 9. MOSTLY DONE: Review latin-macrons.txt against http://www.alatius.com/latin/bennetthidden.html, which corrects Bennett. Ask JohnC5 about this.
# 10. DONE?: Pluralia tantum lemmas, e.g. nuptiae.
# 11. DONE: If {{head|...}} with missing head= param, add it.
# 12. Add note about hidden quantity to pronunciation section if potential hidden quantity is present.
# 13. DONE: If pronun begins with lowercase letter but substitution begins with
#     capital letter, allow it.
#
# Examples of disagreements with Bennett:
#
# Bennett: dēlīctus/relīctus (dēlinquō/relinquō), fīctus (fingō), pīctus (pingō), trāctus (trahō); Allen: dēlĭctus/relĭctus, fĭctus, pĭctus, trăctus
# Bennett: ārdeō, ārsī, ārsūrus; Michelson: ărd-/ărs- in Lindsay, Sommer, Brugmann
# Bennett: fīrmus; Michelson: fĭrmus or fīrmus
# Bennett: ūlna; Michelson: ŭlna
# Bennett: ūstus (ūrō); Michelson: ŭstus
# Bennett: ūsque, nūsque, quoūsque; Buck: ŭsque, etc.
# Bennett: cŭnctor: Michelson: cūnctor
# Bennett: not all vowels are lengthened before -nct; Michelson, Allen: all vowels lengthened before -nct
# Bennett: earlier version: most vowels long before -gn; later version changed his mind

# Clean up use of macrons in Latin lemmas.

import pywikibot, re, sys, codecs, argparse

import blib
from blib import getparam, rmparam, msg, errandmsg, site, tname

import lalib
from lalib import remove_macrons

default_comment = "update macrons in '%s': if before two cons, per Bennett corrected by Allen and Michelson"

def raw_frob_value(t, param, oldval, newval, pagemsg, notes, comment):
  no_macrons_oldval = remove_macrons(oldval)
  no_macrons_newval = remove_macrons(newval)
  if no_macrons_oldval != no_macrons_newval:
    pagemsg("WARNING: Unable to match value %s in param %s against replacement %s: %s" % (
      oldval, param, newval, unicode(t)
    ))
    return "mismatch"
  if oldval != newval:
    pagemsg("Changed value %s to %s" % (oldval, newval))
    notes.append(comment % tname(t))
    return "changed"
  return "unchanged"


# Return True if changed.
def frob_param(t, param, stem_or_exact, is_exact, pagemsg, notes, comment, split_slashes=False, no_warn=False, add_if_needed=False, allow_case_difference=False):
  origt = unicode(t)
  origval = getparam(t, param)
  if split_slashes:
    vals = origval.split("/")
  else:
    vals = [origval]
  newvals = []
  for val in vals:
    no_macrons_val = remove_macrons(val)
    if allow_case_difference:
      no_macrons_val = no_macrons_val.lower()
    if type(stem_or_exact) is not list:
      stem_or_exact = [stem_or_exact]
    for st in stem_or_exact:
      no_macrons_st = remove_macrons(st)
      if allow_case_difference:
        no_macrons_st = no_macrons_st.lower()
      if is_exact:
        if no_macrons_val == no_macrons_st:
          newvals.append(st)
          break
      else:
        if no_macrons_val.startswith(no_macrons_st):
          if len(no_macrons_st) == len(st) and len(no_macrons_val) == len(val):
            newvals.append(st + val[len(st):])
            break
          else:
            # FIXME, If allow_case_difference, synchronize_stems() should
            # be passed that flag in and should allow for case differences.
            full_stem_len = lalib.synchronize_stems(val, st)
            if full_stem_len is False:
              pagemsg("WARNING: Unable to synchronize param %s value %s with replacement stem %s" % (
                param, val, st))
            else:
              newvals.append(st + val[full_stem_len:])
              break
    else:
      # no break
      if not val and add_if_needed:
        nonempty = [x for x in stem_or_exact if x]
        if nonempty:
          val = nonempty[0]
        else:
          pagemsg("WARNING: Unable to add blank value to param %s: %s" % (
            param, unicode(t)))
      elif val or not no_warn:
        if is_exact:
          pagemsg("WARNING: Unable to match value %s in param %s against replacement(s) %s: %s" % (
            val, param, ",".join(stem_or_exact), unicode(t)))
        else:
          pagemsg("WARNING: Unable to match value %s in param %s against replacement stem(s) %s: %s" % (
            val, param, ",".join(stem_or_exact), unicode(t)))
      newvals.append(val)
  newval = "/".join(newvals)
  if newval != origval:
    t.add(param, newval)
    pagemsg("Replaced %s with %s" % (origt, unicode(t)))
    notes.append(comment % tname(t))
    return True
  return False

# Return True if changed.
def frob_stem(t, param, stem, pagemsg, notes, comment, split_slashes=False, no_warn=False):
  return frob_param(t, param, stem, False, pagemsg, notes, comment, split_slashes=split_slashes,
      no_warn=no_warn)

# Return True if changed.
def frob_exact(t, param, newval, pagemsg, notes, comment, split_slashes=False,
    no_warn=False, add_if_needed=False, allow_case_difference=False):
  return frob_param(t, param, newval, True, pagemsg, notes, comment,
    split_slashes=split_slashes, no_warn=no_warn, add_if_needed=add_if_needed,
    allow_case_difference=allow_case_difference)

# Return True if anything changed.
def frob_chain_stem(t, param, stem, pagemsg, notes, comment, split_slashes=False, no_warn=False):
  changed = False
  if type(param) is list:
    first, rest = param
  else:
    first = param
    rest = param
  if first:
    if frob_stem(t, first, stem, pagemsg, notes, comment, split_slashes=split_slashes,
        no_warn=no_warn):
      changed = True
  num = 2
  while getparam(t, "%s%s" % (rest, num)):
    if frob_stem(t, "%s%s" % (rest, num), stem, pagemsg, notes, comment,
        split_slashes=split_slashes, no_warn=no_warn):
      changed = True
    num += 1
  return changed

# Return True if anything changed.
def frob_chain_exact(t, param, newval, pagemsg, notes, comment, split_slashes=False,
    no_warn=False, add_if_needed=False):
  changed = False
  if type(param) is list:
    first, rest = param
  else:
    first = param
    rest = param
  if first:
    if frob_exact(t, first, newval, pagemsg, notes, comment,
        split_slashes=split_slashes, no_warn=no_warn, add_if_needed=add_if_needed):
      changed = True
  num = 2
  while getparam(t, "%s%s" % (rest, num)):
    if frob_exact(t, "%s%s" % (rest, num), newval, pagemsg, notes, comment,
        split_slashes=split_slashes, no_warn=no_warn):
      changed = True
    num += 1
  return changed

def find_tag_sets_for_form(args, form):
  tag_sets = []
  for slot, formspec in args.iteritems():
    forms = formspec.split(",")
    if form in forms:
      tag_sets.append(lalib.slot_to_tag_set(slot))
  return tag_sets

# Return True if changed.
def process_pronun_template(t, lemma, pagemsg, notes, comment):
  if not getparam(t, "1"):
    if remove_macrons(lemma) != lemma:
      eccl = getparam(t, "eccl")
      rmparam(t, "eccl")
      t.add("1", lemma)
      if eccl:
        t.add("eccl", eccl)
      notes.append("add pronunciation to {{la-IPA}}")
      return True
  else:
    return frob_exact(t, "1", lemma, pagemsg, notes, comment,
        allow_case_difference=True)

def process_pronun_templates(pronun_section, lemma, pagemsg, notes, comment):
  if not pronun_section:
    return
  pronun_templates = pronun_section['pronun_templates']
  if len(pronun_templates) > 1:
    pagemsg("WARNING: Multiple pronunciation templates, not changing: %s" %
      ",".join(unicode(t) for t in pronun_templates))
  elif len(pronun_templates) == 1:
    pront = pronun_templates[0]
    origpront = unicode(pront)
    pagetitle = remove_macrons(lemma)
    headwords = set(x for hw in pronun_section['headwords'] for x in lalib.la_get_headword_from_template(hw['head_template'], pagetitle, pagemsg))
    if len(list(headwords)) > 1:
      pagemsg("WARNING: One pronunciation template %s but multiple headword templates with different headwords %s, not changing: %s" %
        (origpront, ",".join(headwords), ",".join(unicode(hw['head_template']) for hw in pronun_section['headwords'])))
    elif process_pronun_template(pront, lemma, pagemsg, notes, comment):
      if len(pronun_section['headwords']) > 1:
        pagemsg("WARNING: Multiple headwords for changed pronunciation template (originally %s, changed to %s), check manually: %s" % (
          origpront, unicode(pront),
          ",".join(unicode(hw['head_template']) for hw in pronun_section['headwords'])))

def do_process_form(index, page, lemma, formind, formval, pos, tag_sets_to_process, progargs):
  pagetitle = unicode(page.title())

  def pagemsg(txt):
    msg("Page %s %s: form %s %s: %s" % (index, lemma, formind, formval, txt))

  def errandpagemsg(txt):
    errandmsg("Page %s %s: form %s %s: %s" % (index, lemma, formind, formval, txt))

  def expand_text(tempcall):
    return blib.expand_text(tempcall, pagetitle, pagemsg, progargs.verbose)

  if "[" in formval:
    pagemsg("Skipping form value %s with link in it" % formval)
    return None, None

  page = pywikibot.Page(site, pagetitle)
  if not page.exists():
    pagemsg("Skipping form value %s, page doesn't exist" % formval)
    return None, None

  if pos == "verbform":
    expected_head_template = "la-verb-form"
    expected_pos = "verb form"
    expected_header_pos = "Verb"
  elif pos == "adjform":
    expected_head_template = "la-adj-form"
    expected_pos = "adjective form"
    expected_header_pos = "Adjective"
  elif pos == "nounform":
    expected_head_template = "la-noun-form"
    expected_pos = "noun form"
    expected_header_pos = "Noun"
  elif pos == "propernounform":
    expected_head_template = "la-proper noun-form"
    expected_pos = "proper noun form"
    expected_header_pos = "Proper noun"
  elif pos == "pronounform":
    expected_head_template = "la-pronoun-form"
    expected_pos = "pronoun form"
    expected_header_pos = "Pronoun"
  elif pos == "detform":
    expected_head_template = "la-det-form"
    expected_pos = "determiner form"
    expected_header_pos = "Determiner"
  elif pos == "partform":
    expected_head_template = "la-part-form"
    expected_pos = "participle form"
    expected_header_pos = "Participle"
  elif pos == "numform":
    expected_head_template = "la-num-form"
    expected_pos = "numeral form"
    expected_header_pos = "Numeral"
  elif pos == "sufform":
    expected_head_template = "la-suffix-form"
    expected_pos = "suffix form"
    expected_header_pos = "Suffix"
  else:
    raise ValueError("Unrecognized part of speech %s" % pos)

  pagemsg("Processing")

  retval = lalib.find_heads_and_defns(unicode(page.text), pagemsg)
  if retval is None:
    return None, None

  (
    sections, j, secbody, sectail, has_non_latin, subsections,
    parsed_subsections, headwords, pronun_sections, etym_sections
  ) = retval

  notes = []

  tag_sets_to_process = True if tag_sets_to_process is True else (
    sorted(tag_sets_to_process)
  )
  frozenset_tag_sets_to_process = True if tag_sets_to_process is True else set(
    frozenset(tag_set) for tag_set in tag_sets_to_process
  )
  for headword in headwords:
    ht = headword['head_template']
    tn = tname(ht)
    saw_infl = False
    good_tag_sets = []
    saw_other_infl = False
    bad_tag_sets = []
    other_lemmas = []
    found_head = False

    if tn == "head":
      if getparam(ht, "1") != "la":
        errandpagemsg("WARNING: Wrong-language {{head}} template in Latin section: %s" % unicode(ht))
        continue
      head_pos = getparam(ht, "2")
      if head_pos != expected_pos:
        pagemsg("Skipping incorrect part of speech %s: %s" % (head_pos, unicode(ht)))
        continue
      head_param = "head"
      found_head = True
      add_if_needed = True

    if tn == expected_head_template:
      head_param = "1"
      found_head = True
      add_if_needed = False

    if not found_head:
      continue

    if headword['header'] != expected_header_pos:
      pagemsg("WARNING: Bad section header %s != %s for headword template %s" % (
        headword['header'], expected_header_pos, unicode(ht)))

    for t in headword['infl_of_templates']:
      lang = getparam(t, "lang")
      if lang:
        lemma_param = 1
      else:
        lang = getparam(t, "1")
        lemma_param = 2
      if lang != "la":
        errandpagemsg("WARNING: In Latin section, found {{inflection of}} for different language %s: %s" % (
          lang, unicode(t)))
        continue
      actual_lemma = getparam(t, str(lemma_param))
      if remove_macrons(actual_lemma) == remove_macrons(lemma):
        # fetch tags
        tags = []
        for param in t.params:
          pname = unicode(param.name).strip()
          pval = unicode(param.value).strip()
          if re.search("^[0-9]+$", pname):
            if int(pname) >= lemma_param + 2:
              if pval:
                tags.append(pval)
        # split tags into tag sets (which may be multipart) and further
        # split any multipart tag sets into component tag sets
        tag_sets = [tag_set
          for maybe_multipart_tag_set in lalib.split_tags_into_tag_sets(tags)
          for tag_set in lalib.split_multipart_tag_set(maybe_multipart_tag_set)
        ]
        for tag_set in tag_sets:
          canon_tag_set = lalib.canonicalize_tag_set(tag_set)
          if tag_sets_to_process is True or frozenset(canon_tag_set) in frozenset_tag_sets_to_process:
            saw_infl = True
            good_tag_sets.append(canon_tag_set)
          else:
            expected_tag_sets = "|".join(lalib.combine_tag_set_group(tag_sets_to_process))
            pagemsg("Found {{inflection of}} for correct lemma but wrong tag set %s (expected %s): %s" % (
              "|".join(canon_tag_set), expected_tag_sets, unicode(t)))
            saw_other_infl = True
            bad_tag_sets.append(canon_tag_set)
      else:
        pagemsg("Found {{inflection of}} for different lemma %s: %s" % (
          actual_lemma, unicode(t)))
        saw_other_infl = True
        other_lemmas.append(actual_lemma)

    if saw_infl and saw_other_infl:
      good_tag_set_str = ",".join("|".join(tag_set) for tag_set in good_tag_sets)
      bad_msgs = []
      if other_lemmas:
        bad_msgs.append("different lemma(s) %s" % ",".join(other_lemmas))
      if bad_tag_sets:
        bad_msgs.append("wrong tag set(s) %s" % ",".join("|".join(tag_set) for tag_set in bad_tag_sets))
      pagemsg("WARNING: Found mixture of inflection-of templates for good tag set(s) %s and inflection-of templates for %s, won't frob" % (
        good_tag_set_str, " and ".join(bad_msgs)))
      continue

    if not saw_infl:
      continue

    frob_exact(ht, head_param, formval, pagemsg, notes, default_comment,
        add_if_needed=add_if_needed)
    for t in headword['infl_of_templates']:
      lang = getparam(t, "lang")
      if lang:
        lemma_param = 1
      else:
        lang = getparam(t, "1")
        lemma_param = 2
      assert lang == "la"
      changed = frob_exact(t, str(lemma_param), lemma, pagemsg, notes, default_comment)
      if getparam(t, str(lemma_param + 1)):
        t.add(str(lemma_param + 1), "")
        if not changed:
          notes.append("remove alt form of {{inflection of}}")

    process_pronun_templates(headword['pronun_section'], formval, pagemsg, notes,
        default_comment)

  secbody = "".join(unicode(x) for x in parsed_subsections)
  sections[j] = secbody + sectail
  return "".join(sections), notes

def process_form(index, lemma, formind, formval, pos, tag_sets_to_process, progargs):
  def pagemsg(txt):
    msg("Page %s %s: form %s %s: %s" % (index, lemma, formind, formval, txt))
  def handler(page, index, parsed):
    return do_process_form(index, page, lemma, formind, formval, pos, tag_sets_to_process, progargs)
  if "[" in formval:
    pagemsg("Skipping form value %s with link in it" % formval)
  else:
    blib.do_edit(pywikibot.Page(site, remove_macrons(formval)), index, handler, save=progargs.save, verbose=progargs.verbose, diff=progargs.diff)

def process_all_forms(args, index, lemma, pos, progargs):
  if progargs.skip_forms:
    return

  single_forms_to_process = []
  for key, form in args.iteritems():
    for single_form in form.split(","):
      single_forms_to_process.append((key, single_form))

  for formind, (key, formval) in blib.iter_items(
      single_forms_to_process, get_name=lambda x: x[1]):
    if not progargs.n_forms or formind <= progargs.n_forms:
      process_form(index, lemma, formind, formval, pos,
          find_tag_sets_for_form(args, formval), progargs)

def do_process_participle(index, page, lemma, formind, formval, explicit_stem,
    progargs):
  pagetitle = unicode(page.title())

  def pagemsg(txt):
    msg("Page %s %s: form %s %s: %s" % (index, lemma, formind, formval, txt))

  def errandpagemsg(txt):
    errandmsg("Page %s %s: form %s %s: %s" % (index, lemma, formind, formval, txt))

  def expand_text(tempcall):
    return blib.expand_text(tempcall, pagetitle, pagemsg, progargs.verbose)

  if "[" in formval:
    pagemsg("Skipping form value %s with link in it" % formval)
    return None, None

  page = pywikibot.Page(site, pagetitle)
  if not page.exists():
    pagemsg("Skipping form value %s, page doesn't exist" % formval)
    return None, None

  if formval.endswith("ns"):
    if explicit_stem:
      expected_decl_arg = "%s/%s<3-P+>" % (formval, explicit_stem)
    else:
      expected_decl_arg = formval + "<3-P+>"
  else:
    if not formval.endswith("us"):
      pagemsg("WARNING: Bad participle form %s, wrong ending" % formval)
      return None, None
    expected_decl_arg = formval

  pagemsg("Processing")

  retval = lalib.find_heads_and_defns(unicode(page.text), pagemsg)
  if retval is None:
    return None, None

  (
    sections, j, secbody, sectail, has_non_latin, subsections,
    parsed_subsections, headwords, pronun_sections, etym_sections
  ) = retval

  notes = []

  for headword in headwords:
    ht = headword['head_template']
    tn = tname(ht)
    saw_infl = False
    saw_other_infl = False
    found_head = False

    if tn == "head":
      if getparam(ht, "1") != "la":
        errandpagemsg("WARNING: Wrong-language {{head}} template in Latin section: %s" % unicode(ht))
        continue
      head_pos = getparam(ht, "2")
      if head_pos != "participle":
        pagemsg("Skipping incorrect part of speech %s: %s" % (head_pos, unicode(ht)))
        continue
      param_to_frob = "head"
      value_to_frob = formval
      found_head = True

    if tn == "la-part":
      param_to_frob = "1"
      if explicit_stem:
        value_to_frob = "%s/%s" % (formval, explicit_stem)
      else:
        value_to_frob = formval
      found_head = True

    if not found_head:
      continue

    # Make sure there's an etym section mentioning the correct lemma and
    # no others.
    if not headword['etym_section']:
      pagemsg("WARNING: Missing etymology section for participle, don't know if it's for the correct verb, skipping")
      continue
    parsed = parsed_subsections[headword['etym_section']['subsection']]
    saw_lemma_in_etym = False
    saw_wrong_lemma_in_etym = False
    lemma_templates_in_etym = []
    for et in parsed.filter_templates():
      etn = tname(et)
      if etn == "m":
        actual_lemma = getparam(et, "2")
        if remove_macrons(lemma) == remove_macrons(actual_lemma):
          saw_lemma_in_etym = True
          lemma_templates_in_etym.append(et)
        else:
          pagemsg("WARNING: Saw wrong lemma %s != %s in Etymology section for participle: %s" % (
            actual_lemma, lemma, unicode(et)))
          saw_wrong_lemma_in_etym = True
    if saw_lemma_in_etym and saw_wrong_lemma_in_etym:
      pagemsg("WARNING: Saw both correct and wrong lemma in Etymology section for participle, skipping")
      continue
    if saw_wrong_lemma_in_etym:
      continue
    if not saw_lemma_in_etym:
      pagemsg("WARNING: Didn't see any lemma in Etymology section for participle, don't know if it's for correct verb, skipping")
      continue

    for et in lemma_templates_in_etym:
      frob_exact(et, "2", lemma, pagemsg, notes, default_comment)
    frob_exact(ht, param_to_frob, value_to_frob, pagemsg, notes, default_comment)

    for inflt in headword['infl_templates']:
      infltn = tname(inflt)
      if infltn != "la-adecl":
        pagemsg("WARNING: Saw bad declension template for participle: %s" % (
          unicode(inflt)))
        continue
      frob_exact(inflt, "1", expected_decl_arg, pagemsg, notes, default_comment)

      args = lalib.generate_adj_forms(unicode(inflt), errandpagemsg, expand_text)
      if args is None:
        return None, None

      process_all_forms(args, "%s.%s" % (index, formind), formval, "partform", progargs)

    process_pronun_templates(headword['pronun_section'], formval, pagemsg, notes,
        default_comment)

  secbody = "".join(unicode(x) for x in parsed_subsections)
  sections[j] = secbody + sectail
  return "".join(sections), notes

def process_participle(index, lemma, formind, formval, explicit_stem, progargs):
  def handler(page, index, parsed):
    return do_process_participle(index, page, lemma, formind, formval,
        explicit_stem, progargs)
  blib.do_edit(pywikibot.Page(site, remove_macrons(formval)), index, handler, save=progargs.save, verbose=progargs.verbose, diff=progargs.diff)

def frob_nominal_lemma_spec(ht, lemmaspec, stem, pagemsg, notes, comment):
  if "((" in lemmaspec or " " in lemmaspec or "<" in lemmaspec or "/" in lemmaspec:
    if frob_exact(ht, "1", lemmaspec, pagemsg, notes, comment):
      return "changed"
    else:
      return "nochange"
  param1 = getparam(ht, "1")
  if "((" in param1:
    pagemsg("WARNING: (( in first param of nominal template, don't know how to handle: %s" % unicode(ht))
    return "fail"
  elif " " in param1:
    pagemsg("WARNING: Space in first param of nominal template, don't know how to handle: %s" % unicode(ht))
    return "fail"
  else:
    m = re.search("^(.*)<([^<>]*?)>$", param1)
    if m:
      head_lemma, head_decl = m.groups()
    else:
      head_lemma = param1
      head_decl = ""
    if "<" in head_lemma:
      pagemsg("WARNING: Non-final < in first param of nominal template, don't know how to handle: %s" % unicode(ht))
      return "fail"
    else:
      if "/" in head_lemma:
        head_lemma, head_stem = head_lemma.split("/")
      else:
        head_stem = None
      changed = False
      retval = raw_frob_value(ht, "1", head_lemma, lemmaspec, pagemsg, notes, comment)
      if retval == "mismatch":
        return "fail"
      if retval == "changed":
        changed = True
      if head_stem:
        retval = raw_frob_value(ht, "1", head_stem, stem or "", pagemsg, notes, comment)
        if retval == "mismatch":
          return "fail"
        if retval == "changed":
          changed = True
      if changed:
        oright = unicode(ht)
        if head_decl:
          head_decl = "<%s>" % head_decl
        if stem:
          ht.add("1", "%s/%s%s" % (lemmaspec, stem, head_decl))
        else:
          ht.add("1", "%s%s" % (lemmaspec, head_decl))
        pagemsg("Replaced %s with %s" % (oright, unicode(ht)))
        return "changed"
      return "nochange"

def do_process_lemma(index, page, pos, explicit_infl, lemmaspec, lemma, explicit_stem, progargs):
  pagetitle = unicode(page.title())
  def pagemsg(txt):
    msg("Page %s %s: %s" % (index, pagetitle, txt))

  def errandpagemsg(txt):
    errandmsg("Page %s %s: %s" % (index, pagetitle, txt))

  def expand_text(tempcall):
    return blib.expand_text(tempcall, pagetitle, pagemsg, progargs.verbose)

  # If the participle's lemma is supplied, use do_process_participle(),
  # which checks (and if necessary updates) the lemma mention in the Etymology
  # section.
  if pos == "part" and type(explicit_stem) is list:
    explicit_stem, paramlemma = explicit_stem
    return do_process_participle(index, page, paramlemma, 1, lemma,
        explicit_stem, progargs)

  pagemsg("Processing")

  retval = lalib.find_heads_and_defns(unicode(page.text), pagemsg)
  if retval is None:
    return None, None

  (
    sections, j, secbody, sectail, has_non_latin, subsections,
    parsed_subsections, headwords, pronun_sections, etym_sections
  ) = retval

  notes = []

  found_any_matching_head = False

  for headword in headwords:
    ht = headword['head_template']
    tn = tname(ht)

    found_head_template = False
    found_matching_head = False

    if tn == "head":
      if getparam(ht, "1") != "la":
        errandpagemsg("WARNING: Wrong-language {{head}} template in Latin section: %s" % unicode(ht))
        continue

      pos_to_full_pos = {
        "noun": "noun",
        "propernoun": "proper noun",
        "pronoun": "pronoun",
        "adj": "adjective",
        "det": "determiner",
        "part": "participle",
        "adv": "adverb",
        "phr": "phrase",
        "prep": "preposition",
        "prov": "proverb", 
        "verb": "verb",
        "numnoun": "numeral",
        "numadj": "numeral",
        "sufnoun": "suffix",
        "sufadj": "suffix",
      }
      if getparam(ht, "2") == pos_to_full_pos[pos]:
        frob_exact(ht, "head", lemma, pagemsg, notes, default_comment,
            add_if_needed=True)
        found_head_template = True
        found_matching_head = True

    if pos == "adv" and tn == "la-adv":
      found_matching_head = True
      frob_exact(ht, "1", lemma, pagemsg, notes, default_comment)
      stem, is_stem = lalib.infer_adv_stem(lemma)
      frob_stem(ht, "2", stem, pagemsg, notes, default_comment, no_warn=True)
      frob_stem(ht, "3", stem, pagemsg, notes, default_comment, no_warn=True)
      frob_chain_stem(ht, "comp", stem, pagemsg, notes, default_comment, no_warn=True)
      frob_chain_stem(ht, "sup", stem, pagemsg, notes, default_comment, no_warn=True)

    elif pos == "phr" and tn == "la-phrase":
      found_matching_head = True
      frob_exact(ht, "head", lemma, pagemsg, notes, default_comment)

    elif pos == "prep" and tn == "la-prep":
      found_matching_head = True
      frob_exact(ht, "1", lemma, pagemsg, notes, default_comment)

    elif (
      pos == "noun" and (found_head_template or tn == "la-noun") or
      pos == "propernoun" and (found_head_template or tn == "la-proper noun") or
      pos == "numnoun" and (found_head_template or tn == "la-num-noun") or
      pos == "sufnoun" and (found_head_template or tn == "la-suffix-noun")
    ):
      ending_re = u"(a|ās|ē|ēs|ae|us|um|os|on|ī|is)"
      if re.search(ending_re + "$", lemma):
        inferred_stem = re.sub(u"^(.*?)%s$" % ending_re, r"\1", lemma)
      else:
        inferred_stem = lalib.infer_3rd_decl_stem(lemma)
      stem = explicit_stem or inferred_stem

      if tn in ["la-noun", "la-proper noun", "la-num-noun", "la-suffix-noun"]:
        if frob_nominal_lemma_spec(ht, lemmaspec, explicit_stem, pagemsg, notes,
            default_comment) == "fail":
          continue

        for override in lalib.la_noun_decl_overrides:
          frob_stem(ht, override, stem, pagemsg, notes, default_comment,
              split_slashes=True, no_warn=True)

      found_matching_head = True

      for inflt in headword['infl_templates']:
        if frob_nominal_lemma_spec(inflt, lemmaspec, explicit_stem, pagemsg, notes,
            default_comment) == "fail":
          continue

        for override in lalib.la_noun_decl_overrides:
          frob_stem(inflt, override, stem, pagemsg, notes, default_comment,
              split_slashes=True, no_warn=True)

        args = lalib.generate_noun_forms(unicode(inflt), errandpagemsg, expand_text)
        if args is None:
          return None, None

        process_all_forms(args, index, lemma,
          pos == "propernoun" and "propernounform" or
          pos == "numnoun" and "numform" or
          pos == "sufnoun" and "sufform" or
          "nounform",
          progargs
        )

    elif (
      pos == "adj" and (found_head_template or tn in lalib.la_adj_headword_templates) or
      pos == "pronoun" and (found_head_template or tn == "la-pronoun") or
      pos == "det" and (found_head_template or tn == "la-det") or
      pos == "part" and (found_head_template or tn == "la-part") or
      pos == "numadj" and (found_head_template or tn == "la-num-adj") or
      pos == "sufadj" and (found_head_template or tn == "la-suffix-adj")
    ):
      if not found_head_template:
        ending_re = u"(us|ī|er|ur|is|ēs)"
        if re.search(ending_re + "$", lemma):
          inferred_stem = re.sub(u"^(.*?)%s$" % ending_re, r"\1", lemma)
        else:
          inferred_stem = lalib.infer_3rd_decl_stem(lemma)
        stem = explicit_stem or inferred_stem

        if tn in ["la-adj", "la-adj-comp", "la-adj-sup", "la-pronoun", "la-det",
            "la-part", "la-num-adj", "la-suffix-adj"]:
          if frob_nominal_lemma_spec(ht, lemmaspec, explicit_stem, pagemsg, notes,
              default_comment) == "fail":
            continue

          if tn == "la-adj-comp":
            if lemma.endswith("ior"):
              base = lemma[:-3]
              frob_stem(ht, "pos", base, pagemsg, notes, default_comment, no_warn=True)
          elif tn == "la-adj-sup":
            if lemma.endswith("issimus"):
              base = lemma[:-7]
            if lemma.endswith("rimus"):
              base = lemma[:-5]
            else:
              base = None
            if base:
              frob_stem(ht, "pos", base, pagemsg, notes, default_comment)
          else:
            frob_chain_stem(ht, "comp", stem, pagemsg, notes, default_comment,
                no_warn=True)
            frob_chain_stem(ht, "sup", stem, pagemsg, notes, default_comment,
                no_warn=True)
            frob_chain_stem(ht, "adv", stem, pagemsg, notes, default_comment,
                no_warn=True)

        else:
          pagemsg("WARNING: Unrecognized adjective headword template %s" % (
            unicode(ht)))
          continue

      found_matching_head = True

      for inflt in headword['infl_templates']:
        infltn = tname(inflt)
        if infltn != "la-adecl":
          pagemsg("WARNING: Saw bad declension template for adj %s: %s" % (
            lemma, unicode(inflt)))
          continue

        if frob_nominal_lemma_spec(inflt, lemmaspec, explicit_stem, pagemsg, notes,
            default_comment) == "fail":
          continue

        for override in lalib.la_adj_decl_overrides:
          frob_stem(inflt, override, stem, pagemsg, notes, default_comment,
              split_slashes=True, no_warn=True)

        args = lalib.generate_adj_forms(unicode(inflt), errandpagemsg, expand_text)
        if args is None:
          return None, None

        process_all_forms(args, index, lemma,
          pos == "part" and "partform" or
          pos == "pronoun" and "pronounform" or
          pos == "det" and "detform" or
          pos == "numadj" and "numform" or
          pos == "sufadj" and "sufform" or
          "adjform", progargs)

    elif pos == "verb" and (found_head_template or tn == "la-verb"):
      if not explicit_stem:
        param3 = ""
        param4 = ""
      elif len(explicit_stem) == 1:
        param3 = explicit_stem[0]
        param4 = ""
      else:
        param3 = explicit_stem[0]
        param4 = explicit_stem[1]
        if param3 == "--":
          param3 = ""

      if not found_head_template:
        def fix_verb_template(t, infl, lemma, param3, param4):
          if re.sub(r"\.(.*)", "", getparam(t, "1")).replace("++", "+") != str(infl):
            return False

          def compare_principal_part(param, value):
            existing = getparam(t, param)
            no_macron_existing = remove_macrons(existing)
            no_macron_value = remove_macrons(value)
            if no_macron_existing != no_macron_value:
              pagemsg("WARNING: Principal part mismatch for param=%s, saw %s, expected %s: %s" % (
                param, existing, value, unicode(t)))
              return False
            return True

          if not compare_principal_part("2", lemma):
            return False
          if not compare_principal_part("3", param3):
            return False
          if not compare_principal_part("4", param4):
            return False

          frob_exact(t, "2", lemma, pagemsg, notes, default_comment)
          frob_exact(t, "3", param3, pagemsg, notes, default_comment)
          frob_exact(t, "4", param4, pagemsg, notes, default_comment)

          return True

      if not fix_verb_template(ht, explicit_infl, lemma, param3, param4):
        continue

      found_matching_head = True

      for inflt in headword['infl_templates']:
        infltn = tname(inflt)
        if infltn != "la-conj":
          pagemsg("WARNING: Saw bad conjugation template for infl=%s verb %s: %s" % (
            explicit_infl, lemma, unicode(inflt)))
          continue

        if not fix_verb_template(inflt, explicit_infl, lemma, param3, param4):
          continue

        # FIXME, handle overrides
        for override in lalib.la_verb_overrides:
          overval = getparam(inflt, override)
          if overval:
            pagemsg("WARNING: Found override %s=%s: %s" % (
              override, overval, unicode(inflt)))

        args = lalib.generate_verb_forms(unicode(inflt), errandpagemsg, expand_text)
        if args is None:
          return None, None

        single_forms_to_process = []
        for key, form in args.iteritems():
          for single_form in form.split(","):
            single_forms_to_process.append((key, single_form))

        for formind, (key, formval) in blib.iter_items(
            single_forms_to_process, get_name=lambda x: x[1]):
          partpos = None
          if key == "pres_actv_ptc":
            partpos = "presactpart"
          elif key in ["perf_actv_ptc", "perf_pasv_ptc"]:
            partpos = "perfpasspart"
          elif key == "futr_actv_ptc":
            partpos = "futactpart"
          elif key == "futr_pasv_ptc":
            partpos = "futpasspart"

          if partpos:
            # FIXME! Supply correct explicit stem for compounds of eō
            process_participle(index, lemma, formind, formval, None, progargs)
          elif not progargs.skip_forms and (not progargs.n_forms or formind <= progargs.n_forms):
            process_form(index, lemma, formind, formval, "verbform",
                find_tag_sets_for_form(args, formval), progargs)

    if found_matching_head:
      found_any_matching_head = True
      process_pronun_templates(headword['pronun_section'], lemma, pagemsg, notes,
          default_comment)

  if not found_any_matching_head:
    pagemsg("WARNING: Unable to find matching head")

  secbody = "".join(unicode(x) for x in parsed_subsections)
  sections[j] = secbody + sectail
  return "".join(sections), notes

if __name__ == "__main__":
  parser = blib.create_argparser("Clean up usage of macrons in Latin lemmas and non-lemma forms")
  parser.add_argument("--direcfile", help="File containing directives of lemmas to process.", required=True)
  parser.add_argument("--skip-forms", help="Skip processing non-lemma forms.", action="store_true")
  parser.add_argument("--n-forms", help="Do only first N non-lemma forms.", type=int)
  parser.add_argument("--comment", help="Do only first N non-lemma forms.")
  args = parser.parse_args()
  start, end = blib.parse_start_end(args.start, args.end)

  lemmas = []

  for lineno, line in blib.iter_items_from_file(args.direcfile, start, end):
    if line.startswith("*"):
      line = line[1:]
      msg("Line %s: Need to investigate: %s" % (lineno, line))
    # remove transitive/intransitive notation after verbs
    line = re.sub(r" *\[.*\]$", "", line)
    parts = line.split(" ")
    # allow underscore to stand for space
    parts = [part.replace("_", " ") for part in parts]
    if len(parts) == 2 and parts[0] in ["adv", "num", "phr", "prep", "prov"]:
      pass
    elif (len(parts) in [2, 3] and
        re.search("^([na]|pn|det|pron|num[na]|suf[na])([1-5]?)$", parts[0])):
      # noun, proper noun, pronoun, adjective, determiner, numeral noun/adj,
      # suffix noun/adj
      if len(parts) == 3:
        pos, lemma, explicit_stem = parts
      else:
        pos, lemma = parts
        explicit_stem = None
      m = re.search("^(.*?)([1-5]?)$", pos)
      code_to_pos = {
        "n": "noun",
        "pn": "propernoun",
        "pron": "pronoun",
        "a": "adj",
        "det": "det",
        "sufn": "sufnoun",
        "sufa": "sufadj",
        "numn": "numnoun",
        "numa": "numadj",
      }
      pos = code_to_pos[m.group(1)]
      infl = m.group(2) and int(m.group(2)) or None
      # FIXME: The infl for nouns and adjectives is no longer used at all
      lemmas.append((pos, infl, lemma, explicit_stem))
    elif (len(parts) in [2, 3, 4] and
        re.search("^part([13]?)$", parts[0])):
      # participle
      infl = parts[0][4:] or None
      partform = parts[1]
      explicit_stem = parts[2:]
      # An explicit stem and/or lemma can be supplied. If one additional
      # argument is given, it could be either, but we can distinguish them
      # because the explicit stem must end in "nt" (it's used only for
      # present participles) and the lemma can never end in "nt".
      if len(explicit_stem) == 0:
        explicit_stem = None
      elif len(explicit_stem) == 2:
        pass
      elif explicit_stem[0].endswith("nt"):
        explicit_stem = explicit_stem[0]
      else:
        explicit_stem = [None, explicit_stem[0]]
      lemmas.append(("part", infl, partform, explicit_stem))
    elif len(parts) >= 2 and parts[0].startswith("v"):
      infl = parts[0][1:]
      lemma = parts[1]
      explicit_stem = parts[2:]
      lemmas.append(("verb", infl, lemma, explicit_stem))
    else:
      errandmsg("Line %s: Unrecognized line: %s" % (lineno, line))

  for index, (pos, infl, lemma, explicit_stem) in blib.iter_items(lemmas,
      get_name=lambda lemmas: remove_macrons(lemmas[2])):
    def pagemsg(txt):
      msg("Page %s %s: %s" % (index, lemma, txt))
    lemmaspec = lemma
    if "/" in lemma or "<" in lemma:
      if pos == "noun":
        fake_template = blib.parse_text("{{la-noun|%s}}" % lemma).filter_templates()[0]
      elif pos == "adj":
        fake_template = blib.parse_text("{{la-adj|%s}}" % lemma).filter_templates()[0]
      elif pos == "numadj":
        fake_template = blib.parse_text("{{la-num-adj|%s}}" % lemma).filter_templates()[0]
      else:
        errandmsg("Page %s %s: Apparent complex nominal spec for lemma but POS %s isn't noun/adj/numadj" % (
          index, lemma, pos))
        continue
      lemma = lalib.la_get_headword_from_template(fake_template, "foo", pagemsg)[0]
    def handler(page, index, parsed):
      return do_process_lemma(index, page, pos, infl, lemmaspec, lemma, explicit_stem, args)

    blib.do_edit(pywikibot.Page(site, remove_macrons(lemma)), index, handler, save=args.save,
        verbose=args.verbose, diff=args.diff)
