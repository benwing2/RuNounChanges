#!/usr/bin/env python
# -*- coding: utf-8 -*-

# Templates:
#
# Nouns:
# -----
#
# aquila:
#
# {{la-noun|aquila|aquilae|f|first}}
# {{la-decl-1st|aquil}}
#
# abāctor:
#
# {{la-noun|abāctor|abāctōris|m|third}}
# {{la-decl-3rd|abactor}}
#
# abaculus:
#
# {{la-noun|abaculus|abaculī|m|second}}
# {{la-decl-2nd|abacul}}
#
# abdōmen:
#
# {{la-noun|abdōmen|abdōminis|n|third}}
# {{la-decl-3rd-N|abdōmen}}
#
# abomāsum:
#
# {{la-noun|abomāsum|abomāsī|n|second}}
# {{la-decl-2nd-N|abomās}}
#
# accipiter:
#
# {{la-noun|accipiter|accipitris|m|third}}
# {{la-decl-3rd|accipiter}}
#
# ȳ:
#
# {{la-noun|ȳ|indecl=yes}}
#
# dē:
#
# {{head|la|noun|head=dē|{{l|en|indeclinable}}}}
#
# absinthium:
#
# {{la-noun|absinthium|absinthiī|gen2=absinthī|n|second}}
# {{la-decl-2nd-N-ium|absinth}}
#
# lēns:
#
# {{la-noun|lēns|lentis|f|third}}
# {{la-decl-3rd|lēns}}
#
# diēs:
#
# {{la-noun|diēs|diēī|m|g2=f|fifth}}
# {{la-decl-5th-i|d}}
#
# ōs:
#
# {{la-noun|ōs|ōris|n|third}}
# {{la-decl-3rd-N-I|ōs|ōr}}
#
# os:
#
# {{la-noun|os|ossis|n|third}}
# {{la-decl-3rd-N-I|os|oss|gen_pl=ossium}}
#
# cōnsēnsus:
#
# {{la-noun|cōnsēnsus|cōnsēnsūs|m|fourth}}
# {{la-decl-4th|cōnsēns}}
#
# comma:
#
# {{la-noun|comma|commatis|n|third}}
# {{la-decl-3rd-N|comma}}
#
# colon:
#
# {{la-noun|colon|colī|n|second}}
# {{la-decl-2nd-N-Greek|col}}
#
# gas:
#
# {{la-noun|gas|gasis|n|third}}
# {{la-decl-3rd|gas|gas}}
#
# phoenīx:
#
# {{la-noun|phoenīx|phoenīcis|f|third}}
# {{la-decl-3rd-I|phoenīx}}
# {{la-noun|phoenīx|phoenīcis|m|third}}
# {{la-decl-3rd|phoenīx}}
#
# Proper nouns:
# -------------
#
# Belgium:
#
# {{la-proper noun|Belgium|Belgiī|n|second}}
# {{la-decl-2nd-N|num=sg|Belgi}}
#
# Isrāēl:
#
# {{la-proper noun|Isrāēl||m|indecl=1}}<br/>
# {{la-proper noun|Isrāēl|Isrāēlis|m|third}}
# {{la-decl-3rd|num=sg|Isrāēl|Isrāēl}}
#
# Abaddōn:
#
# {{head|la|proper noun|head=Abaddōn|g=m|indeclinable}}
#
# Andorra:
#
# {{la-proper noun|Andorra|Andorrae|f|first}}
# {{la-decl-1st|loc=1|num=sg|Andorr}}
#
# Niger:
#
# {{la-proper noun|Niger|Nigrī|m|second}}
# {{la-decl-2nd-er|Niger|Nigr}}
# {{la-proper noun|Niger|Nigris|m|third}}
# {{la-decl-3rd|num=sg|Niger|acc_sg=Nigrim}}
#
# Achilles:
#
# {{la-proper noun|Achilles|Achillis|m|third}}
# {{la-decl-3rd|num=sg|Achilles|Achill}}
#
# Pronouns:
# ---------
#
# is:
#
# {{head|la|pronoun}}
# {{la-decl-irreg|is}}
#
# Verbs:
# ------
#
# līberō:
#
# {{la-verb|līberō|līberāre|līberāvī|līberātum|conj=1}}
# {{la-conj-1st|līber|līberāv|līberāt|sync_perf=poet|p3inf=1}}
#
# ferō:
#
# {{la-verb|ferō|ferre|tulī|perf2=tetulī|lātum|conj=3|pattern=irreg}}
# {{la-conj-irreg|fero}}
#
# eō:
#
# {{la-verb|eō|īre|iī|itum|conj=irreg}}
# {{la-conj-irreg|eo|p3inf=1}}
#
# for:
#
# {{la-verb|for|fārī|fātus sum|conj=1|pattern=depon}}
# {{la-conj-1st|type=depon|f|fāt|p3inf=1}}
#
# abdīcō:
#
# {{la-verb|abdīcō|abdīcere|abdīxī|abdictum|conj=irreg}}
# {{la-conj-irreg|dico|ab}}
#
# abdō:
#
# {{la-verb|abdō|abdere|abdidī|abditum|conj=3}}
# {{la-conj-3rd|abd|abdid|abdit}}
#
# alō:
#
# {{la-verb|alō|alere|aluī|altum|sup2=alitum|conj=3}}
# {{la-conj-3rd|al|alu|alt}}
# {{la-conj-3rd|al|alu|alit}}
#
# lingō:
#
# {{la-verb|lingō|lingere|linxī|linctum|conj=3}}
# {{la-conj-3rd|ling|linx|linct}}
#
# vērō:
#
# {{la-verb|vērō|vērāre|conj=1|pattern=nopass-noperf}}
# {{la-conj-1st|type=nopass-noperf|vēr}}
#
# lābor:
#
# {{la-verb|lābor|lābī|lāpsus sum|conj=3|pattern=depon}}
# {{la-conj-3rd|type=depon|lāb|lāps}}
#
# videō:
#
# {{la-verb|videō|vidēre|vīdī|vīsum|conj=2}}
# {{la-conj-2nd|vid|vīd|vīs|p3inf=1}} 
#
# Participles:
# ------------
#
# accūsāns:
#
# {{la-present participle|accūs|ans}}
# {{la-decl-3rd-part|accūsāns}}
#
# sapiēns:
#
# {{la-present participle|sapi|ens}}
# {{la-decl-3rd-part|sapiēns}}
#
# abditus:
#
# {{la-perfect participle|abdit}}
# {{la-decl-1&2|abdit}}
#
# futūrus:
#
# {{la-future participle|futūr}}
# {{la-decl-1&2|futūr}}
#
# rendus:
#
# {{la-gerundive|rend}}
# {{la-decl-1&2|rend}}
#
# Prefixes:
# ---------
#
# ā-:
#
# {{head|la|prefix|head=ā-}}
#
# Prepositions:
# -------------
#
# in:
#
# {{la-prep|accusative|ablative}}
#
# Adjectives:
# -----------
#
# phoenīx:
#
# {{la-adj-3rd-1E|phoenīx|phoenīcis}}
# {{la-decl-3rd-1E|type=par|phoenīx|phoenīc}}
#
# incōmptus:
#
# {{la-adj-1&2|incōmptus|incōmpta|incōmptum}}
# {{la-decl-1&2|incōmpt}}
#
# Adverbs:
# --------
#
# lentē:
#
# {{la-adv|lentē}}
#
# ferē:
#
# {{la-adv|ferē|-}}
#
# Interjections:
# --------------
#
# ēn:
#
# {{la-interj|ēn}}
#
# tax:
#
# {{head|la|interjection}}
#
# Letters:
# --------
#
# o:
#
# {{head|la|letter}}
#
# Abbreviations:
# --------------
#
# JUL:
#
# {{head|la|abbreviation}}
#
# Adjective forms:
# ----------------
#
# {{la-adj-form|abdominālēs}}
# # {{inflection of|abdominālis||nom|m|p|lang=la}}
# # {{inflection of|abdominālis||nom|f|p|lang=la}}
# # {{inflection of|abdominālis||acc|m|p|lang=la}}
# # {{inflection of|abdominālis||acc|f|p|lang=la}}
# # {{inflection of|abdominālis||voc|m|p|lang=la}}
# # {{inflection of|abdominālis||voc|f|p|lang=la}}
#
# Verb forms:
# -----------
#
# {{la-verb-form|abdūce}}
#
# # {{inflection of|abdūcō||2|s|pres|actv|impr|lang=la}}
#
# Noun forms:
# -----------
#
# {{la-noun-form|diē}}
#
# # {{inflection of|diēs||abl|s|lang=la|nodot=1}} (&quot;[[day]]&quot;).
#
# Participle forms:
# -----------------
#
# abrāse:
#
# {{la-part-form|abrāse}}
#
# # {{inflection of|abrāsus||voc|m|s|lang=la}}
#
# Pronoun forms:
# --------------
#
# mī:
#
# {{la-pronoun-form|mī}}
# {{head|la|pronoun form|head=mī}}
#


# FIXME:
#
# 1. Pronunciation templates.
# 2. DONE: Make sure lang and pos in {{head}} agree.
# 3. DONE: Verb overrides.
# 4. * before supine and perfect (maybe not needed).
# 5. For participles, check the etymology section to make sure the lemma
#    is correct.
# 6. Numbers, phrases, etc.

# Clean up use of macrons in Latin lemmas.

import pywikibot, re, sys, codecs, argparse

import blib
from blib import getparam, rmparam, msg, errandmsg, site, tname

import lalib
from lalib import remove_macrons


def frob_param(t, param, stem_or_exact, is_exact, pagemsg, notes, split_slashes=False, no_warn=False):
  origt = unicode(t)
  origval = getparam(t, param)
  if split_slashes:
    vals = origval.split("/")
  else:
    vals = [origval]
  newvals = []
  for val in vals:
    no_macrons_val = remove_macrons(val)
    assert len(no_macrons_val) == len(val)
    if type(stem_or_exact) is not list:
      stem_or_exact = [stem_or_exact]
    for st in stem_or_exact:
      no_macrons_st = remove_macrons(st)
      assert len(no_macrons_st) == len(st)
      if is_exact:
        if no_macrons_val == no_macrons_st:
          newvals.append(st)
          break
      else:
        if no_macrons_val.startswith(no_macrons_st):
          newvals.append(st + val[len(st):])
          break
    else:
      if val or not no_warn:
        # no break
        if is_exact:
          pagemsg("WARNING: Unable to match value %s in param %s against replacement(s) %s" % (
            val, param, ",".join(stem_or_exact)))
        else:
          pagemsg("WARNING: Unable to match value %s in param %s against replacement stem(s) %s" % (
            val, param, ",".join(stem_or_exact)))
      newvals.append(val)
  newval = "/".join(newvals)
  if newval != origval:
    t.add(param, newval)
    pagemsg("Replaced %s with %s" % (origt, unicode(t)))
    notes.append("updated macrons in %s per Bennett" % tname(t))

def frob_stem(t, param, stem, pagemsg, notes, split_slashes=False, no_warn=False):
  frob_param(t, param, stem, False, pagemsg, notes, split_slashes=split_slashes,
      no_warn=no_warn)

def frob_exact(t, param, newval, pagemsg, notes, split_slashes=False, no_warn=False):
  frob_param(t, param, newval, True, pagemsg, notes, split_slashes=split_slashes,
      no_warn=no_warn)

def frob_chain_stem(t, param, stem, pagemsg, notes, split_slashes=False, no_warn=False):
  if type(param) is list:
    first, rest = param
  else:
    first = param
    rest = param
  if first:
    frob_stem(t, first, stem, pagemsg, notes, split_slashes=split_slashes,
        no_warn=no_warn)
  num = 2
  while getparam(t, "%s%s" % (rest, num)):
    frob_stem(t, "%s%s" % (rest, num), stem, pagemsg, notes, split_slashes=split_slashes,
        no_warn=no_warn)
    num += 1

def frob_chain_exact(t, param, newval, pagemsg, notes, split_slashes=False, no_warn=False):
  if type(param) is list:
    first, rest = param
  else:
    first = param
    rest = param
  if first:
    frob_exact(t, first, newval, pagemsg, notes, split_slashes=split_slashes,
        no_warn=no_warn)
  num = 2
  while getparam(t, "%s%s" % (rest, num)):
    frob_exact(t, "%s%s" % (rest, num), newval, pagemsg, notes, split_slashes=split_slashes,
        no_warn=no_warn)
    num += 1

def find_heads_and_defns(page, pagemsg):
  text = unicode(page.text)

  retval = lalib.find_latin_section(text, pagemsg)
  if retval is None:
    return None

  sections, j, secbody, sectail, has_non_latin = retval

  subsections = re.split("(^==+[^=\n]+==+\n)", secbody, 0, re.M)

  parsed_subsections = [None] * len(subsections)
  pronun_templates = []
  headwords = []

  most_recent_headword = None

  def new_headword(header, level, subsection, head_template, is_lemma):
    return {
      'head_template': head_template,
      'header': header,
      'is_lemma': is_lemma,
      'infl_templates': [],
      'infl_of_templates': [],
      'subsection': subsection,
      'level': level,
    }

  def transfer_most_recent_headword():
    headwords.append(most_recent_headword)

  for k in xrange(len(subsections)):
    if k < 2 or (k % 2) == 1:
      parsed_subsections[k] = blib.parse_text(subsections[k])
      continue
    m = re.search("^(==+)([^=\n]+)", subsections[k - 1])
    level = len(m.group(1))
    header = m.group(2)
    headword_templates_in_section = []

    if most_recent_headword and most_recent_headword['level'] >= level:
      transfer_most_recent_headword()
      most_recent_headword = None

    parsed = blib.parse_text(subsections[k])
    parsed_subsections[k] = parsed
    for t in parsed.filter_templates():
      tn = tname(t)
      if tn == "la-IPA":
        pronun_templates.append((t, k))
      elif tn in lalib.la_headword_templates or tn == "head":
        if tn == "head":
          if getparam(t, "1") != "la":
            errandpagemsg("WARNING: Wrong-language {{head}} template in Latin section: %s" % unicode(t))
            continue
          head_pos = getparam(t, "2")
          if head_pos not in lalib.la_poses:
            pagemsg("WARNING: Unrecognized part of speech %s" % pos)
        if headword_templates_in_section:
          pagemsg("WARNING: Found additional headword template in same section: %s" % unicode(t))
          transfer_most_recent_headword()
        elif most_recent_headword:
          pagemsg("WARNING: Found headword template nested under previous one: %s" % unicode(t))
          transfer_most_recent_headword()
        most_recent_headword = new_headword(header, level, k, t,
          tn in lalib.la_lemma_headword_templates or (
            tn == "head" and head_pos in lalib.la_lemma_poses))
        headword_templates_in_section.append(t)
      elif tn in lalib.la_infl_templates:
        if not most_recent_headword:
          pagemsg("WARNING: Found inflection template not under headword template: %s" % unicode(t))
        else:
          most_recent_headword['infl_templates'].append(t)
      elif tn in lalib.la_infl_of_templates:
        if not most_recent_headword:
          pagemsg("WARNING: Found inflection-of template not under headword template: %s" % unicode(t))
        else:
          most_recent_headword['infl_of_templates'].append(t)

  if most_recent_headword:
    transfer_most_recent_headword()

  return (
    sections, j, secbody, sectail, has_non_latin, subsections,
    parsed_subsections, pronun_templates, headwords
  )

def find_tag_sets_for_form(args, form):
  tag_sets = []
  for key, formspec in args.iteritems():
    forms = formspec.split(",")
    if form in forms:
      tag_sets.append(lalib.form_key_to_tag_set(key))
  return tag_sets

def process_pronun_template(t, lemma, pagemsg, notes):
  if not getparam(t, "1"):
    if remove_macrons(lemma) != lemma:
      eccl = getparam(t, "eccl")
      rmparam(t, "eccl")
      t.add("1", lemma)
      if eccl:
        t.add("eccl", eccl)
      notes.append("add pronunciation to {{la-IPA}}")
  else:
    frob_exact(t, "1", lemma, pagemsg, notes)

def do_process_form(index, page, lemma, formind, formval, pos, tag_sets_to_process, save, verbose):
  pagetitle = unicode(page.title())

  def pagemsg(txt):
    msg("Page %s %s: form %s %s: %s" % (index, lemma, formind, formval, txt))

  def errandpagemsg(txt):
    errandmsg("Page %s %s: form %s %s: %s" % (index, lemma, formind, formval, txt))

  def expand_text(tempcall):
    return blib.expand_text(tempcall, pagetitle, pagemsg, verbose)

  if "[" in formval:
    pagemsg("Skipping form value %s with link in it" % formval)
    return None, None

  page = pywikibot.Page(site, pagetitle)
  if not page.exists():
    pagemsg("Skipping form value %s, page doesn't exist" % formval)
    return None, None

  if pos == "verbform":
    expected_head_template = "la-verb-form"
    expected_pos = "verb form"
    expected_header_pos = "Verb"
  elif pos == "adjform":
    expected_head_template = "la-adj-form"
    expected_pos = "adjective form"
    expected_header_pos = "Adjective"
  elif pos == "nounform":
    expected_head_template = "la-noun-form"
    expected_pos = "noun form"
    expected_header_pos = "Noun"
  elif pos == "partform":
    expected_head_template = "la-part-form"
    expected_pos = "participle form"
    expected_header_pos = "Participle"
  else:
    raise ValueError("Unrecognized part of speech %s" % pos)

  pagemsg("Processing")

  retval = find_heads_and_defns(page, pagemsg)
  if retval is None:
    return None, None

  (
    sections, j, secbody, sectail, has_non_latin, subsections,
    parsed_subsections, pronun_templates, headwords
  ) = retval

  notes = []

  for headword in headwords:
    ht = headword['head_template']
    tn = tname(ht)
    saw_infl = False
    saw_other_infl = False
    found_head = False

    if tn == "head":
      if getparam(ht, "1") != "la":
        errandpagemsg("WARNING: Wrong-language {{head}} template in Latin section: %s" % unicode(ht))
        continue
      head_pos = getparam(t, "2")
      if head_pos != expected_pos:
        pagemsg("Skipping incorrect part of speech %s: %s" % (head_pos, unicode(ht)))
        continue
      head_param = "head"
      found_head = True

    if tn == expected_head_template:
      head_param = "1"
      found_head = True

    if not found_head:
      continue

    for t in headword['infl_of_templates']:
      lang = getparam(t, "lang")
      if lang:
        lemma_param = 1
      else:
        lang = getparam(t, "1")
        lemma_param = 2
      if lang != "la":
        errandpagemsg("WARNING: In Latin section, found {{inflection of}} for different language %s: %s" % (
          lang, unicode(t)))
        return None, None
      actual_lemma = getparam(t, str(lemma_param))
      if remove_macrons(actual_lemma) == remove_macrons(lemma):
        # fetch tags
        tags = []
        for param in t.params:
          pname = unicode(param.name).strip()
          pval = unicode(param.value).strip()
          if re.search("^[0-9]+$", pname):
            if int(pname) >= lemma_param + 2:
              if pval:
                tags.append(pval)
        for tag in tags:
          if "//" in tag:
            pagemsg("WARNING: Don't know how to handle multipart tags yet: %s" % unicode(t))
            saw_other_infl = True
            break
        else:
          # no break
          tag_sets = lalib.split_tags_into_tag_sets(tags)
          for tag_set in tag_sets:
            if tag_sets_to_process is True or frozenset(lalib.canonicalize_tag_set(tag_set)) in tag_sets_to_process:
              saw_infl = True
            else:
              expected_tag_sets = "|".join(lalib.combine_tag_set_group(tag_sets_to_process))
              pagemsg("Found {{inflection of}} for correct lemma but wrong tag set %s (expected %s): %s" % (
                "|".join(tag_set), expected_tag_sets, unicode(t)))
              saw_other_infl = True
      else:
        pagemsg("Found {{inflection of}} for different lemma %s: %s" % (
          actual_lemma, unicode(t)))
        saw_other_infl = True

    if saw_infl and saw_other_infl:
      pagemsg("WARNING: Found mixture of good inflection-of templates and inflection-of templates for different lemma or nondeletable tag set, won't frob")
      continue

    if not saw_infl:
      continue

    frob_exact(ht, head_param, formval, pagemsg, notes)
    for t in headword['infl_of_templates']:
      lang = getparam(t, "lang")
      if lang:
        lemma_param = 1
      else:
        lang = getparam(t, "1")
        lemma_param = 2
      assert lang == "la"
      frob_exact(t, str(lemma_param), lemma, pagemsg, notes)

  secbody = "".join(unicode(x) for x in parsed_subsections)
  sections[j] = secbody + sectail
  return "".join(sections), notes

def process_form(index, lemma, formind, formval, pos, tag_sets_to_process, save, verbose):
  def handler(page, index, parsed):
    return do_process_form(index, page, lemma, formind, formval, pos, tag_sets_to_process, save, verbose)
  blib.do_edit(pywikibot.Page(site, remove_macrons(formval)), index, handler, save=save, verbose=verbose)

def process_all_forms(args, index, lemma, pos, save, verbose):
  single_forms_to_process = []
  for key, form in args.iteritems():
    for single_form in form.split(","):
      single_forms_to_process.append((key, single_form))

  for formind, (key, formval) in blib.iter_items(
      single_forms_to_process, get_name=lambda x: x[1]):
    process_form(index, lemma, formind, formval, pos,
        find_tag_sets_for_form(args, formval), save, verbose)

def do_process_participle(index, page, lemma, formind, formval, pos, save, verbose):
  pagetitle = unicode(page.title())

  def pagemsg(txt):
    msg("Page %s %s: form %s %s: %s" % (index, lemma, formind, formval, txt))

  def errandpagemsg(txt):
    errandmsg("Page %s %s: form %s %s: %s" % (index, lemma, formind, formval, txt))

  def expand_text(tempcall):
    return blib.expand_text(tempcall, pagetitle, pagemsg, verbose)

  if "[" in formval:
    pagemsg("Skipping form value %s with link in it" % formval)
    return None, None

  page = pywikibot.Page(site, pagetitle)
  if not page.exists():
    pagemsg("Skipping form value %s, page doesn't exist" % formval)
    return None, None

  if pos == "presactpart":
    expected_head_template = "la-present participle"
    if not re.search(u"[āē]ns$", formval):
      pagemsg("WARNING: Bad present participle form %s, wrong ending" %
        formval)
      return None, None
    expected_head_arg = re.sub(u"[āē]ns$", "", formval)
    expected_decl_template = "la-decl-3rd-part"
    expected_decl_arg = formval
  else:
    if pos == "perfpasspart":
      expected_head_template = "la-perfect participle"
    elif pos == "futactpart":
      expected_head_template = "la-future participle"
    elif pos == "futpasspart":
      expected_head_template = "la-gerundive"
    else:
      raise ValueError("Unrecognized participle part of speech %s" % pos)
    if not formval.endswith("us"):
      pagemsg("WARNING: Bad participle form %s, wrong ending" % formval)
      return None, None
    expected_head_arg = re.sub("us$", "", formval)
    expected_decl_template = "la-decl-1&2"
    expected_decl_arg = expected_head_arg

  pagemsg("Processing")

  retval = find_heads_and_defns(page, pagemsg)
  if retval is None:
    return None, None

  (
    sections, j, secbody, sectail, has_non_latin, subsections,
    parsed_subsections, pronun_templates, headwords
  ) = retval

  notes = []

  for headword in headwords:
    ht = headword['head_template']
    tn = tname(ht)
    saw_infl = False
    saw_other_infl = False
    found_head = False

    if tn == "head":
      if getparam(ht, "1") != "la":
        errandpagemsg("WARNING: Wrong-language {{head}} template in Latin section: %s" % unicode(ht))
        continue
      head_pos = getparam(t, "2")
      if head_pos != "participle":
        pagemsg("Skipping incorrect part of speech %s: %s" % (head_pos, unicode(ht)))
        continue
      frob_exact(ht, "head", formval, pagemsg, notes)
      found_head = True

    if tn == expected_head_template:
      frob_exact(ht, "1", expected_head_arg, pagemsg, notes)
      found_head = True

    if not found_head:
      continue

    for inflt in headword['infl_templates']:
      infltn = tname(inflt)
      if infltn != expected_decl_template:
        pagemsg("WARNING: Saw bad declension template for participle: %s" % (
          formval, unicode(inflt)))
        continue
      frob_exact(inflt, "1", expected_decl_arg, pagemsg, notes)

      args = lalib.generate_adj_forms(unicode(inflt), errandpagemsg, expand_text)
      if args is None:
        return None, None

      process_all_forms(args, index, formval, "partform", save, verbose)

  secbody = "".join(unicode(x) for x in parsed_subsections)
  sections[j] = secbody + sectail
  return "".join(sections), notes

def process_participle(index, lemma, formind, formval, pos, save, verbose):
  def handler(page, index, parsed):
    return do_process_participle(index, page, lemma, formind, formval, pos, save, verbose)
  blib.do_edit(pywikibot.Page(site, remove_macrons(formval)), index, handler, save=save, verbose=verbose)

def do_process_lemma(index, page, pos, explicit_infl, lemma, explicit_stem, save, verbose):
  pagetitle = unicode(page.title())
  def pagemsg(txt):
    msg("Page %s %s: %s" % (index, pagetitle, txt))

  def errandpagemsg(txt):
    errandmsg("Page %s %s: %s" % (index, pagetitle, txt))

  def expand_text(tempcall):
    return blib.expand_text(tempcall, pagetitle, pagemsg, verbose)

  pagemsg("Processing")

  retval = find_heads_and_defns(page, pagemsg)
  if retval is None:
    return None, None

  (
    sections, j, secbody, sectail, has_non_latin, subsections,
    parsed_subsections, pronun_templates, headwords
  ) = retval

  notes = []
  for headword in headwords:
    ht = headword['head_template']
    tn = tname(ht)

    found_head_template = False

    if tn == "head":
      if getparam(ht, "1") != "la":
        errandpagemsg("WARNING: Wrong-language {{head}} template in Latin section: %s" % unicode(ht))
        continue

      pos_to_full_pos = {
        "noun": "noun",
        "propernoun": "proper noun",
        "adj": "adjective",
        "adv": "adverb",
        "phr": "phrase",
        "prov": "proverb", 
        "verb": "verb",
        "num": "numeral",
      }
      if getparam(ht, "2") == pos_to_full_pos[pos]:
        frob_exact(ht, "head", lemma, pagemsg, notes)
        found_head_template = True

    if pos == "noun" and (found_head_template or tn == "la-noun"):
      if not found_head_template:
        if explicit_infl == 1:
          if lemma.endswith("a"):
            inferred_stem = lemma[:-1]
          else:
            errandpagemsg("WARNING: Bad 1st-declension noun lemma %s" % lemma)
            return None, None
        elif explicit_infl == 2:
          if lemma.endswith("r"):
            inferred_stem = lemma
          elif lemma.endswith("ius") or lemma.endswith("ium"):
            inferred_stem = lemma[:-3] # second genitive will have -ī
          elif lemma.endswith("us") or lemma.endswith("um"):
            inferred_stem = lemma[:-2]
          else:
            errandpagemsg("WARNING: Bad 2nd-declension noun lemma %s" % lemma)
            return None, None
        elif explicit_infl == 3:
          inferred_stem = lalib.infer_3rd_decl_stem(lemma)
        elif explicit_infl == 4:
          if lemma.endswith("us"):
            inferred_stem = lemma[:-2]
          else:
            errandpagemsg("WARNING: Bad 4th-declension noun lemma %s" % lemma)
            return None, None
        elif explicit_infl == 5:
          if lemma.endswith(u"ēs"):
            inferred_stem = lemma[:-2]
          else:
            errandpagemsg("WARNING: Bad 5th-declension noun lemma %s" % lemma)
            return None, None
        else:
          errandpagemsg("WARNING: Unrecognized infl %s" % explicit_infl)
          return None, None

        stem = explicit_stem or inferred_stem

        infl_to_ordinal = {
          1: 'first',
          2: 'second',
          3: 'third',
          4: 'fourth',
          5: 'fifth'
        }

        if (remove_macrons(lemma) == remove_macrons(getparam(ht, "1")) and
            getparam(ht, "4") == infl_to_ordinal[explicit_infl]):
          frob_exact(ht, "1", lemma, pagemsg, notes)
          frob_chain_stem(ht, ["2", "gen"], stem, pagemsg, notes)
        else:
          continue

      for inflt in headword['infl_templates']:
        infltn = tname(inflt)
        if infltn not in lalib.la_noun_decl_templates:
          pagemsg("WARNING: Saw bad declension template for infl=%s noun %s: %s" % (
            explicit_infl, lemma, unicode(inflt)))
          continue
        m = re.search('^la-decl-(.*)$', infltn)
        decltype = lalib.la_noun_decl_suffix_to_decltype[m.group(1)]
        if type(decltype) is tuple:
          decl = decltype[0]
          if len(decltype) >= 2:
            declsubtypes = decltype[1].split("-")
          else:
            declsubtypes = []
        else:
          decl = decltype
          declsubtypes = []
        if decl is None:
          pagemsg("WARNING: Don't know how to handle decl: %s" % unicode(inflt))
          continue
        if decl != str(explicit_infl):
          pagemsg("WARNING: Wrong decl %s != expected %s for decl template: %s" % (
            decl, explicit_infl, unicode(inflt)))
          continue
        if explicit_infl == 1:
          if not lemma.endswith("a"):
            errandpagemsg("WARNING: Bad 1st-declension noun lemma %s" % lemma)
            return None, None
          arg1 = lemma[:-1]
          arg2 = ""
        elif explicit_infl == 2:
          if lemma.endswith("us"):
            if "ius" in declsubtypes:
              if not lemma.endswith("ius"):
                pagemsg("WARNING: Declension template requires lemma in -ius but lemma %s doesn't end that way: %s" % (
                  lemma, unicode(inflt)))
                continue
              arg1 = lemma[:-3]
              arg2 = ""
            else:
              arg1 = lemma[:-2]
              arg2 = ""
          elif lemma.endswith("um"):
            if "ium" in declsubtypes:
              if not lemma.endswith("ium"):
                pagemsg("WARNING: Declension template requires lemma in -ium but lemma %s doesn't end that way: %s" % (
                  lemma, unicode(inflt)))
                continue
              arg1 = lemma[:-3]
              arg2 = ""
            else:
              arg1 = lemma[:-2]
              arg2 = ""
          elif lemma.endswith("r"):
            arg1 = lemma
            if explicit_stem and explicit_stem != lemma:
              arg2 = explicit_stem
            else:
              arg2 = ["", lemma]
          else:
            errandpagemsg("WARNING: Bad 2nd-declension noun lemma %s" % lemma)
            return None, None
        elif explicit_infl == 3:
          arg1 = lemma
          if explicit_stem and explicit_stem != inferred_stem:
            arg2 = explicit_stem
          else:
            arg2 = ["", inferred_stem]
        elif explicit_infl == 4:
          if not lemma.endswith("us"):
            errandpagemsg("WARNING: Bad 4th-declension noun lemma %s" % lemma)
            return None, None
          arg1 = lemma[:-2]
          arg2 = ""
        elif explicit_infl == 5:
          if not lemma.endswith(u"ēs"):
            errandpagemsg("WARNING: Bad 5th-declension noun lemma %s" % lemma)
            return None, None
          if "i" in declsubtypes:
            if not lemma.endswith(u"iēs"):
              pagemsg(u"WARNING: Declension template requires lemma in -iēs but lemma %s doesn't end that way: %s" % (
                lemma, unicode(inflt)))
              continue
            arg1 = lemma[:-3]
            arg2 = ""
          else:
            arg1 = lemma[:-2]
            arg2 = ""
        else:
          errandpagemsg("WARNING: Unrecognized infl %s" % explicit_infl)
          return None, None

        if remove_macrons(arg1) != remove_macrons(getparam(inflt, "1")):
          pagemsg("WARNING: lemma stem %s doesn't match template stem: %s" % (
            arg1, unicode(inflt)))
          continue
        param2 = getparam(inflt, "2")
        if type(arg2) is not list:
          arg2 = [arg2]
        actual_matching_arg2 = None
        for matching_arg2 in arg2:
          if remove_macrons(matching_arg2) == remove_macrons(param2):
            actual_matching_arg2 = matching_arg2
            break
        else:
          # no break
          pagemsg("WARNING: lemma secondary stem(s) %s not matching template second param: %s" % (
            ",".join(arg2), unicode(inflt)))
          continue

        frob_exact(inflt, "1", arg1, pagemsg, notes)
        frob_exact(inflt, "2", actual_matching_arg2, pagemsg, notes)

        for override in lalib.la_noun_decl_overrides:
          frob_stem(inflt, override, stem, pagemsg, notes, split_slashes=True,
              no_warn=True)

        args = lalib.generate_noun_forms(unicode(inflt), errandpagemsg, expand_text)
        if args is None:
          return None, None

        process_all_forms(args, index, lemma, "nounform", save, verbose)

    elif pos == "adj" and (found_head_template or tn in lalib.la_adj_headword_templates):
      if not found_head_template:
        if explicit_infl == 1:
          if lemma.endswith("r"):
            inferred_stem = lemma
          elif lemma.endswith("us"):
            inferred_stem = lemma[:-2]
          else:
            errandpagemsg("WARNING: Bad 1st/2nd-declension adjective lemma %s" % lemma)
            return None, None
        elif explicit_infl == 3:
          inferred_stem = lalib.infer_3rd_decl_stem(lemma)
        stem = explicit_stem or inferred_stem

        if (explicit_infl == 1 and tn in ["la-adj-1&2", "la-adj-superlative"] or
            explicit_infl == 3 and tn in ["la-adj-3rd-1E", "la-adj-3rd-2E", "la-adj-3rd-3E", "la-adj-comparative"]):
          frob_chain_exact(ht, ["1", "head"], lemma, pagemsg, notes)
          if tn in ["la-adj-1&2", "la-adj-3rd-1E", "la-adj-3rd-2E", "la-adj-3rd-3E"]:
            frob_chain_stem(ht, "comp", stem, pagemsg, notes, no_warn=True)
            frob_chain_stem(ht, "sup", stem, pagemsg, notes, no_warn=True)
          if tn in ["la-adj-1&2", "la-adj-3rd-3E"]:
            frob_chain_stem(ht, ["2", "f"], stem, pagemsg, notes)
            frob_chain_stem(ht, ["3", "n"], stem, pagemsg, notes)
          elif tn == "la-adj-3rd-1E":
            frob_chain_stem(ht, ["2", "gen"], stem, pagemsg, notes)
          elif tn == "la-adj-3rd-2E":
            frob_chain_stem(ht, ["2", "n"], stem, pagemsg, notes)
          elif tn == "la-adj-comparative":
            if lemma.endswith("ior"):
              base = lemma[:-3]
              frob_stem(ht, "comp", base, pagemsg, notes, no_warn=True)
          elif tn == "la-adj-superlative":
            if lemma.endswith("issimus"):
              base = lemma[:-7]
            if lemma.endswith("rimus"):
              base = lemma[:-5]
            else:
              base = None
            if base:
              frob_stem(ht, "sup", base, pagemsg, notes)
        else:
          pagemsg("WARNING: Mismatch between requested adjective inflection %s and actual adjective headword template %s" % (
            explicit_infl, unicode(ht)))
          continue

      for inflt in headword['infl_templates']:
        infltn = tname(inflt)
        if infltn not in lalib.la_adj_decl_templates:
          pagemsg("WARNING: Saw bad declension template for infl=%s adj %s: %s" % (
            explicit_infl, lemma, unicode(inflt)))
          continue

        if explicit_infl == 1:
          if infltn != "la-decl-1&2":
            pagemsg("WARNING: Saw mismatching adjective declension template for first/second-declension adjective %s: %s" % (
              lemma, unicode(inflt)))
            continue
          if lemma.endswith("er") and lemma != stem:
            if getparam(inflt, "1").endswith("(e)r"):
              arg1 = lemma[:-2] + "(e)r"
              arg2 = ""
            else:
              arg1 = lemma
              arg2 = stem
          else:
            arg1 = stem
            arg2 = ""
        elif explicit_infl == 3:
          if infltn in ["la-decl-3rd-1E", "la-decl-3rd-3E", "la-decl-3rd-part"]:
            arg1 = lemma
            if stem != inferred_stem:
              arg2 = stem
            else:
              arg2 = ["", inferred_stem]
          elif infltn == "la-decl-3rd-2E":
            if not lemma.endswith("is"):
              pagemsg("WARNING: Bad lemma %s for 3rd declension, two-ending adjective: %s" % (
                lemma, unicode(inflt)))
              continue
            arg1 = lemma[:-2]
            arg2 = ""
          elif infltn == "la-decl-3rd-comp":
            if not lemma.endswith("or"):
              pagemsg("WARNING: Bad lemma %s for 3rd declension comparative adjective: %s" % (
                lemma, unicode(inflt)))
              continue
            arg1 = lemma[:-3]
            if getparam(inflt, "2"):
              arg2 = lemma[-3]
            else:
              arg2 = ""
        else:
          errandpagemsg("WARNING: Unrecognized infl %s" % explicit_infl)
          return None, None

        if remove_macrons(arg1) != remove_macrons(getparam(inflt, "1")):
          pagemsg("WARNING: lemma stem %s doesn't match template stem: %s" % (
            arg1, unicode(inflt)))
          continue
        param2 = getparam(inflt, "2")
        if type(arg2) is not list:
          arg2 = [arg2]
        actual_matching_arg2 = None
        for matching_arg2 in arg2:
          if remove_macrons(matching_arg2) == remove_macrons(param2):
            actual_matching_arg2 = matching_arg2
            break
        else:
          # no break
          pagemsg("WARNING: lemma secondary stem(s) %s not matching template second param: %s" % (
            ",".join(arg2), unicode(inflt)))
          continue
        frob_exact(inflt, "1", arg1, pagemsg, notes)
        frob_exact(inflt, "2", actual_matching_arg2, pagemsg, notes)

        for override in lalib.la_adj_decl_overrides:
          frob_stem(inflt, override, stem, pagemsg, notes, split_slashes=True,
              no_warn=True)

        args = lalib.generate_adj_forms(unicode(inflt), errandpagemsg, expand_text)
        if args is None:
          return None, None
        process_all_forms(args, index, lemma, "adjform", save, verbose)

    elif pos == "verb" and (found_head_template or tn == "la-verb"):
      if not found_head_template:
        deponent = False
        if explicit_infl == 1 and not explicit_stem:
          infl = 1
          if lemma.endswith("or"):
            deponent = True
            vinf = lemma[:-2] + u"ārī"
            vperf = ""
            vsup = lemma[:-2] + u"ātum"
          elif lemma.endswith(u"ō"):
            vinf = lemma[:-1] + u"āre"
            vperf = lemma[:-1] + u"āvī"
            vsup = lemma[:-1] + u"ātum"
          else:
            errandpagemsg("WARNING: Bad lemma %s for 1st-conjugation verb" % lemma)
            return None, None
        elif explicit_infl == 4 and not explicit_stem:
          infl = 4
          if lemma.endswith("ior"):
            deponent = True
            vinf = lemma[:-3] + u"īrī"
            vperf = ""
            vsup = lemma[:-3] + u"ītum"
          elif lemma.endswith(u"iō"):
            vinf = lemma[:-2] + u"īre"
            vperf = lemma[:-2] + u"īvī"
            vsup = lemma[:-2] + u"ītum"
          else:
            errandpagemsg("WARNING: Bad lemma %s for 4th-conjugation verb" % lemma)
            return None, None
        elif not explicit_infl and explicit_stem:
          if lemma.endswith("or"):
            deponent = True
            if len(explicit_stem) != 2:
              errandpagemsg("WARNING: For verb lemma %s, wrong length of explicit stem %s" % (lemma, explicit_stem))
              return None, None
            vinf, vsup = explicit_stem
            vperf = ""
            if vinf.endswith(u"ī") and lemma[:-2] == vinf[:-1]:
              infl = 3
            elif vinf.endswith(u"ī") and lemma.endswith("ior") and lemma[:-3] == vinf[:-1]:
              infl = "io"
            elif vinf.endswith(u"ārī"):
              infl = 1
            elif vinf.endswith(u"ērī"):
              infl = 2
            elif vinf.endswith(u"īrī"):
              infl = 4
            else:
              errandpagemsg("WARNING: Unrecognized verb infinitive %s for lemma %s" % (vinf, lemma))
              return None, None
          elif lemma.endswith(u"ō"):
            if len(explicit_stem) != 3:
              errandpagemsg("WARNING: For verb lemma %s, wrong length of explicit stem %s" % (lemma, explicit_stem))
              return None, None
            vinf, vperf, vsup = explicit_stem
            if vinf.endswith(u"āre"):
              infl = 1
            elif vinf.endswith(u"ēre"):
              infl = 2
            elif vinf.endswith(u"īre"):
              infl = 4
            elif vinf.endswith("ere") and lemma.endswith(u"iō"):
              infl = "io"
            elif vinf.endswith("ere"):
              infl = 3
            elif (vinf.endswith("rre") or vinf.endswith("lle") or vinf.endswith("sse") or vinf.endswith("dare")):
              infl = "irreg"
            else:
              errandpagemsg("WARNING: Unrecognized verb infinitive %s for lemma %s" % (vinf, lemma))
              return None, None
        else:
          errandpagemsg("WARNING: For verb lemma %s, bad infl %s combined with explicit stem %s" % (lemma, explicit_infl, explicit_stem))
          return None, None

        if getparam(ht, "conj") != str(infl):
          continue

        def compare_principal_part(first, rest, value):
          values = [] if not value else value.split("/")
          no_macron_values = [remove_macrons(x) for x in values]
          actual_values = blib.fetch_param_chain(ht, first, rest)
          no_macron_actual_values = [remove_macrons(x) for x in actual_values]
          if no_macron_values != no_macron_actual_values:
            pagemsg("WARNING: Principal part mismatch for param=%s, saw %s, expected %s" % (
              rest, "/".join(actual_values), "/".join(values)))
            return False
          return True

        if not compare_principal_part("1", "head", lemma):
          continue
        if not compare_principal_part("2", "inf", vinf):
          continue
        if deponent:
          sups = vsup.split("/")
          perfs = []
          for sup in sups:
            if not sup.endswith("um"):
              errandpagemsg("WARNING: For verb lemma %s, bad deponent supine %s" % (lemma, sup))
              return None, None
            perfs.append(sup[:-2] + "us sum")
          if not compare_principal_part("3", "perf", "/".join(perfs)):
            continue
        else:
          if not compare_principal_part("3", "perf", vperf):
            continue
          if not compare_principal_part("4", "sup", vsup):
            continue

        frob_chain_exact(ht, ["1", "head"], lemma.split("/"), pagemsg, notes)
        frob_chain_exact(ht, ["2", "inf"], vinf.split("/"), pagemsg, notes)
        if deponent:
          frob_chain_exact(ht, ["3", "perf"], perfs, pagemsg, notes)
        else:
          frob_chain_exact(ht, ["3", "perf"], vperf.split("/"), pagemsg, notes)
          frob_chain_exact(ht, ["4", "sup"], vsup.split("/"), pagemsg, notes)

      for inflt in headword['infl_templates']:
        infltn = tname(inflt)
        if infltn not in lalib.la_verb_conj_templates:
          pagemsg("WARNING: Saw bad conjugation template for infl=%s verb %s: %s" % (
            infl, lemma, unicode(inflt)))
          continue

        def truncate_ending(val, expected_ending, parttype):
          if not val:
            return ""
          vals = val.split("/")
          stems = []
          for v in vals:
            if not v.endswith(expected_ending):
              errandpagemsg("WARNING: %s should end in -%s: %s" % (parttype, expected_ending, v))
              return None
            stems.append(v[:-len(expected_ending)])
          return "/".join(stems)

        if infl == "irreg":
          if infltn != "la-conj-irreg":
            pagemsg("WARNING: Saw mismatching conjugation template for infl=%s verb %s: %s" % (
              infl, lemma, unicode(inflt)))
            continue
          prefix = getparam(inflt, "2")
          if prefix:
            lemmaprefix = lemma[0:len(prefix)]
            if remove_macrons(lemmaprefix) != remove_macrons(prefix):
              pagemsg("WARNING: Saw prefix mismatch, actual %s != expected %s for lemma %s: %s" % (
                prefix, lemmaprefix, lemma, unicode(inflt)))
              continue
            frob_exact(inflt, "2", lemmaprefix, pagemsg, notes)
        else:
          if infl == 1:
            if infltn != "la-conj-1st":
              pagemsg("WARNING: Saw mismatching conjugation template for first-conjugation verb %s: %s" % (
                lemma, unicode(inflt)))
              continue
            if deponent:
              if not lemma.endswith("or"):
                errpagemsg("First-conjugation deponent lemma should end in -or: %s" % lemma)
                return None, None
              arg1 = lemma[:-2]
              if vsup == arg1 + u"ātum":
                arg2 = ["", arg1 + u"āt"]
              else:
                arg2 = truncate_ending(vsup, "um", "First-conjugation deponent supine")
                if arg2 is None:
                  return None, None
              arg3 = ""
            else:
              if not lemma.endswith(u"ō"):
                errpagemsg(u"First-conjugation lemma should end in -ō: %s" % lemma)
                return None, None
              arg1 = lemma[:-1]
              if vperf == arg1 + u"āvī":
                arg2 = ["", arg1 + u"āv"]
              else:
                arg2 = truncate_ending(vperf, u"ī", "First-conjugation perfect")
                if arg2 is None:
                  return None, None
              if vsup == arg1 + u"ātum":
                arg3 = ["", arg1 + u"āt"]
              else:
                arg3 = truncate_ending(vsup, "um", "First-conjugation supine")
                if arg3 is None:
                  return None, None
          else:
            if (infl == 2 and infltn != "la-conj-2nd" or
                infl == 3 and infltn != "la-conj-3rd" or
                infl == "io" and infltn != "la-conj-3rd-IO" or
                infl == 4 and infltn != "la-conj-4th"):
              pagemsg("WARNING: Saw mismatching conjugation template for infl=%s verb %s: %s" % (
                infl, lemma, unicode(inflt)))
              continue
            if deponent:
              if infl == 2:
                expected_ending = "eor"
              elif infl == 3:
                expected_ending = "or"
              else:
                expected_ending = "ior"
              if not lemma.endswith(expected_ending):
                errpagemsg("Infl=%s deponent lemma should end in -%s: %s" % (
                  infl, expected_ending, lemma))
                return None, None
              arg1 = lemma[:-len(expected_ending)]
              arg2 = truncate_ending(vsup, "um", "Infl=%s deponent supine" % infl)
              if arg2 is None:
                return None, None
              arg3 = ""
            else:
              if infl == 2:
                expected_ending = u"eō"
              elif infl == 3:
                expected_ending = u"ō"
              else:
                expected_ending = u"iō"
              if not lemma.endswith(expected_ending):
                errpagemsg("Infl=%s lemma should end in -%s: %s" % (
                  infl, expected_ending, lemma))
                return None, None
              arg1 = lemma[:-len(expected_ending)]
              arg2 = truncate_ending(vperf, u"ī", "Infl=%s perfect" % infl)
              if arg2 is None:
                return None, None
              arg3 = truncate_ending(vsup, "um", "Infl=%s supine" % infl)
              if arg3 is None:
                return None, None
          frob_exact(inflt, "1", arg1, pagemsg, notes)
          frob_exact(inflt, "2", arg2, pagemsg, notes)
          frob_exact(inflt, "3", arg3, pagemsg, notes)

        # FIXME, handle overrides
        for override in lalib.la_verb_overrides:
          overval = getparam(inflt, override)
          if overval:
            pagemsg("WARNING: Found override %s=%s: %s" % (
              override, overval, unicode(inflt)))

        args = lalib.generate_verb_forms(unicode(inflt), errandpagemsg, expand_text)
        if args is None:
          return None, None

        single_forms_to_process = []
        for key, form in args.iteritems():
          for single_form in form.split(","):
            single_forms_to_process.append((key, single_form))

        for formind, (key, formval) in blib.iter_items(
            single_forms_to_process, get_name=lambda x: x[1]):
          partpos = None
          if key == "pres_actv_ptc":
            partpos = "presactpart"
          elif key in ["perf_actv_ptc", "perf_pasv_ptc"]:
            partpos = "perfpasspart"
          elif key == "futr_actv_ptc":
            partpos = "futactpart"
          elif key == "futr_pasv_ptc":
            partpos = "futpasspart"

          if partpos:
            process_participle(index, lemma, formind, formval, partpos,
                save, verbose)
          else:
            process_form(index, lemma, formind, formval, "verbform",
                find_tag_sets_for_form(args, formval), save, verbose)

        #for formtype in ["pres", "perf", "sup"]:
        #  forms_to_process = []
        #  tag_sets_to_process = []
        #  for key, val in args.iteritems():
        #    if (
        #        (formtype == "pres" and not re.search("(perf|plup|futp|sup)", key) and key != "futr_actv_ptc") or
        #        (formtype == "perf" and key not in ["perf_actv_ptc", "perf_pasv_ptc"] and re.search("(perf|plup|futp)", key)) or
        #        (formtype == "sup" and ("sup" in key or key in ["perf_actv_ptc", "perf_pasv_ptc", "futr_actv_ptc"]))
        #      ):
        #      tag_sets_to_process.append(lalib.form_key_to_tag_set(key))
        #      forms_to_process.append((key, val))
        #  single_forms_to_process = []
        #  for key, form in forms_to_process:
        #    for single_form in form.split(","):
        #      single_forms_to_process.append((key, single_form))

        #  for formind, (key, formval) in blib.iter_items(
        #      single_forms_to_process, get_name=lambda x: x[1]):

  secbody = "".join(unicode(x) for x in parsed_subsections)
  sections[j] = secbody + sectail
  return "".join(sections), notes

parser = blib.create_argparser("Clean up usage of macrons in Latin non-lemma forms")
parser.add_argument("--direcfile", help="File containing directives of lemmas to process.")
parser.add_argument("--dry-run", help="Just show what would be checked, don't actually check references.", action="store_true")
args = parser.parse_args()
start, end = blib.parse_start_end(args.start, args.end)

direcfile = args.direcfile.decode("utf-8")

lemmas = []

for line in codecs.open(direcfile, "r", "utf-8"):
  line = line.rstrip('\n')
  if line.startswith("*"):
    line = line[1:]
    msg("Need to investigate: %s" % line)
  if line.startswith("#"):
    continue
  line = re.sub(r" *\[.*\]$", "", line)
  parts = line.split(" ")
  if len(parts) == 2 and parts[0] in ["adv", "num", "phr", "prov"]:
    pass
  elif (len(parts) == 2 or len(parts) == 3) and parts[0] in [
      "n1", "n2", "n3", "n4", "n5", "pn1", "pn2", "pn3", "pn4", "pn5",
      "num1", "a1", "a3"
  ]:
    # noun or adjective
    if len(parts) == 3:
      pos, lemma, explicit_stem = parts
    else:
      pos, lemma = parts
      explicit_stem = None
    m = re.search("^(n|pn|a|num)([1-5])$", pos)
    code_to_pos = {"n": "noun", "pn": "propernoun", "a": "adj", "num": "numadj"}
    pos = code_to_pos[m.group(1)]
    infl = int(m.group(2))
  
    lemmas.append((pos, infl, lemma, explicit_stem))

  elif len(parts) == 2 and parts[0] in ["v1", "v4"]:
    # regular verb
    pos, lemma = parts
    m = re.search("^v([14])$", pos)
    infl = int(m.group(1))
    lemmas.append(("verb", infl, lemma, None))
  else:
    pos = "verb"
    stems_lemmas = []
    if len(parts) == 3:
      # deponent verb
      lemma, inf, supine = parts
      if lemma.startswith("*"):
        no_main = True
        lemma = lemma[1:]
      else:
        no_main = False
      if inf.startswith("*"):
        # FIXME
        inf = inf[1:]
      if supine.startswith("*"):
        # FIXME
        supine = supine[1:]
      if inf == "--":
        inf = ""
      if supine == "--":
        supine = ""
      lemmas.append(("verb", None, lemma, [inf, supine]))

    else:
      assert len(parts) == 4
      lemma, inf, perf, supine = parts
      if lemma.startswith("*"):
        no_main = True
        lemma = lemma[1:]
      else:
        no_main = False
      if inf.startswith("*"):
        # FIXME
        inf = inf[1:]
      if perf.startswith("*"):
        # FIXME
        perf = perf[1:]
      if supine.startswith("*"):
        # FIXME
        supine = supine[1:]
      if inf == "--":
        inf = ""
      if perf == "--":
        perf = ""
      if supine == "--":
        supine = ""
      lemmas.append(("verb", None, lemma, [inf, perf, supine]))

for index, (pos, infl, lemma, explicit_stem) in blib.iter_items(lemmas, start, end,
    get_name=lambda lemmas: remove_macrons(lemmas[2])):
  def handler(page, index, parsed):
    return do_process_lemma(index, page, pos, infl, lemma, explicit_stem, args.save, args.verbose)
  blib.do_edit(pywikibot.Page(site, remove_macrons(lemma)), index, handler, save=args.save, verbose=args.verbose)
