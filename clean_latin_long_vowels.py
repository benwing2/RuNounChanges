#!/usr/bin/env python
# -*- coding: utf-8 -*-

# Templates:
#
# Nouns:
# -----
#
# aquila:
#
# {{la-noun|aquila|aquilae|f|first}}
# {{la-decl-1st|aquil}}
#
# abāctor:
#
# {{la-noun|abāctor|abāctōris|m|third}}
# {{la-decl-3rd|abactor}}
#
# abaculus:
#
# {{la-noun|abaculus|abaculī|m|second}}
# {{la-decl-2nd|abacul}}
#
# abdōmen:
#
# {{la-noun|abdōmen|abdōminis|n|third}}
# {{la-decl-3rd-N|abdōmen}}
#
# abomāsum:
#
# {{la-noun|abomāsum|abomāsī|n|second}}
# {{la-decl-2nd-N|abomās}}
#
# accipiter:
#
# {{la-noun|accipiter|accipitris|m|third}}
# {{la-decl-3rd|accipiter}}
#
# ȳ:
#
# {{la-noun|ȳ|indecl=yes}}
#
# dē:
#
# {{head|la|noun|head=dē|{{l|en|indeclinable}}}}
#
# absinthium:
#
# {{la-noun|absinthium|absinthiī|gen2=absinthī|n|second}}
# {{la-decl-2nd-N-ium|absinth}}
#
# lēns:
#
# {{la-noun|lēns|lentis|f|third}}
# {{la-decl-3rd|lēns}}
#
# diēs:
#
# {{la-noun|diēs|diēī|m|g2=f|fifth}}
# {{la-decl-5th-i|d}}
#
# ōs:
#
# {{la-noun|ōs|ōris|n|third}}
# {{la-decl-3rd-N-I|ōs|ōr}}
#
# os:
#
# {{la-noun|os|ossis|n|third}}
# {{la-decl-3rd-N-I|os|oss|gen_pl=ossium}}
#
# cōnsēnsus:
#
# {{la-noun|cōnsēnsus|cōnsēnsūs|m|fourth}}
# {{la-decl-4th|cōnsēns}}
#
# comma:
#
# {{la-noun|comma|commatis|n|third}}
# {{la-decl-3rd-N|comma}}
#
# colon:
#
# {{la-noun|colon|colī|n|second}}
# {{la-decl-2nd-N-Greek|col}}
#
# gas:
#
# {{la-noun|gas|gasis|n|third}}
# {{la-decl-3rd|gas|gas}}
#
# phoenīx:
#
# {{la-noun|phoenīx|phoenīcis|f|third}}
# {{la-decl-3rd-I|phoenīx}}
# {{la-noun|phoenīx|phoenīcis|m|third}}
# {{la-decl-3rd|phoenīx}}
#
# Proper nouns:
# -------------
#
# Belgium:
#
# {{la-proper noun|Belgium|Belgiī|n|second}}
# {{la-decl-2nd-N|num=sg|Belgi}}
#
# Isrāēl:
#
# {{la-proper noun|Isrāēl||m|indecl=1}}<br/>
# {{la-proper noun|Isrāēl|Isrāēlis|m|third}}
# {{la-decl-3rd|num=sg|Isrāēl|Isrāēl}}
#
# Abaddōn:
#
# {{head|la|proper noun|head=Abaddōn|g=m|indeclinable}}
#
# Andorra:
#
# {{la-proper noun|Andorra|Andorrae|f|first}}
# {{la-decl-1st|loc=1|num=sg|Andorr}}
#
# Niger:
#
# {{la-proper noun|Niger|Nigrī|m|second}}
# {{la-decl-2nd-er|Niger|Nigr}}
# {{la-proper noun|Niger|Nigris|m|third}}
# {{la-decl-3rd|num=sg|Niger|acc_sg=Nigrim}}
#
# Achilles:
#
# {{la-proper noun|Achilles|Achillis|m|third}}
# {{la-decl-3rd|num=sg|Achilles|Achill}}
#
# Pronouns:
# ---------
#
# is:
#
# {{head|la|pronoun}}
# {{la-decl-irreg|is}}
#
# Verbs:
# ------
#
# līberō:
#
# {{la-verb|līberō|līberāre|līberāvī|līberātum|conj=1}}
# {{la-conj-1st|līber|līberāv|līberāt|sync_perf=poet|p3inf=1}}
#
# ferō:
#
# {{la-verb|ferō|ferre|tulī|perf2=tetulī|lātum|conj=3|pattern=irreg}}
# {{la-conj-irreg|fero}}
#
# eō:
#
# {{la-verb|eō|īre|iī|itum|conj=irreg}}
# {{la-conj-irreg|eo|p3inf=1}}
#
# for:
#
# {{la-verb|for|fārī|fātus sum|conj=1|pattern=depon}}
# {{la-conj-1st|type=depon|f|fāt|p3inf=1}}
#
# abdīcō:
#
# {{la-verb|abdīcō|abdīcere|abdīxī|abdictum|conj=irreg}}
# {{la-conj-irreg|dico|ab}}
#
# abdō:
#
# {{la-verb|abdō|abdere|abdidī|abditum|conj=3}}
# {{la-conj-3rd|abd|abdid|abdit}}
#
# alō:
#
# {{la-verb|alō|alere|aluī|altum|sup2=alitum|conj=3}}
# {{la-conj-3rd|al|alu|alt}}
# {{la-conj-3rd|al|alu|alit}}
#
# lingō:
#
# {{la-verb|lingō|lingere|linxī|linctum|conj=3}}
# {{la-conj-3rd|ling|linx|linct}}
#
# vērō:
#
# {{la-verb|vērō|vērāre|conj=1|pattern=nopass-noperf}}
# {{la-conj-1st|type=nopass-noperf|vēr}}
#
# lābor:
#
# {{la-verb|lābor|lābī|lāpsus sum|conj=3|pattern=depon}}
# {{la-conj-3rd|type=depon|lāb|lāps}}
#
# videō:
#
# {{la-verb|videō|vidēre|vīdī|vīsum|conj=2}}
# {{la-conj-2nd|vid|vīd|vīs|p3inf=1}} 
#
# Participles:
# ------------
#
# accūsāns:
#
# {{la-present participle|accūs|ans}}
# {{la-decl-3rd-part|accūsāns}}
#
# sapiēns:
#
# {{la-present participle|sapi|ens}}
# {{la-decl-3rd-part|sapiēns}}
#
# abditus:
#
# {{la-perfect participle|abdit}}
# {{la-decl-1&2|abdit}}
#
# futūrus:
#
# {{la-future participle|futūr}}
# {{la-decl-1&2|futūr}}
#
# rendus:
#
# {{la-gerundive|rend}}
# {{la-decl-1&2|rend}}
#
# Prefixes:
# ---------
#
# ā-:
#
# {{head|la|prefix|head=ā-}}
#
# Prepositions:
# -------------
#
# in:
#
# {{la-prep|accusative|ablative}}
#
# Adjectives:
# -----------
#
# phoenīx:
#
# {{la-adj-3rd-1E|phoenīx|phoenīcis}}
# {{la-decl-3rd-1E|type=par|phoenīx|phoenīc}}
#
# incōmptus:
#
# {{la-adj-1&2|incōmptus|incōmpta|incōmptum}}
# {{la-decl-1&2|incōmpt}}
#
# Adverbs:
# --------
#
# lentē:
#
# {{la-adv|lentē}}
#
# ferē:
#
# {{la-adv|ferē|-}}
#
# Interjections:
# --------------
#
# ēn:
#
# {{la-interj|ēn}}
#
# tax:
#
# {{head|la|interjection}}
#
# Letters:
# --------
#
# o:
#
# {{head|la|letter}}
#
# Abbreviations:
# --------------
#
# JUL:
#
# {{head|la|abbreviation}}
#
# Adjective forms:
# ----------------
#
# {{la-adj-form|abdominālēs}}
# # {{inflection of|abdominālis||nom|m|p|lang=la}}
# # {{inflection of|abdominālis||nom|f|p|lang=la}}
# # {{inflection of|abdominālis||acc|m|p|lang=la}}
# # {{inflection of|abdominālis||acc|f|p|lang=la}}
# # {{inflection of|abdominālis||voc|m|p|lang=la}}
# # {{inflection of|abdominālis||voc|f|p|lang=la}}
#
# Verb forms:
# -----------
#
# {{la-verb-form|abdūce}}
#
# # {{inflection of|abdūcō||2|s|pres|actv|impr|lang=la}}
#
# Noun forms:
# -----------
#
# {{la-noun-form|diē}}
#
# # {{inflection of|diēs||abl|s|lang=la|nodot=1}} (&quot;[[day]]&quot;).
#
# Participle forms:
# -----------------
#
# abrāse:
#
# {{la-part-form|abrāse}}
#
# # {{inflection of|abrāsus||voc|m|s|lang=la}}
#
# Pronoun forms:
# --------------
#
# mī:
#
# {{la-pronoun-form|mī}}
# {{head|la|pronoun form|head=mī}}
#


# FIXME:
#
# 1. DONE: Pronunciation templates.
# 2. DONE: Make sure lang and pos in {{head}} agree.
# 3. DONE: Verb overrides.
# 4. * before supine and perfect (maybe not needed).
# 5. DONE: For participles, check the etymology section to make sure the lemma
#    is correct.
# 6. DONE: Numbers, phrases, etc.
# 7. DONE: Handle multipart tag sets.
# 8. Handle irregular verb conjugations, which may have prefixes.
# 9. MOSTLY DONE: Review latin-macrons.txt against http://www.alatius.com/latin/bennetthidden.html, which corrects Bennett. Ask JohnC5 about this.
# 10. Pluralia tantum lemmas, e.g. nuptiae.
#
# Examples of disagreements with Bennett:
#
# Bennett: dēlīctus/relīctus (dēlinquō/relinquō), fīctus (fingō), pīctus (pingō), trāctus (trahō); Allen: dēlĭctus/relĭctus, fĭctus, pĭctus, trăctus
# Bennett: ārdeō, ārsī, ārsurus; Michelson: ărd- in Lindsay, Sommer, Brugmann
# Bennett: fīrmus; Michelson: fĭrmus or fīrmus
# Bennett: ūlna; Michelson: ŭlna
# Bennett: ūstus (ūrō); Michelson: ŭstus
# Bennett: ūsque, nūsque, quoūsque; Buck: ŭsque, etc.
# Bennett: cŭnctor: Michelson: cūnctor
# Bennett: not all vowels are lengthened before -nct; Michelson, Allen: all vowels lengthened before -nct
# Bennett: earlier version: most vowels long before -gn; later version changed his mind

# Clean up use of macrons in Latin lemmas.

import pywikibot, re, sys, codecs, argparse

import blib
from blib import getparam, rmparam, msg, errandmsg, site, tname

import lalib
from lalib import remove_macrons


# Return True if changed.
def frob_param(t, param, stem_or_exact, is_exact, pagemsg, notes, split_slashes=False, no_warn=False):
  origt = unicode(t)
  origval = getparam(t, param)
  if split_slashes:
    vals = origval.split("/")
  else:
    vals = [origval]
  newvals = []
  for val in vals:
    no_macrons_val = remove_macrons(val)
    assert len(no_macrons_val) == len(val)
    if type(stem_or_exact) is not list:
      stem_or_exact = [stem_or_exact]
    for st in stem_or_exact:
      no_macrons_st = remove_macrons(st)
      assert len(no_macrons_st) == len(st)
      if is_exact:
        if no_macrons_val == no_macrons_st:
          newvals.append(st)
          break
      else:
        if no_macrons_val.startswith(no_macrons_st):
          newvals.append(st + val[len(st):])
          break
    else:
      if val or not no_warn:
        # no break
        if is_exact:
          pagemsg("WARNING: Unable to match value %s in param %s against replacement(s) %s" % (
            val, param, ",".join(stem_or_exact)))
        else:
          pagemsg("WARNING: Unable to match value %s in param %s against replacement stem(s) %s" % (
            val, param, ",".join(stem_or_exact)))
      newvals.append(val)
  newval = "/".join(newvals)
  if newval != origval:
    t.add(param, newval)
    pagemsg("Replaced %s with %s" % (origt, unicode(t)))
    notes.append("updated macrons in %s per Bennett (with corrections by Allen and Michelson)" % tname(t))
    return True
  return False

# Return True if changed.
def frob_stem(t, param, stem, pagemsg, notes, split_slashes=False, no_warn=False):
  return frob_param(t, param, stem, False, pagemsg, notes, split_slashes=split_slashes,
      no_warn=no_warn)

# Return True if changed.
def frob_exact(t, param, newval, pagemsg, notes, split_slashes=False, no_warn=False):
  return frob_param(t, param, newval, True, pagemsg, notes, split_slashes=split_slashes,
      no_warn=no_warn)

# Return True if anything changed.
def frob_chain_stem(t, param, stem, pagemsg, notes, split_slashes=False, no_warn=False):
  changed = False
  if type(param) is list:
    first, rest = param
  else:
    first = param
    rest = param
  if first:
    if frob_stem(t, first, stem, pagemsg, notes, split_slashes=split_slashes,
        no_warn=no_warn):
      changed = True
  num = 2
  while getparam(t, "%s%s" % (rest, num)):
    if frob_stem(t, "%s%s" % (rest, num), stem, pagemsg, notes, split_slashes=split_slashes,
        no_warn=no_warn):
      changed = True
    num += 1
  return changed

# Return True if anything changed.
def frob_chain_exact(t, param, newval, pagemsg, notes, split_slashes=False, no_warn=False):
  changed = False
  if type(param) is list:
    first, rest = param
  else:
    first = param
    rest = param
  if first:
    if frob_exact(t, first, newval, pagemsg, notes, split_slashes=split_slashes,
        no_warn=no_warn):
      changed = True
  num = 2
  while getparam(t, "%s%s" % (rest, num)):
    if frob_exact(t, "%s%s" % (rest, num), newval, pagemsg, notes, split_slashes=split_slashes,
        no_warn=no_warn):
      changed = True
    num += 1
  return changed

def find_heads_and_defns(page, pagemsg):
  text = unicode(page.text)

  retval = lalib.find_latin_section(text, pagemsg)
  if retval is None:
    return None

  sections, j, secbody, sectail, has_non_latin = retval

  subsections = re.split("(^==+[^=\n]+==+\n)", secbody, 0, re.M)

  parsed_subsections = [None] * len(subsections)

  headwords = []
  pronun_sections = []
  etym_sections = []

  most_recent_headword = None
  most_recent_pronun_section = None
  most_recent_etym_section = None

  def new_headword(header, level, subsection, head_template, is_lemma):
    retval = {
      'head_template': head_template,
      'header': header,
      'is_lemma': is_lemma,
      'infl_templates': [],
      'infl_of_templates': [],
      'subsection': subsection,
      'level': level,
      'pronun_section': most_recent_pronun_section,
      'etym_section': most_recent_etym_section,
    }
    if most_recent_pronun_section:
      most_recent_pronun_section['headwords'].append(retval)
    if most_recent_etym_section:
      most_recent_etym_section['headwords'].append(retval)
    return retval

  def new_pronun_section(header, level, subsection):
    return {
      'header': header,
      'pronun_templates': [],
      'headwords': [],
      'subsection': subsection,
      'level': level,
    }

  def new_etym_section(header, level, subsection):
    return {
      'header': header,
      'headwords': [],
      'subsection': subsection,
      'level': level,
    }

  for k in xrange(len(subsections)):
    if k < 2 or (k % 2) == 1:
      parsed_subsections[k] = blib.parse_text(subsections[k])
      continue
    m = re.search("^(==+)([^=\n]+)", subsections[k - 1])
    level = len(m.group(1))
    header = m.group(2)
    headword_templates_in_section = []

    if most_recent_headword and most_recent_headword['level'] >= level:
      headwords.append(most_recent_headword)
      most_recent_headword = None

    is_pronun_section = header.startswith('Pronunciation')
    if is_pronun_section:
      if most_recent_pronun_section:
        pronun_sections.append(most_recent_pronun_section)
      most_recent_pronun_section = new_pronun_section(header, level, k)
    elif most_recent_pronun_section and most_recent_pronun_section['level'] > level:
      pronun_sections.append(most_recent_pronun_section)
      most_recent_pronun_section = None

    is_etym_section = header.startswith('Etymology')
    if is_etym_section:
      if most_recent_etym_section:
        etym_sections.append(most_recent_etym_section)
      most_recent_etym_section = new_etym_section(header, level, k)
    elif most_recent_etym_section and most_recent_etym_section['level'] > level:
      etym_sections.append(most_recent_etym_section)
      most_recent_etym_section = None

    parsed = blib.parse_text(subsections[k])
    parsed_subsections[k] = parsed
    for t in parsed.filter_templates():
      tn = tname(t)
      if tn == "la-IPA":
        if is_pronun_section:
          most_recent_pronun_section['pronun_templates'].append(t)
        else:
          pagemsg("WARNING: Pronunciation template %s in %s section, not pronunciation section" % (
            unicode(t), header))
      elif tn in lalib.la_headword_templates or tn == "head":
        if tn == "head":
          if getparam(t, "1") != "la":
            errandpagemsg("WARNING: Wrong-language {{head}} template in Latin section: %s" % unicode(t))
            continue
          head_pos = getparam(t, "2")
          if head_pos not in lalib.la_poses:
            pagemsg("WARNING: Unrecognized part of speech %s" % pos)
        if headword_templates_in_section:
          pagemsg("WARNING: Found additional headword template in same section: %s" % unicode(t))
          headwords.append(most_recent_headword)
        elif most_recent_headword:
          pagemsg("WARNING: Found headword template nested under previous one: %s" % unicode(t))
          headwords.append(most_recent_headword)
        most_recent_headword = new_headword(header, level, k, t,
          tn in lalib.la_lemma_headword_templates or (
            tn == "head" and head_pos in lalib.la_lemma_poses))
        headword_templates_in_section.append(t)
      elif tn in lalib.la_infl_templates:
        if not most_recent_headword:
          pagemsg("WARNING: Found inflection template not under headword template: %s" % unicode(t))
        else:
          most_recent_headword['infl_templates'].append(t)
      elif tn in lalib.la_infl_of_templates:
        if not most_recent_headword:
          pagemsg("WARNING: Found inflection-of template not under headword template: %s" % unicode(t))
        else:
          most_recent_headword['infl_of_templates'].append(t)

  if most_recent_headword:
    headwords.append(most_recent_headword)
  if most_recent_pronun_section:
    pronun_sections.append(most_recent_pronun_section)
  if most_recent_etym_section:
    etym_sections.append(most_recent_etym_section)


  return (
    sections, j, secbody, sectail, has_non_latin, subsections,
    parsed_subsections, headwords, pronun_sections, etym_sections
  )

def find_tag_sets_for_form(args, form):
  tag_sets = []
  for key, formspec in args.iteritems():
    forms = formspec.split(",")
    if form in forms:
      tag_sets.append(lalib.form_key_to_tag_set(key))
  return tag_sets

# Return True if changed.
def process_pronun_template(t, lemma, pagemsg, notes):
  if not getparam(t, "1"):
    if remove_macrons(lemma) != lemma:
      eccl = getparam(t, "eccl")
      rmparam(t, "eccl")
      t.add("1", lemma)
      if eccl:
        t.add("eccl", eccl)
      notes.append("add pronunciation to {{la-IPA}}")
      return True
  else:
    return frob_exact(t, "1", lemma, pagemsg, notes)

def process_pronun_templates(pronun_section, lemma, pagemsg, notes):
  if not pronun_section:
    return
  pronun_templates = pronun_section['pronun_templates']
  if len(pronun_templates) > 1:
    pagemsg("WARNING: Multiple pronunciation templates, not changing: %s" %
      ",".join(unicode(t) for t in pronun_templates))
  elif len(pronun_templates) == 1:
    pront = pronun_templates[0]
    origpront = unicode(pront)
    pagetitle = remove_macrons(lemma)
    headwords = set(lalib.la_get_headword_from_template(hw['head_template'], pagetitle) for hw in pronun_section['headwords'])
    if len(list(headwords)) > 1:
      pagemsg("WARNING: One pronunciation template %s but multiple headword templates with different headwords, not changing: %s" %
        (origpront, ",".join(unicode(hw['head_template']) for hw in pronun_section['headwords'])))
    elif process_pronun_template(pront, lemma, pagemsg, notes):
      if len(pronun_section['headwords']) > 1:
        pagemsg("WARNING: Multiple headwords for changed pronunciation template (originally %s, changed to %s), check manually: %s" % (
          origpront, unicode(pront),
          ",".join(unicode(hw['head_template']) for hw in pronun_section['headwords'])))

def do_process_form(index, page, lemma, formind, formval, pos, tag_sets_to_process, save, verbose):
  pagetitle = unicode(page.title())

  def pagemsg(txt):
    msg("Page %s %s: form %s %s: %s" % (index, lemma, formind, formval, txt))

  def errandpagemsg(txt):
    errandmsg("Page %s %s: form %s %s: %s" % (index, lemma, formind, formval, txt))

  def expand_text(tempcall):
    return blib.expand_text(tempcall, pagetitle, pagemsg, verbose)

  if "[" in formval:
    pagemsg("Skipping form value %s with link in it" % formval)
    return None, None

  page = pywikibot.Page(site, pagetitle)
  if not page.exists():
    pagemsg("Skipping form value %s, page doesn't exist" % formval)
    return None, None

  if pos == "verbform":
    expected_head_template = "la-verb-form"
    expected_pos = "verb form"
    expected_header_pos = "Verb"
  elif pos == "adjform":
    expected_head_template = "la-adj-form"
    expected_pos = "adjective form"
    expected_header_pos = "Adjective"
  elif pos == "nounform":
    expected_head_template = "la-noun-form"
    expected_pos = "noun form"
    expected_header_pos = "Noun"
  elif pos == "propernounform":
    expected_head_template = "la-proper noun-form"
    expected_pos = "proper noun form"
    expected_header_pos = "Proper noun"
  elif pos == "partform":
    expected_head_template = "la-part-form"
    expected_pos = "participle form"
    expected_header_pos = "Participle"
  elif pos == "numform":
    expected_head_template = "la-num-form"
    expected_pos = "numeral form"
    expected_header_pos = "Numeral"
  else:
    raise ValueError("Unrecognized part of speech %s" % pos)

  pagemsg("Processing")

  retval = find_heads_and_defns(page, pagemsg)
  if retval is None:
    return None, None

  (
    sections, j, secbody, sectail, has_non_latin, subsections,
    parsed_subsections, headwords, pronun_sections, etym_sections
  ) = retval

  notes = []

  tag_sets_to_process = True if tag_sets_to_process is True else (
    sorted(tag_sets_to_process)
  )
  frozenset_tag_sets_to_process = True if tag_sets_to_process is True else set(
    frozenset(tag_set) for tag_set in tag_sets_to_process
  )
  for headword in headwords:
    ht = headword['head_template']
    tn = tname(ht)
    saw_infl = False
    good_tag_sets = []
    saw_other_infl = False
    bad_tag_sets = []
    other_lemmas = []
    found_head = False

    if tn == "head":
      if getparam(ht, "1") != "la":
        errandpagemsg("WARNING: Wrong-language {{head}} template in Latin section: %s" % unicode(ht))
        continue
      head_pos = getparam(ht, "2")
      if head_pos != expected_pos:
        pagemsg("Skipping incorrect part of speech %s: %s" % (head_pos, unicode(ht)))
        continue
      head_param = "head"
      found_head = True

    if tn == expected_head_template:
      head_param = "1"
      found_head = True

    if not found_head:
      continue

    if headword['header'] != expected_header_pos:
      pagemsg("WARNING: Bad section header %s != %s for headword template %s" % (
        headword['header'], expected_header_pos, unicode(ht)))

    for t in headword['infl_of_templates']:
      lang = getparam(t, "lang")
      if lang:
        lemma_param = 1
      else:
        lang = getparam(t, "1")
        lemma_param = 2
      if lang != "la":
        errandpagemsg("WARNING: In Latin section, found {{inflection of}} for different language %s: %s" % (
          lang, unicode(t)))
        return None, None
      actual_lemma = getparam(t, str(lemma_param))
      if remove_macrons(actual_lemma) == remove_macrons(lemma):
        # fetch tags
        tags = []
        for param in t.params:
          pname = unicode(param.name).strip()
          pval = unicode(param.value).strip()
          if re.search("^[0-9]+$", pname):
            if int(pname) >= lemma_param + 2:
              if pval:
                tags.append(pval)
        # split tags into tag sets (which may be multipart) and further
        # split any multipart tag sets into component tag sets
        tag_sets = [tag_set
          for maybe_multipart_tag_set in lalib.split_tags_into_tag_sets(tags)
          for tag_set in lalib.split_multipart_tag_set(maybe_multipart_tag_set)
        ]
        for tag_set in tag_sets:
          canon_tag_set = lalib.canonicalize_tag_set(tag_set)
          if tag_sets_to_process is True or frozenset(canon_tag_set) in frozenset_tag_sets_to_process:
            saw_infl = True
            good_tag_sets.append(canon_tag_set)
          else:
            expected_tag_sets = "|".join(lalib.combine_tag_set_group(tag_sets_to_process))
            pagemsg("Found {{inflection of}} for correct lemma but wrong tag set %s (expected %s): %s" % (
              "|".join(canon_tag_set), expected_tag_sets, unicode(t)))
            saw_other_infl = True
            bad_tag_sets.append(canon_tag_set)
      else:
        pagemsg("Found {{inflection of}} for different lemma %s: %s" % (
          actual_lemma, unicode(t)))
        saw_other_infl = True
        other_lemmas.append(actual_lemma)

    if saw_infl and saw_other_infl:
      good_tag_set_str = ",".join("|".join(tag_set) for tag_set in good_tag_sets)
      bad_msgs = []
      if other_lemmas:
        bad_msgs.append("different lemma(s) %s" % ",".join(other_lemmas))
      if bad_tag_sets:
        bad_msgs.append("wrong tag set(s) %s" % ",".join("|".join(tag_set) for tag_set in bad_tag_sets))
      pagemsg("WARNING: Found mixture of inflection-of templates for good tag set(s) %s and inflection-of templates for %s, won't frob" % (
        good_tag_set_str, " and ".join(bad_msgs)))
      continue

    if not saw_infl:
      continue

    frob_exact(ht, head_param, formval, pagemsg, notes)
    for t in headword['infl_of_templates']:
      lang = getparam(t, "lang")
      if lang:
        lemma_param = 1
      else:
        lang = getparam(t, "1")
        lemma_param = 2
      assert lang == "la"
      frob_exact(t, str(lemma_param), lemma, pagemsg, notes)

    process_pronun_templates(headword['pronun_section'], formval, pagemsg, notes)

  secbody = "".join(unicode(x) for x in parsed_subsections)
  sections[j] = secbody + sectail
  return "".join(sections), notes

def process_form(index, lemma, formind, formval, pos, tag_sets_to_process, save, verbose):
  def handler(page, index, parsed):
    return do_process_form(index, page, lemma, formind, formval, pos, tag_sets_to_process, save, verbose)
  blib.do_edit(pywikibot.Page(site, remove_macrons(formval)), index, handler, save=save, verbose=verbose)

def process_all_forms(args, index, lemma, pos, save, verbose):
  single_forms_to_process = []
  for key, form in args.iteritems():
    for single_form in form.split(","):
      single_forms_to_process.append((key, single_form))

  for formind, (key, formval) in blib.iter_items(
      single_forms_to_process, get_name=lambda x: x[1]):
    process_form(index, lemma, formind, formval, pos,
        find_tag_sets_for_form(args, formval), save, verbose)

def do_process_participle(index, page, lemma, formind, formval, pos, save, verbose):
  pagetitle = unicode(page.title())

  def pagemsg(txt):
    msg("Page %s %s: form %s %s: %s" % (index, lemma, formind, formval, txt))

  def errandpagemsg(txt):
    errandmsg("Page %s %s: form %s %s: %s" % (index, lemma, formind, formval, txt))

  def expand_text(tempcall):
    return blib.expand_text(tempcall, pagetitle, pagemsg, verbose)

  if "[" in formval:
    pagemsg("Skipping form value %s with link in it" % formval)
    return None, None

  page = pywikibot.Page(site, pagetitle)
  if not page.exists():
    pagemsg("Skipping form value %s, page doesn't exist" % formval)
    return None, None

  if pos == "presactpart":
    expected_head_template = "la-present participle"
    if not re.search(u"[āē]ns$", formval):
      pagemsg("WARNING: Bad present participle form %s, wrong ending" %
        formval)
      return None, None
    expected_head_arg = re.sub(u"[āē]ns$", "", formval)
    expected_decl_template = "la-decl-3rd-part"
    expected_decl_arg = formval
  else:
    if pos == "perfpasspart":
      expected_head_template = "la-perfect participle"
    elif pos == "futactpart":
      expected_head_template = "la-future participle"
    elif pos == "futpasspart":
      expected_head_template = "la-gerundive"
    else:
      raise ValueError("Unrecognized participle part of speech %s" % pos)
    if not formval.endswith("us"):
      pagemsg("WARNING: Bad participle form %s, wrong ending" % formval)
      return None, None
    expected_head_arg = re.sub("us$", "", formval)
    expected_decl_template = "la-decl-1&2"
    expected_decl_arg = expected_head_arg

  pagemsg("Processing")

  retval = find_heads_and_defns(page, pagemsg)
  if retval is None:
    return None, None

  (
    sections, j, secbody, sectail, has_non_latin, subsections,
    parsed_subsections, headwords, pronun_sections, etym_sections
  ) = retval

  notes = []

  for headword in headwords:
    ht = headword['head_template']
    tn = tname(ht)
    saw_infl = False
    saw_other_infl = False
    found_head = False

    if tn == "head":
      if getparam(ht, "1") != "la":
        errandpagemsg("WARNING: Wrong-language {{head}} template in Latin section: %s" % unicode(ht))
        continue
      head_pos = getparam(t, "2")
      if head_pos != "participle":
        pagemsg("Skipping incorrect part of speech %s: %s" % (head_pos, unicode(ht)))
        continue
      param_to_frob = "head"
      frob_val = formval
      found_head = True

    if tn == expected_head_template:
      param_to_frob = "1"
      frob_val = expected_head_arg
      found_head = True

    if not found_head:
      continue

    # Make sure there's an etym section mentioning the correct lemma and
    # no others.
    if not headword['etym_section']:
      pagemsg("WARNING: Missing etymology section for participle, don't know if it's for the correct verb, skipping")
      continue
    parsed = parsed_subsections[headword['etym_section']['subsection']]
    saw_lemma_in_etym = False
    saw_wrong_lemma_in_etym = False
    for et in parsed.filter_templates():
      etn = tname(et)
      if etn == "m":
        actual_lemma = getparam(et, "2")
        if remove_macrons(lemma) == remove_macrons(actual_lemma):
          saw_lemma_in_etym = True
        else:
          pagemsg("WARNING: Saw wrong lemma %s != %s in Etymology section for participle: %s" % (
            actual_lemma, lemma, unicode(et)))
          saw_wrong_lemma_in_etym = True
    if saw_lemma_in_etym and saw_wrong_lemma_in_etym:
      pagemsg("WARNING: Saw both correct and wrong lemma in Etymology section for participle, skipping")
      continue
    if saw_wrong_lemma_in_etym:
      continue
    if not saw_lemma_in_etym:
      pagemsg("WARNING: Didn't see any lemma in Etymology section for participle, don't know if it's for correct verb, skipping")
      continue

    frob_exact(ht, param_to_frob, frob_val, pagemsg, notes)

    for inflt in headword['infl_templates']:
      infltn = tname(inflt)
      if infltn != expected_decl_template:
        pagemsg("WARNING: Saw bad declension template for participle: %s" % (
          unicode(inflt)))
        continue
      frob_exact(inflt, "1", expected_decl_arg, pagemsg, notes)

      args = lalib.generate_adj_forms(unicode(inflt), errandpagemsg, expand_text)
      if args is None:
        return None, None

      process_all_forms(args, index, formval, "partform", save, verbose)

    process_pronun_templates(headword['pronun_section'], formval, pagemsg, notes)

  secbody = "".join(unicode(x) for x in parsed_subsections)
  sections[j] = secbody + sectail
  return "".join(sections), notes

def process_participle(index, lemma, formind, formval, pos, save, verbose):
  def handler(page, index, parsed):
    return do_process_participle(index, page, lemma, formind, formval, pos, save, verbose)
  blib.do_edit(pywikibot.Page(site, remove_macrons(formval)), index, handler, save=save, verbose=verbose)

def do_process_lemma(index, page, pos, explicit_infl, lemma, explicit_stem, save, verbose):
  pagetitle = unicode(page.title())
  def pagemsg(txt):
    msg("Page %s %s: %s" % (index, pagetitle, txt))

  def errandpagemsg(txt):
    errandmsg("Page %s %s: %s" % (index, pagetitle, txt))

  def expand_text(tempcall):
    return blib.expand_text(tempcall, pagetitle, pagemsg, verbose)

  pagemsg("Processing")

  retval = find_heads_and_defns(page, pagemsg)
  if retval is None:
    return None, None

  (
    sections, j, secbody, sectail, has_non_latin, subsections,
    parsed_subsections, headwords, pronun_sections, etym_sections
  ) = retval

  notes = []


  for headword in headwords:
    ht = headword['head_template']
    tn = tname(ht)

    found_head_template = False
    found_matching_head = False

    if tn == "head":
      if getparam(ht, "1") != "la":
        errandpagemsg("WARNING: Wrong-language {{head}} template in Latin section: %s" % unicode(ht))
        continue

      pos_to_full_pos = {
        "noun": "noun",
        "propernoun": "proper noun",
        "adj": "adjective",
        "adv": "adverb",
        "phr": "phrase",
        "prov": "proverb", 
        "verb": "verb",
        "num": "numeral",
        "numadj": "numeral",
      }
      if getparam(ht, "2") == pos_to_full_pos[pos]:
        frob_exact(ht, "head", lemma, pagemsg, notes)
        found_head_template = True
        found_matching_head = True

    if pos == "adv" and tn == "la-adv":
      found_matching_head = True
      frob_exact(ht, "1", lemma, pagemsg, notes)
      stem = lalib.infer_adv_stem(lemma)
      frob_stem(ht, "2", stem, pagemsg, notes, no_warn=True)
      frob_stem(ht, "3", stem, pagemsg, notes, no_warn=True)
      frob_chain_stem(ht, "comp", stem, pagemsg, notes, no_warn=True)
      frob_chain_stem(ht, "sup", stem, pagemsg, notes, no_warn=True)

    elif pos == "phr" and tn == "la-phrase":
      found_matching_head = True
      frob_exact(ht, "head", lemma, pagemsg, notes)

    elif pos == "num" and tn == "la-num-card":
      found_matching_head = True
      if lemma.endswith(u"ī"):
        stem = lemma[:-1]
      else:
        stem = lemma
      frob_exact(ht, "1", stem, pagemsg, notes)

    elif (
      pos == "noun" and (found_head_template or tn == "la-noun") or
      pos == "propernoun" and (found_head_template or tn == "la-proper noun")
    ):
      if explicit_infl == 1:
        if lemma.endswith("a"):
          inferred_stem = lemma[:-1]
        elif lemma.endswith("ae"): # plural
          inferred_stem = lemma[:-2]
        else:
          errandpagemsg("WARNING: Bad 1st-declension noun lemma %s" % lemma)
          return None, None
      elif explicit_infl == 2:
        if lemma.endswith("r"):
          inferred_stem = lemma
        elif lemma.endswith("ius") or lemma.endswith("ium"):
          inferred_stem = lemma[:-3]
        elif lemma.endswith("us") or lemma.endswith("um"):
          inferred_stem = lemma[:-2]
        elif lemma.endswith(u"iī"): # plural
          inferred_stem = lemma[:-2]
        elif lemma.endswith(u"ī"): # plural
          inferred_stem = lemma[:-1]
        # We don't implement neuter plurals to catch errors where
        # n2 is given instead of n1. If we need them, we should make
        # the plurality be specified explicitly, e.g. 'n2p' for n2 plural.
        else:
          errandpagemsg("WARNING: Bad 2nd-declension noun lemma %s" % lemma)
          return None, None
      elif explicit_infl == 3:
        inferred_stem = lalib.infer_3rd_decl_stem(lemma)
      elif explicit_infl == 4:
        if lemma.endswith("us"):
          inferred_stem = lemma[:-2]
        else:
          errandpagemsg("WARNING: Bad 4th-declension noun lemma %s" % lemma)
          return None, None
      elif explicit_infl == 5:
        if lemma.endswith(u"ēs"):
          inferred_stem = lemma[:-2]
        else:
          errandpagemsg("WARNING: Bad 5th-declension noun lemma %s" % lemma)
          return None, None
      else:
        errandpagemsg("WARNING: Unrecognized infl %s" % explicit_infl)
        return None, None

      stem = explicit_stem or inferred_stem

      if not found_head_template:
        infl_to_ordinal = {
          1: 'first',
          2: 'second',
          3: 'third',
          4: 'fourth',
          5: 'fifth'
        }

        if (remove_macrons(lemma) == remove_macrons(getparam(ht, "1")) and
            getparam(ht, "4") == infl_to_ordinal[explicit_infl]):
          frob_exact(ht, "1", lemma, pagemsg, notes)
          frob_chain_stem(ht, ["2", "gen"], stem, pagemsg, notes)
        else:
          continue

      found_matching_head = True

      for inflt in headword['infl_templates']:
        infltn = tname(inflt)
        if infltn not in lalib.la_noun_decl_templates:
          pagemsg("WARNING: Saw bad declension template for infl=%s noun %s: %s" % (
            explicit_infl, lemma, unicode(inflt)))
          continue
        m = re.search('^la-decl-(.*)$', infltn)
        decltype = lalib.la_noun_decl_suffix_to_decltype[m.group(1)]
        if type(decltype) is tuple:
          decl = decltype[0]
          if len(decltype) >= 2:
            declsubtypes = decltype[1].split("-")
          else:
            declsubtypes = []
        else:
          decl = decltype
          declsubtypes = []
        if decl is None:
          pagemsg("WARNING: Don't know how to handle decl: %s" % unicode(inflt))
          continue
        if decl != str(explicit_infl):
          pagemsg("WARNING: Wrong decl %s != expected %s for decl template: %s" % (
            decl, explicit_infl, unicode(inflt)))
          continue
        if explicit_infl == 1:
          arg1 = inferred_stem
          arg2 = ""
        elif explicit_infl == 2:
          if lemma.endswith("us"):
            if "ius" in declsubtypes:
              if not lemma.endswith("ius"):
                pagemsg("WARNING: Declension template requires lemma in -ius but lemma %s doesn't end that way: %s" % (
                  lemma, unicode(inflt)))
                continue
              arg1 = lemma[:-3]
              arg2 = ""
            else:
              arg1 = lemma[:-2]
              arg2 = ""
          elif lemma.endswith(u"ī"):
            if "ius" in declsubtypes:
              if not lemma.endswith(u"iī"):
                pagemsg(u"WARNING: Declension template requires lemma in -iī but lemma %s doesn't end that way: %s" % (
                  lemma, unicode(inflt)))
                continue
              arg1 = lemma[:-2]
              arg2 = ""
            else:
              arg1 = lemma[:-1]
              arg2 = ""
          elif lemma.endswith("um"):
            if "ium" in declsubtypes:
              if not lemma.endswith("ium"):
                pagemsg("WARNING: Declension template requires lemma in -ium but lemma %s doesn't end that way: %s" % (
                  lemma, unicode(inflt)))
                continue
              arg1 = lemma[:-3]
              arg2 = ""
            else:
              arg1 = lemma[:-2]
              arg2 = ""
          elif lemma.endswith("r"):
            arg1 = lemma
            if explicit_stem and explicit_stem != lemma:
              arg2 = explicit_stem
            else:
              arg2 = ["", lemma]
          else:
            errandpagemsg("WARNING: Bad 2nd-declension noun lemma %s" % lemma)
            return None, None
        elif explicit_infl == 3:
          arg1 = lemma
          if explicit_stem and explicit_stem != inferred_stem:
            arg2 = explicit_stem
          else:
            arg2 = ["", inferred_stem]
        elif explicit_infl == 4:
          arg1 = inferred_stem
          arg2 = ""
        elif explicit_infl == 5:
          if not lemma.endswith(u"ēs"):
            errandpagemsg("WARNING: Bad 5th-declension noun lemma %s" % lemma)
            return None, None
          if "i" in declsubtypes:
            if not lemma.endswith(u"iēs"):
              pagemsg(u"WARNING: Declension template requires lemma in -iēs but lemma %s doesn't end that way: %s" % (
                lemma, unicode(inflt)))
              continue
            arg1 = lemma[:-3]
            arg2 = ""
          else:
            arg1 = lemma[:-2]
            arg2 = ""
        else:
          errandpagemsg("WARNING: Unrecognized infl %s" % explicit_infl)
          return None, None

        if remove_macrons(arg1) != remove_macrons(getparam(inflt, "1")):
          pagemsg("WARNING: lemma stem %s doesn't match template stem: %s" % (
            arg1, unicode(inflt)))
          continue
        param2 = getparam(inflt, "2")
        if type(arg2) is not list:
          arg2 = [arg2]
        actual_matching_arg2 = None
        for matching_arg2 in arg2:
          if remove_macrons(matching_arg2) == remove_macrons(param2):
            actual_matching_arg2 = matching_arg2
            break
        else:
          # no break
          pagemsg("WARNING: lemma secondary stem(s) %s not matching template second param: %s" % (
            ",".join(arg2), unicode(inflt)))
          continue

        frob_exact(inflt, "1", arg1, pagemsg, notes)
        frob_exact(inflt, "2", actual_matching_arg2, pagemsg, notes)

        for override in lalib.la_noun_decl_overrides:
          frob_stem(inflt, override, stem, pagemsg, notes, split_slashes=True,
              no_warn=True)

        args = lalib.generate_noun_forms(unicode(inflt), errandpagemsg, expand_text)
        if args is None:
          return None, None

        process_all_forms(args, index, lemma,
          pos == "propernoun" and "propernounform" or "nounform", save, verbose
        )

    elif (
      pos == "adj" and (found_head_template or tn in lalib.la_adj_headword_templates) or
      pos == "numadj" and (found_head_template or tn == "la-num-1&2")
    ):
      if not found_head_template:
        if explicit_infl == 1:
          if lemma.endswith("r"):
            inferred_stem = lemma
          elif lemma.endswith("us"):
            inferred_stem = lemma[:-2]
          else:
            errandpagemsg("WARNING: Bad 1st/2nd-declension adjective lemma %s" % lemma)
            return None, None
        elif explicit_infl == 3:
          inferred_stem = lalib.infer_3rd_decl_stem(lemma)
        stem = explicit_stem or inferred_stem

        if (explicit_infl == 1 and tn in ["la-adj-1&2", "la-adj-superlative", "la-num-1&2"] or
            explicit_infl == 3 and tn in ["la-adj-3rd-1E", "la-adj-3rd-2E", "la-adj-3rd-3E", "la-adj-comparative"]):
          frob_chain_exact(ht, ["1", "head"], lemma, pagemsg, notes)
          if tn in ["la-adj-1&2", "la-adj-3rd-1E", "la-adj-3rd-2E", "la-adj-3rd-3E"]:
            frob_chain_stem(ht, "comp", stem, pagemsg, notes, no_warn=True)
            frob_chain_stem(ht, "sup", stem, pagemsg, notes, no_warn=True)
          if tn in ["la-adj-1&2", "la-num-1&2", "la-adj-3rd-3E"]:
            frob_chain_stem(ht, ["2", "f"], stem, pagemsg, notes)
            frob_chain_stem(ht, ["3", "n"], stem, pagemsg, notes)
          elif tn == "la-adj-3rd-1E":
            frob_chain_stem(ht, ["2", "gen"], stem, pagemsg, notes)
          elif tn == "la-adj-3rd-2E":
            frob_chain_stem(ht, ["2", "n"], stem, pagemsg, notes)
          elif tn == "la-adj-comparative":
            if lemma.endswith("ior"):
              base = lemma[:-3]
              frob_stem(ht, "comp", base, pagemsg, notes, no_warn=True)
          elif tn == "la-adj-superlative":
            if lemma.endswith("issimus"):
              base = lemma[:-7]
            if lemma.endswith("rimus"):
              base = lemma[:-5]
            else:
              base = None
            if base:
              frob_stem(ht, "sup", base, pagemsg, notes)
        else:
          pagemsg("WARNING: Mismatch between requested adjective inflection %s and actual adjective headword template %s" % (
            explicit_infl, unicode(ht)))
          continue

      found_matching_head = True

      for inflt in headword['infl_templates']:
        infltn = tname(inflt)
        if infltn not in lalib.la_adj_decl_templates:
          pagemsg("WARNING: Saw bad declension template for infl=%s adj %s: %s" % (
            explicit_infl, lemma, unicode(inflt)))
          continue

        if explicit_infl == 1:
          if infltn != "la-decl-1&2":
            pagemsg("WARNING: Saw mismatching adjective declension template for first/second-declension adjective %s: %s" % (
              lemma, unicode(inflt)))
            continue
          if lemma.endswith("er") and lemma != stem:
            if getparam(inflt, "1").endswith("(e)r"):
              arg1 = lemma[:-2] + "(e)r"
              arg2 = ""
            else:
              arg1 = lemma
              arg2 = stem
          else:
            arg1 = stem
            arg2 = ""
        elif explicit_infl == 3:
          if infltn in ["la-decl-3rd-1E", "la-decl-3rd-3E", "la-decl-3rd-part"]:
            arg1 = lemma
            if stem != inferred_stem:
              arg2 = stem
            else:
              arg2 = ["", inferred_stem]
          elif infltn == "la-decl-3rd-2E":
            if not lemma.endswith("is"):
              pagemsg("WARNING: Bad lemma %s for 3rd declension, two-ending adjective: %s" % (
                lemma, unicode(inflt)))
              continue
            arg1 = lemma[:-2]
            arg2 = ""
          elif infltn == "la-decl-3rd-comp":
            if not lemma.endswith("or"):
              pagemsg("WARNING: Bad lemma %s for 3rd declension comparative adjective: %s" % (
                lemma, unicode(inflt)))
              continue
            arg1 = lemma[:-3]
            if getparam(inflt, "2"):
              arg2 = lemma[-3]
            else:
              arg2 = ""
        else:
          errandpagemsg("WARNING: Unrecognized infl %s" % explicit_infl)
          return None, None

        if remove_macrons(arg1) != remove_macrons(getparam(inflt, "1")):
          pagemsg("WARNING: lemma stem %s doesn't match template stem: %s" % (
            arg1, unicode(inflt)))
          continue
        param2 = getparam(inflt, "2")
        if type(arg2) is not list:
          arg2 = [arg2]
        actual_matching_arg2 = None
        for matching_arg2 in arg2:
          if remove_macrons(matching_arg2) == remove_macrons(param2):
            actual_matching_arg2 = matching_arg2
            break
        else:
          # no break
          pagemsg("WARNING: lemma secondary stem(s) %s not matching template second param: %s" % (
            ",".join(arg2), unicode(inflt)))
          continue
        frob_exact(inflt, "1", arg1, pagemsg, notes)
        frob_exact(inflt, "2", actual_matching_arg2, pagemsg, notes)

        for override in lalib.la_adj_decl_overrides:
          frob_stem(inflt, override, stem, pagemsg, notes, split_slashes=True,
              no_warn=True)

        args = lalib.generate_adj_forms(unicode(inflt), errandpagemsg, expand_text)
        if args is None:
          return None, None
        process_all_forms(args, index, lemma,
          pos == "numadj" and "numform" or "adjform", save, verbose)

    elif pos == "verb" and (found_head_template or tn == "la-verb"):
      # Figure out the actual inflection and deponent status.
      deponent = False
      if explicit_infl == 1 and not explicit_stem:
        infl = 1
        if lemma.endswith("or"):
          deponent = True
          vinf = lemma[:-2] + u"ārī"
          vperf = ""
          vsup = lemma[:-2] + u"ātum"
        elif lemma.endswith(u"ō"):
          vinf = lemma[:-1] + u"āre"
          vperf = lemma[:-1] + u"āvī"
          vsup = lemma[:-1] + u"ātum"
        else:
          errandpagemsg("WARNING: Bad lemma %s for 1st-conjugation verb" % lemma)
          return None, None
      elif explicit_infl == 4 and not explicit_stem:
        infl = 4
        if lemma.endswith("ior"):
          deponent = True
          vinf = lemma[:-3] + u"īrī"
          vperf = ""
          vsup = lemma[:-3] + u"ītum"
        elif lemma.endswith(u"iō"):
          vinf = lemma[:-2] + u"īre"
          vperf = lemma[:-2] + u"īvī"
          vsup = lemma[:-2] + u"ītum"
        else:
          errandpagemsg("WARNING: Bad lemma %s for 4th-conjugation verb" % lemma)
          return None, None
      elif not explicit_infl and explicit_stem:
        if lemma.endswith("or") or lemma.endswith("tur"):
          impers = lemma.endswith("tur")
          deponent = True
          if len(explicit_stem) != 2:
            errandpagemsg("WARNING: For verb lemma %s, wrong length of explicit stem %s" % (lemma, explicit_stem))
            return None, None
          vinf, vsup = explicit_stem
          vperf = ""
          if vinf.endswith(u"ī") and (lemma[:-4] if impers else lemma[:-2]) == vinf[:-1]:
            infl = 3
          elif vinf.endswith(u"ī") and lemma.endswith("ior") and lemma[:-3] == vinf[:-1]:
            infl = "io"
          elif vinf.endswith(u"ārī"):
            infl = 1
          elif vinf.endswith(u"ērī"):
            infl = 2
          elif vinf.endswith(u"īrī"):
            infl = 4
          else:
            errandpagemsg("WARNING: Unrecognized verb infinitive %s for lemma %s" % (vinf, lemma))
            return None, None
        elif lemma.endswith(u"ō") or lemma.endswith("t"):
          if len(explicit_stem) != 3:
            errandpagemsg("WARNING: For verb lemma %s, wrong length of explicit stem %s" % (lemma, explicit_stem))
            return None, None
          vinf, vperf, vsup = explicit_stem
          if vinf.endswith(u"āre"):
            infl = 1
          elif vinf.endswith(u"ēre"):
            infl = 2
          elif vinf.endswith(u"īre"):
            infl = 4
          elif vinf.endswith("ere") and lemma.endswith(u"iō"):
            infl = "io"
          elif vinf.endswith("ere"):
            infl = 3
          elif (vinf.endswith("rre") or vinf.endswith("lle") or vinf.endswith("sse") or vinf.endswith("dare")):
            infl = "irreg"
          else:
            errandpagemsg("WARNING: Unrecognized verb infinitive %s for lemma %s" % (vinf, lemma))
            return None, None
        else:
          errandpagemsg("WARNING: Unrecognized verb lemma %s" % lemma)
          return None, None
      else:
        errandpagemsg("WARNING: For verb lemma %s, bad infl %s combined with explicit stem %s" % (lemma, explicit_infl, explicit_stem))
        return None, None

      if not found_head_template:
        if getparam(ht, "conj") != str(infl):
          continue

        def compare_principal_part(first, rest, value):
          values = [] if not value else value.split("/")
          no_macron_values = [remove_macrons(x) for x in values]
          actual_values = blib.fetch_param_chain(ht, first, rest)
          no_macron_actual_values = [remove_macrons(x) for x in actual_values]
          if no_macron_values != no_macron_actual_values:
            pagemsg("WARNING: Principal part mismatch for param=%s, saw %s, expected %s" % (
              rest, "/".join(actual_values), "/".join(values)))
            return False
          return True

        if not compare_principal_part("1", "head", lemma):
          continue
        if not compare_principal_part("2", "inf", vinf):
          continue
        if deponent:
          sups = vsup.split("/")
          perfs = []
          for sup in sups:
            if not sup.endswith("um"):
              errandpagemsg("WARNING: For verb lemma %s, bad deponent supine %s" % (lemma, sup))
              return None, None
            perfs.append(sup[:-2] + "us sum")
          if not compare_principal_part("3", "perf", "/".join(perfs)):
            continue
        else:
          if not compare_principal_part("3", "perf", vperf):
            continue
          if not compare_principal_part("4", "sup", vsup):
            continue

        frob_chain_exact(ht, ["1", "head"], lemma.split("/"), pagemsg, notes)
        frob_chain_exact(ht, ["2", "inf"], vinf.split("/"), pagemsg, notes)
        if deponent:
          frob_chain_exact(ht, ["3", "perf"], perfs, pagemsg, notes)
        else:
          frob_chain_exact(ht, ["3", "perf"], vperf.split("/"), pagemsg, notes)
          frob_chain_exact(ht, ["4", "sup"], vsup.split("/"), pagemsg, notes)

      found_matching_head = True

      for inflt in headword['infl_templates']:
        infltn = tname(inflt)
        if infltn not in lalib.la_verb_conj_templates:
          pagemsg("WARNING: Saw bad conjugation template for infl=%s verb %s: %s" % (
            infl, lemma, unicode(inflt)))
          continue

        def truncate_ending(val, expected_ending, parttype):
          if not val:
            return ""
          vals = val.split("/")
          stems = []
          for v in vals:
            if not v.endswith(expected_ending):
              errandpagemsg("WARNING: %s should end in -%s: %s" % (parttype, expected_ending, v))
              return None
            stems.append(v[:-len(expected_ending)])
          return "/".join(stems)

        if infl == "irreg":
          if infltn != "la-conj-irreg":
            pagemsg("WARNING: Saw mismatching conjugation template for infl=%s verb %s: %s" % (
              infl, lemma, unicode(inflt)))
            continue
          prefix = getparam(inflt, "2")
          if prefix:
            lemmaprefix = lemma[0:len(prefix)]
            if remove_macrons(lemmaprefix) != remove_macrons(prefix):
              pagemsg("WARNING: Saw prefix mismatch, actual %s != expected %s for lemma %s: %s" % (
                prefix, lemmaprefix, lemma, unicode(inflt)))
              continue
            frob_exact(inflt, "2", lemmaprefix, pagemsg, notes)
        else:
          if infl == 1:
            if infltn != "la-conj-1st":
              pagemsg("WARNING: Saw mismatching conjugation template for first-conjugation verb %s: %s" % (
                lemma, unicode(inflt)))
              continue
            if deponent:
              if not lemma.endswith("or"):
                errpagemsg("First-conjugation deponent lemma should end in -or: %s" % lemma)
                return None, None
              arg1 = lemma[:-2]
              if vsup == arg1 + u"ātum":
                arg2 = ["", arg1 + u"āt"]
              else:
                arg2 = truncate_ending(vsup, "um", "First-conjugation deponent supine")
                if arg2 is None:
                  return None, None
              arg3 = ""
            else:
              if not lemma.endswith(u"ō"):
                errpagemsg(u"First-conjugation lemma should end in -ō: %s" % lemma)
                return None, None
              arg1 = lemma[:-1]
              if vperf == arg1 + u"āvī":
                arg2 = ["", arg1 + u"āv"]
              else:
                arg2 = truncate_ending(vperf, u"ī", "First-conjugation perfect")
                if arg2 is None:
                  return None, None
              if vsup == arg1 + u"ātum":
                arg3 = ["", arg1 + u"āt"]
              else:
                arg3 = truncate_ending(vsup, "um", "First-conjugation supine")
                if arg3 is None:
                  return None, None
          else:
            if (infl == 2 and infltn != "la-conj-2nd" or
                infl == 3 and infltn != "la-conj-3rd" or
                infl == "io" and infltn != "la-conj-3rd-IO" or
                infl == 4 and infltn != "la-conj-4th"):
              pagemsg("WARNING: Saw mismatching conjugation template for infl=%s verb %s: %s" % (
                infl, lemma, unicode(inflt)))
              continue
            if deponent:
              if infl == 2:
                expected_ending = "eor"
              elif infl == 3:
                expected_ending = "or"
              else:
                expected_ending = "ior"
              if not lemma.endswith(expected_ending):
                errpagemsg("WARNING: Infl=%s deponent lemma should end in -%s: %s" % (
                  infl, expected_ending, lemma))
                return None, None
              arg1 = lemma[:-len(expected_ending)]
              arg2 = truncate_ending(vsup, "um", "Infl=%s deponent supine" % infl)
              if arg2 is None:
                return None, None
              arg3 = ""
            else:
              if infl == 2:
                expected_ending = u"eō"
              elif infl == 3:
                expected_ending = u"ō"
              else:
                expected_ending = u"iō"
              if not lemma.endswith(expected_ending):
                errandpagemsg("WARNING: Infl=%s lemma should end in -%s: %s" % (
                  infl, expected_ending, lemma))
                return None, None
              arg1 = lemma[:-len(expected_ending)]
              arg2 = truncate_ending(vperf, u"ī", "Infl=%s perfect" % infl)
              if arg2 is None:
                return None, None
              arg3 = truncate_ending(vsup, "um", "Infl=%s supine" % infl)
              if arg3 is None:
                return None, None
          frob_exact(inflt, "1", arg1, pagemsg, notes)
          frob_exact(inflt, "2", arg2, pagemsg, notes)
          frob_exact(inflt, "3", arg3, pagemsg, notes)

        # FIXME, handle overrides
        for override in lalib.la_verb_overrides:
          overval = getparam(inflt, override)
          if overval:
            pagemsg("WARNING: Found override %s=%s: %s" % (
              override, overval, unicode(inflt)))

        args = lalib.generate_verb_forms(unicode(inflt), errandpagemsg, expand_text)
        if args is None:
          return None, None

        single_forms_to_process = []
        for key, form in args.iteritems():
          for single_form in form.split(","):
            single_forms_to_process.append((key, single_form))

        for formind, (key, formval) in blib.iter_items(
            single_forms_to_process, get_name=lambda x: x[1]):
          partpos = None
          if key == "pres_actv_ptc":
            partpos = "presactpart"
          elif key in ["perf_actv_ptc", "perf_pasv_ptc"]:
            partpos = "perfpasspart"
          elif key == "futr_actv_ptc":
            partpos = "futactpart"
          elif key == "futr_pasv_ptc":
            partpos = "futpasspart"

          if partpos:
            process_participle(index, lemma, formind, formval, partpos,
                save, verbose)
          else:
            process_form(index, lemma, formind, formval, "verbform",
                find_tag_sets_for_form(args, formval), save, verbose)

        #for formtype in ["pres", "perf", "sup"]:
        #  forms_to_process = []
        #  tag_sets_to_process = []
        #  for key, val in args.iteritems():
        #    if (
        #        (formtype == "pres" and not re.search("(perf|plup|futp|sup)", key) and key != "futr_actv_ptc") or
        #        (formtype == "perf" and key not in ["perf_actv_ptc", "perf_pasv_ptc"] and re.search("(perf|plup|futp)", key)) or
        #        (formtype == "sup" and ("sup" in key or key in ["perf_actv_ptc", "perf_pasv_ptc", "futr_actv_ptc"]))
        #      ):
        #      tag_sets_to_process.append(lalib.form_key_to_tag_set(key))
        #      forms_to_process.append((key, val))
        #  single_forms_to_process = []
        #  for key, form in forms_to_process:
        #    for single_form in form.split(","):
        #      single_forms_to_process.append((key, single_form))

        #  for formind, (key, formval) in blib.iter_items(
        #      single_forms_to_process, get_name=lambda x: x[1]):

    if found_matching_head:
      process_pronun_templates(headword['pronun_section'], lemma, pagemsg, notes)

  secbody = "".join(unicode(x) for x in parsed_subsections)
  sections[j] = secbody + sectail
  return "".join(sections), notes

parser = blib.create_argparser("Clean up usage of macrons in Latin non-lemma forms")
parser.add_argument("--direcfile", help="File containing directives of lemmas to process.")
parser.add_argument("--dry-run", help="Just show what would be checked, don't actually check references.", action="store_true")
args = parser.parse_args()
start, end = blib.parse_start_end(args.start, args.end)

direcfile = args.direcfile.decode("utf-8")

lemmas = []

for line in codecs.open(direcfile, "r", "utf-8"):
  line = line.rstrip('\n')
  if line.startswith("*"):
    line = line[1:]
    msg("Need to investigate: %s" % line)
  if line.startswith("#"):
    continue
  # remove transitive/intransitive notation after verbs
  line = re.sub(r" *\[.*\]$", "", line)
  parts = line.split(" ")
  # allow underscore to stand for space
  parts = [part.replace("_", " ") for part in parts]
  if len(parts) == 2 and parts[0] in ["adv", "num", "phr", "prov"]:
    pass
  elif (len(parts) == 2 or len(parts) == 3) and parts[0] in [
      "n1", "n2", "n3", "n4", "n5", "pn1", "pn2", "pn3", "pn4", "pn5",
      "num1", "a1", "a3"
  ]:
    # noun or adjective
    if len(parts) == 3:
      pos, lemma, explicit_stem = parts
    else:
      pos, lemma = parts
      explicit_stem = None
    m = re.search("^(n|pn|a|num)([1-5])$", pos)
    code_to_pos = {"n": "noun", "pn": "propernoun", "a": "adj", "num": "numadj"}
    pos = code_to_pos[m.group(1)]
    infl = int(m.group(2))
  
    lemmas.append((pos, infl, lemma, explicit_stem))

  elif len(parts) == 2 and parts[0] in ["v1", "v4"]:
    # regular verb
    pos, lemma = parts
    m = re.search("^v([14])$", pos)
    infl = int(m.group(1))
    lemmas.append(("verb", infl, lemma, None))
  else:
    pos = "verb"
    stems_lemmas = []
    if len(parts) == 3:
      # deponent verb
      lemma, inf, supine = parts
      if lemma.startswith("*"):
        no_main = True
        lemma = lemma[1:]
      else:
        no_main = False
      if inf.startswith("*"):
        # FIXME
        inf = inf[1:]
      if supine.startswith("*"):
        # FIXME
        supine = supine[1:]
      if inf == "--":
        inf = ""
      if supine == "--":
        supine = ""
      lemmas.append(("verb", None, lemma, [inf, supine]))

    else:
      assert len(parts) == 4
      lemma, inf, perf, supine = parts
      if lemma.startswith("*"):
        no_main = True
        lemma = lemma[1:]
      else:
        no_main = False
      if inf.startswith("*"):
        # FIXME
        inf = inf[1:]
      if perf.startswith("*"):
        # FIXME
        perf = perf[1:]
      if supine.startswith("*"):
        # FIXME
        supine = supine[1:]
      if inf == "--":
        inf = ""
      if perf == "--":
        perf = ""
      if supine == "--":
        supine = ""
      lemmas.append(("verb", None, lemma, [inf, perf, supine]))

for index, (pos, infl, lemma, explicit_stem) in blib.iter_items(lemmas, start, end,
    get_name=lambda lemmas: remove_macrons(lemmas[2])):
  def handler(page, index, parsed):
    return do_process_lemma(index, page, pos, infl, lemma, explicit_stem, args.save, args.verbose)
  blib.do_edit(pywikibot.Page(site, remove_macrons(lemma)), index, handler, save=args.save, verbose=args.verbose)
